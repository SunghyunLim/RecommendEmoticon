{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.4] API GATEWAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_N_label(score_list, topN):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    top_n_idx = np.argsort(score_list)[-topN:]\n",
    "    top_n_values = [score_list[i] for i in top_n_idx]\n",
    "    \n",
    "    print(top_n_idx)\n",
    "\n",
    "\n",
    "    top_n_idx_list = top_n_idx.tolist()\n",
    "    top_n_idx_list.reverse()\n",
    "    top_n_values = [score_list[i] for i in top_n_idx_list]    \n",
    "    \n",
    "    print(top_n_idx_list)\n",
    "    print(top_n_values)\n",
    "\n",
    "topN = 3    \n",
    "show_top_N_label(predicted_classes[0], topN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boto3 Client 에서 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint = tweet_bert_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-tensorflow-serving-2020-07-24-10-34-12-001'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo {$invoke_endpoint}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-tensorflow-serving-2020-07-24-10-34-12-001\n",
      "{\n",
      "    \"ContentType\": \"application/json\",\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {invoke_endpoint}\n",
    "\n",
    "invoke_endpoint=$1\n",
    "echo $invoke_endpoint\n",
    "\n",
    "aws sagemaker-runtime invoke-endpoint \\\n",
    "  --endpoint-name  $invoke_endpoint \\\n",
    "  --body '[\"This is great\"]' \\\n",
    "  --content-type application/json \\\n",
    "  --accept application/json \\\n",
    "  results\n",
    "echo $results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = \"This is great\"\n",
    "payload = '[\"' + payload + '\"]'\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "import csv\n",
    "\n",
    "ENDPOINT_NAME = os.environ['ENDPOINT_NAME'] \n",
    "runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # TODO implement\n",
    "try:\n",
    "print(\"Received event: \" + json.dumps(event, indent=2))\n",
    "\n",
    "data = json.loads(json.dumps(event))\n",
    "payload = data['tweet']\n",
    "payload = '[\"' + payload + '\"]'\n",
    "print(\"Final input: \" ,payload)\n",
    "\n",
    "print(payload)\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName = ENDPOINT_NAME,\n",
    "                            ContentType = 'application/json',\n",
    "                            Body = payload)\n",
    "\n",
    "print(response)\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)\n",
    "return result\n",
    "except:\n",
    "print(\"An error occurred\")\n",
    "return data\n",
    "\n",
    "\n",
    "# return {\n",
    "#     'statusCode': 200,\n",
    "#     'body': json.dumps('Hello from Lambda!')\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Different Inference Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "import csv\n",
    "\n",
    "ENDPOINT_NAME = os.environ['ENDPOINT_NAME'] \n",
    "runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # TODO implement\n",
    "try:\n",
    "print(\"Received event: \" + json.dumps(event, indent=2))\n",
    "\n",
    "data = json.loads(json.dumps(event))\n",
    "payload = data['tweet']\n",
    "payload = '[\"' + payload + '\"]'\n",
    "print(\"Final input: \" ,payload)\n",
    "\n",
    "print(payload)\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName = ENDPOINT_NAME,\n",
    "                            ContentType = 'application/json',\n",
    "                            Body = payload)\n",
    "\n",
    "print(response)\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)\n",
    "return result\n",
    "except:\n",
    "print(\"An error occurred\")\n",
    "return data\n",
    "\n",
    "\n",
    "# return {\n",
    "#     'statusCode': 200,\n",
    "#     'body': json.dumps('Hello from Lambda!')\n",
    "# }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
