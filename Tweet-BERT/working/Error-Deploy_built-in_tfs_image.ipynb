{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 첫번째 링크를 시도를 해보았으나, 2.0.0 의 TFS 버전은 지원을 하지 않음.\n",
    "TFS_VERSION = 1.3 으로 해서 Endpoint 생성은 되었으나 아래와 같은 에러 발생\n",
    "\n",
    "ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"{\"error\": \"{ \\\"error\\\": \\\"Servable not found for request: Latest(saved_model)\\\" }\"}\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/bert-tweet-endpoint2020-07-24-05-09-54 in account 057716757052 for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Performing batch inference with TensorFlow Serving in Amazon SageMaker# inference on Docker Image\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/performing-batch-inference-with-tensorflow-serving-in-amazon-sagemaker/\n",
    "\n",
    "SageMaker TensorFlow Serving Container\n",
    "- https://github.com/aws/sagemaker-tensorflow-serving-container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repackage Model Artifact\n",
    "####  Download the Model to the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_download = 'model'\n",
    "model_repackage = 'model/package'\n",
    "model_repackage_code = 'model/package/code'\n",
    "os.makedirs(model_download, exist_ok=True)\n",
    "os.makedirs(model_repackage, exist_ok=True)\n",
    "os.makedirs(model_repackage_code, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_download_path = 's3://{}/{}/output/model.tar.gz'.format(bucket,training_job_name) \n",
    "model_upload_model_path = 's3://{}/{}/upload-model/model.tar.gz'.format(bucket,training_job_name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-057716757052/tensorflow-training-2020-07-23-13-02-11-499/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp  {model_download_path} {model_download}/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers/\n",
      "transformers/fine-tuned/\n",
      "transformers/fine-tuned/config.json\n",
      "transformers/fine-tuned/tf_model.h5\n",
      "tensorflow/\n",
      "tensorflow/saved_model/\n",
      "tensorflow/saved_model/0/\n",
      "tensorflow/saved_model/0/saved_model.pb\n",
      "tensorflow/saved_model/0/assets/\n",
      "tensorflow/saved_model/0/variables/\n",
      "tensorflow/saved_model/0/variables/variables.index\n",
      "tensorflow/saved_model/0/variables/variables.data-00001-of-00002\n",
      "tensorflow/saved_model/0/variables/variables.data-00000-of-00002\n",
      "tensorflow/\n",
      "tensorflow/saved_model/\n",
      "tensorflow/saved_model/0/\n",
      "tensorflow/saved_model/0/variables/\n",
      "tensorflow/saved_model/0/variables/variables.index\n",
      "tensorflow/saved_model/0/variables/variables.data-00000-of-00002\n",
      "tensorflow/saved_model/0/variables/variables.data-00001-of-00002\n",
      "tensorflow/saved_model/0/assets/\n",
      "tensorflow/saved_model/0/saved_model.pb\n",
      "transformers/\n",
      "transformers/fine-tuned/\n",
      "transformers/fine-tuned/tf_model.h5\n",
      "transformers/fine-tuned/config.json\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf   {model_download}/model.tar.gz -C {model_download}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/inference.py\n",
      "code/requirements.txt\n",
      "0/\n",
      "0/assets/\n",
      "0/saved_model.pb\n",
      "0/variables/\n",
      "0/variables/variables.index\n",
      "0/variables/variables.data-00001-of-00002\n",
      "0/variables/variables.data-00000-of-00002\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {model_download} {model_repackage} {model_repackage_code}\n",
    "\n",
    "cp  requirements.txt $3\n",
    "cp  inference.py $3\n",
    "cp -r $1/tensorflow/saved_model/0/ $2\n",
    "cd $2\n",
    "tar -czvf model.tar.gz code 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/package/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "repackage_model_file = os.path.join(model_repackage, 'model.tar.gz')\n",
    "print(repackage_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inference_image = container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region:\tus-west-2\n",
      "520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-serving:1.13-cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "prefix = 'tensorflow-training-2020-07-23-13-02-11-499/upload-model'\n",
    "\n",
    "tfs_version = '1.13'\n",
    "processor_type = 'cpu'\n",
    "\n",
    "# model_url = model_upload_model_path\n",
    "model_url = \"s3://{}/model.tar.gz\".format(os.path.join(bucket, prefix))\n",
    "model_name = \"bert-tweet\" + timestamp_prefix\n",
    "endpoint_cfg_name = \"bert-tweet-endpoint-config\" + timestamp_prefix\n",
    "endpoint_name = \"bert-tweet-endpoint\" + timestamp_prefix\n",
    "\n",
    "container = \"520713654638.dkr.ecr.{}.amazonaws.com/sagemaker-tensorflow-serving:{}-{}\".format(\n",
    "    region, tfs_version, processor_type)\n",
    "\n",
    "print('Region:\\t{}'.format(region))\n",
    "#print('Role:\\t{}'.format(role))\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: model/package/model.tar.gz to s3://sagemaker-us-west-2-057716757052/tensorflow-training-2020-07-23-13-02-11-499/upload-model/model.tar.gz\n",
      "{\n",
      "    \"ModelArn\": \"arn:aws:sagemaker:us-west-2:057716757052:model/bert-tweet2020-07-24-05-09-54\"\n",
      "}\n",
      "{\n",
      "    \"EndpointConfigArn\": \"arn:aws:sagemaker:us-west-2:057716757052:endpoint-config/bert-tweet-endpoint-config2020-07-24-05-09-54\"\n",
      "}\n",
      "{\n",
      "    \"EndpointArn\": \"arn:aws:sagemaker:us-west-2:057716757052:endpoint/bert-tweet-endpoint2020-07-24-05-09-54\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$role\" \"$region\" \"$bucket\" \"$prefix\" \"$model_url\" \"$model_name\" \"$endpoint_cfg_name\" \"$endpoint_name\" \"$container\"\n",
    "# For convenience, we pass in variables in first Python set-up cell\n",
    "\n",
    "timestamp() {\n",
    "  date +%Y-%m-%d-%H-%M-%S\n",
    "}\n",
    "\n",
    "ROLE_ARN=$1\n",
    "REGION=$2\n",
    "BUCKET=$3\n",
    "# PREFIX=$4\n",
    "MODEL_DATA_URL=$5\n",
    "MODEL_NAME=$6\n",
    "ENDPOINT_CONFIG_NAME=$7\n",
    "ENDPOINT_NAME=$8\n",
    "CONTAINER=$9\n",
    "\n",
    "aws s3 cp model/package/model.tar.gz $MODEL_DATA_URL\n",
    "\n",
    "aws sagemaker create-model \\\n",
    "    --model-name $MODEL_NAME \\\n",
    "    --primary-container Image=$CONTAINER,ModelDataUrl=$MODEL_DATA_URL \\\n",
    "    --execution-role-arn $ROLE_ARN\n",
    "    \n",
    "VARIANT_NAME=\"TFS\"\n",
    "INITIAL_INSTANCE_COUNT=1\n",
    "#INSTANCE_TYPE=\"ml.p2.xlarge\"\n",
    "INSTANCE_TYPE=\"ml.c4.xlarge\"\n",
    "aws sagemaker create-endpoint-config \\\n",
    "    --endpoint-config-name $ENDPOINT_CONFIG_NAME \\\n",
    "    --production-variants VariantName=$VARIANT_NAME,ModelName=$MODEL_NAME,InitialInstanceCount=$INITIAL_INSTANCE_COUNT,InstanceType=$INSTANCE_TYPE\n",
    "\n",
    "aws sagemaker create-endpoint \\\n",
    "    --endpoint-name $ENDPOINT_NAME \\\n",
    "    --endpoint-config-name $ENDPOINT_CONFIG_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the endpoint without custom Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-tweet-endpoint2020-07-24-05-09-54\n"
     ]
    }
   ],
   "source": [
    "# tweet_bert_endpoint_name = 'sagemaker-tensorflow-serving-2020-07-09-00-37-50-247'\n",
    "tweet_bert_endpoint_name = endpoint_name\n",
    "print(tweet_bert_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-tweet-endpoint2020-07-24-05-09-54'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_bert_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "\n",
    "predictor = Predictor(endpoint_name = tweet_bert_endpoint_name,\n",
    "                      sagemaker_session = sess,\n",
    "                      content_type = 'application/json',\n",
    "                      model_name = 'saved_model',\n",
    "                      model_version=0\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"{\"error\": \"{ \\\"error\\\": \\\"Servable not found for request: Latest(saved_model)\\\" }\"}\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/bert-tweet-endpoint2020-07-24-05-09-54 in account 057716757052 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-accc11fbb050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# reviews = [\"The weather is so nice causing me to be depressed!\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredicted_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredicted_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/tensorflow/serving.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CustomAttributes\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"{\"error\": \"{ \\\"error\\\": \\\"Servable not found for request: Latest(saved_model)\\\" }\"}\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/bert-tweet-endpoint2020-07-24-05-09-54 in account 057716757052 for more information."
     ]
    }
   ],
   "source": [
    "# reviews = [\"This is not great!\", \"You are awesome because you look great\"]\n",
    "# reviews = [\"The weather is so nice causing me to be depressed!\"]\n",
    "reviews = [\"hi\"]\n",
    "predicted_classes = predictor.predict(reviews)\n",
    "predicted_classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_N_label(score_list, topN):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    top_n_idx = np.argsort(score_list)[-topN:]\n",
    "    top_n_values = [score_list[i] for i in top_n_idx]\n",
    "    \n",
    "    print(top_n_idx)\n",
    "\n",
    "\n",
    "    top_n_idx_list = top_n_idx.tolist()\n",
    "    top_n_idx_list.reverse()\n",
    "    top_n_values = [score_list[i] for i in top_n_idx_list]    \n",
    "    \n",
    "    print(top_n_idx_list)\n",
    "    print(top_n_values)\n",
    "\n",
    "topN = 3    \n",
    "show_top_N_label(predicted_classes[0], topN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Boto3 Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint = 'sagemaker-tensorflow-serving-2020-07-09-07-31-25-739'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo {$invoke_endpoint}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws sagemaker-runtime invoke-endpoint \\\n",
    "  --endpoint-name sagemaker-tensorflow-serving-2020-07-09-07-31-25-739 \\\n",
    "  --body '[\"This is great\"]' \\\n",
    "  --content-type application/json \\\n",
    "  --accept application/json \\\n",
    "  results\n",
    "echo $results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = \"This is great\"\n",
    "payload = '[\"' + payload + '\"]'\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_test(num1):\n",
    "    try:\n",
    "        sum = num1 + 10\n",
    "        return sum\n",
    "    except:\n",
    "        print(\"Error occured\")\n",
    "        return num1\n",
    "    \n",
    "result = try_test(\"2\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "import csv\n",
    "\n",
    "ENDPOINT_NAME = os.environ['ENDPOINT_NAME'] \n",
    "runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # TODO implement\n",
    "try:\n",
    "print(\"Received event: \" + json.dumps(event, indent=2))\n",
    "\n",
    "data = json.loads(json.dumps(event))\n",
    "payload = data['tweet']\n",
    "payload = '[\"' + payload + '\"]'\n",
    "print(\"Final input: \" ,payload)\n",
    "\n",
    "print(payload)\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName = ENDPOINT_NAME,\n",
    "                            ContentType = 'application/json',\n",
    "                            Body = payload)\n",
    "\n",
    "print(response)\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)\n",
    "return result\n",
    "except:\n",
    "print(\"An error occurred\")\n",
    "return data\n",
    "\n",
    "\n",
    "# return {\n",
    "#     'statusCode': 200,\n",
    "#     'body': json.dumps('Hello from Lambda!')\n",
    "# }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
