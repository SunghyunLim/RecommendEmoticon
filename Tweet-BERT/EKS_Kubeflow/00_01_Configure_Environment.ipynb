{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associate IAM Policies with EKS Worker Nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export INSTANCE_ROLE_NAME=eksctl-cluster-nodegroup-cpu-node-NodeInstanceRole-4DG6CRI38MUD\n",
      "export INSTANCE_PROFILE_ARN=arn:aws:iam::343441690612:role/eksctl-cluster-nodegroup-cpu-node-NodeInstanceRole-4DG6CRI38MUD\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "### Source the environment\n",
    "source ~/.bash_profile\n",
    "\n",
    "export INSTANCE_ROLE_NAME=$(aws iam list-roles \\\n",
    "    | jq -r \".Roles[] \\\n",
    "    | select(.RoleName \\\n",
    "    | startswith(\\\"eksctl-$AWS_CLUSTER_NAME\\\") and contains(\\\"NodeInstanceRole\\\")) \\\n",
    "    .RoleName\")\n",
    "echo \"export INSTANCE_ROLE_NAME=${INSTANCE_ROLE_NAME}\" | tee -a ~/.bash_profile\n",
    "\n",
    "export INSTANCE_PROFILE_ARN=$(aws iam list-roles \\\n",
    "    | jq -r \".Roles[] \\\n",
    "    | select(.RoleName \\\n",
    "    | startswith(\\\"eksctl-$AWS_CLUSTER_NAME\\\") and contains(\\\"NodeInstanceRole\\\")) \\\n",
    "    .Arn\")\n",
    "echo \"export INSTANCE_PROFILE_ARN=${INSTANCE_PROFILE_ARN}\" | tee -a ~/.bash_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "### Source the environment\n",
    "source ~/.bash_profile\n",
    "\n",
    "#### Allow Access from/to the Elastic Container Registry (ECR)\n",
    "# This allows our cluster worker nodes to load custom Docker images (ie. models) from ECR.  We will load these custom Docker images in a later section.\n",
    "aws iam attach-role-policy --role-name $INSTANCE_ROLE_NAME --policy-arn arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryFullAccess\n",
    "\n",
    "echo \"Completed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associated IAM and OIDC\n",
    "To use IAM Roles for Service Accounts in your cluster, you must create an OIDC identity provider in the IAM console.  \n",
    "\n",
    "See https://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html for more info.\n",
    "\n",
    "# _This may take a few minutes.  Please be patient._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ℹ]  eksctl version 0.25.0\n",
      "[ℹ]  using region ap-northeast-2\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 34.327784ms\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 70.467186ms\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 193.029524ms\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 438.904696ms\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 524.595568ms\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 1.333743936s\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 3.128297152s\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 7.49810432s\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 13.55181056s\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 18.869989888s\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 47.890305024s\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 1m55.23520512s\n",
      "[!]  retryable error (EC2MetadataError: failed to make EC2Metadata request\n",
      "\tstatus code: 405, request id: \n",
      "caused by: ) from ec2metadata/GetToken - will retry after delay of 2m53.073911808s\n",
      "request expired, resigning\n",
      "[ℹ]  will create IAM Open ID Connect provider for cluster \"cluster\" in \"ap-northeast-2\"\n",
      "[✔]  created IAM Open ID Connect provider for cluster \"cluster\" in \"ap-northeast-2\"\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "### Source the environment\n",
    "source ~/.bash_profile\n",
    "\n",
    "eksctl utils associate-iam-oidc-provider --cluster ${AWS_CLUSTER_NAME} --approve\n",
    "\n",
    "echo \"Completed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oidc.eks.ap-northeast-2.amazonaws.com/id/89C372954BDCA6AC1A2F60DCFEF39EAD\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "### Source the environment\n",
    "source ~/.bash_profile\n",
    "\n",
    "aws eks describe-cluster --name ${AWS_CLUSTER_NAME} --region ${AWS_REGION} --query \"cluster.identity.oidc.issuer\" --output text\n",
    "\n",
    "echo \"Completed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update `~/.kube/config` with our new EKS cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added new context arn:aws:eks:ap-northeast-2:343441690612:cluster/cluster to /home/ec2-user/.kube/config\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "source ~/.bash_profile\n",
    "\n",
    "aws eks --region ${AWS_REGION} update-kubeconfig --name ${AWS_CLUSTER_NAME} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Your EKS Cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              STATUS   AGE\n",
      "default           Active   17m\n",
      "kube-node-lease   Active   17m\n",
      "kube-public       Active   17m\n",
      "kube-system       Active   17m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "kubectl get ns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                STATUS   ROLES    AGE   VERSION\n",
      "ip-192-168-39-223.ap-northeast-2.compute.internal   Ready    <none>   12m   v1.17.9-eks-4c6976\n",
      "ip-192-168-74-46.ap-northeast-2.compute.internal    Ready    <none>   12m   v1.17.9-eks-4c6976\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "kubectl get nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.save_checkpoint();\n",
       "Jupyter.notebook.session.delete();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.save_checkpoint();\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
