{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On a Docker, Train a BERT Model with Tensorflow\n",
    "- 스크립트 모드를 사용하기 위해서 아래의 API 문서 참고 하세요\n",
    "- Script Mode Ref:\n",
    "    - https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#train-a-model-with-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  스크립트 (Local Mode) 학습 <a class=\"anchor\" id=\"LocalModeTraining\">\n",
    "\n",
    "SageMaker에서 로컬 모드는, 여러분이 작성한 코드를 SageMaker에서 관리되는 보다 강력한 클러스터에서 실행하기 전에, 여러분의 코드가 기대한 방식으로 동작하는 지 로컬에서 확인할 수 있는 편리한 방식입니다. 로컬모드 학습을 위해서는 docker-compose 또는 nvidia-docker-compose (GPU 인스턴스인 경우)의 설치가 필요합니다. 다음 셀의 명령은 본 노트북환경에 docker-compose 또는 nvidia-docker-compose를 설치하고 구성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-057716757052/sagemaker-scikit-learn-2020-06-28-05-08-39-660/output/bert-train', 'S3DataDistributionType': 'ShardedByS3Key'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-057716757052/sagemaker-scikit-learn-2020-06-28-05-08-39-660/output/bert-validation', 'S3DataDistributionType': 'ShardedByS3Key'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-057716757052/sagemaker-scikit-learn-2020-06-28-05-08-39-660/output/bert-test', 'S3DataDistributionType': 'ShardedByS3Key'}}}\n"
     ]
    }
   ],
   "source": [
    "s3_input_train_data = sagemaker.s3_input(s3_data=processed_train_data_s3_uri, \n",
    "                                         distribution='ShardedByS3Key') \n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=processed_validation_data_s3_uri, \n",
    "                                              distribution='ShardedByS3Key')\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=processed_test_data_s3_uri, \n",
    "                                        distribution='ShardedByS3Key')\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-057716757052/checkpoints/388fed24-f3c7-4dc0-96f4-9a22abdb6af1/\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "checkpoint_s3_prefix = 'checkpoints/{}'.format(str(uuid.uuid4()))\n",
    "checkpoint_s3_uri = 's3://{}/{}/'.format(bucket, checkpoint_s3_prefix)\n",
    "\n",
    "print(checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "     {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'train:accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "train_steps_per_epoch=10\n",
    "\n",
    "learning_rate=0.00001\n",
    "epsilon=0.00000001\n",
    "train_batch_size=128\n",
    "validation_batch_size=128\n",
    "test_batch_size=128\n",
    "\n",
    "\n",
    "# train_steps_per_epoch=10\n",
    "validation_steps=100\n",
    "test_steps=100\n",
    "\n",
    "train_instance_count=2 # modified by gonsoo\n",
    "train_instance_type='ml.p3.2xlarge'\n",
    "train_volume_size=1024\n",
    "\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "freeze_bert_layer=False\n",
    "enable_checkpointing=True\n",
    "input_mode='Pipe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_image = \"057716757052.dkr.ecr.us-west-2.amazonaws.com/bert2tweet:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "# if subprocess.call('nvidia-smi') == 0:\n",
    "#     ## Set type to GPU if one is present\n",
    "#     instance_type = 'local_gpu'\n",
    "    \n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "\n",
    "estimator = Estimator( image_name = ecr_image,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       train_instance_count=train_instance_count, # Make sure you have at least this number of input files or the ShardedByS3Key distibution strategy will fail the job due to no data available\n",
    "#                        train_instance_type=train_instance_type,\n",
    "                       train_instance_type= instance_type,                      \n",
    "                       train_volume_size=train_volume_size,\n",
    "#                        checkpoint_s3_uri=checkpoint_s3_uri, # Not support in local mode\n",
    "                       hyperparameters={'epochs': epochs,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'epsilon': epsilon,\n",
    "                                        'train_batch_size': train_batch_size,\n",
    "                                        'validation_batch_size': validation_batch_size,\n",
    "                                        'test_batch_size': test_batch_size,                                             \n",
    "                                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                                        'validation_steps': validation_steps,\n",
    "                                        'test_steps': test_steps,\n",
    "                                        'use_xla': use_xla,\n",
    "                                        'use_amp': use_amp,                                             \n",
    "                                        'max_seq_length': max_seq_length,\n",
    "                                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                                        'enable_checkpointing': enable_checkpointing\n",
    "                                        },\n",
    "                       input_mode=input_mode,\n",
    "                       metric_definitions=metrics_definitions\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/output/bert/train'\n",
    "validation_dir = 'data/output/bert/validation'\n",
    "test_dir = 'data/output/bert/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmp_ocg58_6_algo-2-5h12m_1 ... \n",
      "Creating tmp_ocg58_6_algo-1-5h12m_1 ... \n",
      "\u001b[1BAttaching to tmp_ocg58_6_algo-2-5h12m_1, tmp_ocg58_6_algo-1-5h12m_1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,524 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,525 sagemaker-containers INFO     Failed to parse hyperparameter use_xla value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,525 sagemaker-containers INFO     Failed to parse hyperparameter use_amp value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,525 sagemaker-containers INFO     Failed to parse hyperparameter freeze_bert_layer value False to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,526 sagemaker-containers INFO     Failed to parse hyperparameter enable_checkpointing value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,530 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,531 sagemaker-containers INFO     Failed to parse hyperparameter use_xla value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,531 sagemaker-containers INFO     Failed to parse hyperparameter use_amp value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,531 sagemaker-containers INFO     Failed to parse hyperparameter freeze_bert_layer value False to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,532 sagemaker-containers INFO     Failed to parse hyperparameter enable_checkpointing value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,532 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,539 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,551 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,552 sagemaker-containers INFO     Failed to parse hyperparameter use_xla value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,552 sagemaker-containers INFO     Failed to parse hyperparameter use_amp value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,552 sagemaker-containers INFO     Failed to parse hyperparameter freeze_bert_layer value False to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,553 sagemaker-containers INFO     Failed to parse hyperparameter enable_checkpointing value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,557 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,558 sagemaker-containers INFO     Failed to parse hyperparameter use_xla value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,558 sagemaker-containers INFO     Failed to parse hyperparameter use_amp value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,558 sagemaker-containers INFO     Failed to parse hyperparameter freeze_bert_layer value False to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,558 sagemaker-containers INFO     Failed to parse hyperparameter enable_checkpointing value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,568 sagemaker-containers INFO     Failed to parse hyperparameter use_xla value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,568 sagemaker-containers INFO     Failed to parse hyperparameter use_amp value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,568 sagemaker-containers INFO     Failed to parse hyperparameter freeze_bert_layer value False to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,568 sagemaker-containers INFO     Failed to parse hyperparameter enable_checkpointing value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,572 sagemaker-containers INFO     Failed to parse hyperparameter use_xla value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,572 sagemaker-containers INFO     Failed to parse hyperparameter use_amp value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,572 sagemaker-containers INFO     Failed to parse hyperparameter freeze_bert_layer value False to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,572 sagemaker-containers INFO     Failed to parse hyperparameter enable_checkpointing value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,575 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,579 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,587 sagemaker-containers INFO     Failed to parse hyperparameter use_xla value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,587 sagemaker-containers INFO     Failed to parse hyperparameter use_amp value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,587 sagemaker-containers INFO     Failed to parse hyperparameter freeze_bert_layer value False to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,587 sagemaker-containers INFO     Failed to parse hyperparameter enable_checkpointing value True to Json.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,591 sagemaker-containers INFO     Failed to parse hyperparameter use_xla value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,591 sagemaker-containers INFO     Failed to parse hyperparameter use_amp value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,592 sagemaker-containers INFO     Failed to parse hyperparameter freeze_bert_layer value False to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,592 sagemaker-containers INFO     Failed to parse hyperparameter enable_checkpointing value True to Json.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Returning the value itself\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,593 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,597 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,605 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Training Env:\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m {\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     },\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"current_host\": \"algo-2-5h12m\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"algo-1-5h12m\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"algo-2-5h12m\"\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     ],\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"learning_rate\": 1e-05,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"epsilon\": 1e-08,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"train_batch_size\": 128,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"validation_batch_size\": 128,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"test_batch_size\": 128,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"train_steps_per_epoch\": 10,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"validation_steps\": 100,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"test_steps\": 100,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"use_xla\": \"True\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"use_amp\": \"True\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"max_seq_length\": 128,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"freeze_bert_layer\": \"False\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"enable_checkpointing\": \"True\"\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     },\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"train\": {\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         },\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         },\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"test\": {\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         }\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     },\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"is_master\": false,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"job_name\": \"bert2tweet-2020-06-28-07-04-50-691\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"master_hostname\": \"algo-1-5h12m\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"module_name\": \"tf_script_bert_tweet\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"current_host\": \"algo-2-5h12m\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m             \"algo-1-5h12m\",\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m             \"algo-2-5h12m\"\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m         ]\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     },\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     \"user_entry_point\": \"tf_script_bert_tweet.py\"\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m }\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Environment variables:\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HOSTS=[\"algo-1-5h12m\",\"algo-2-5h12m\"]\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HPS={\"enable_checkpointing\":\"True\",\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":\"False\",\"learning_rate\":1e-05,\"max_seq_length\":128,\"test_batch_size\":128,\"test_steps\":100,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":\"True\",\"use_xla\":\"True\",\"validation_batch_size\":128,\"validation_steps\":100}\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_USER_ENTRY_POINT=tf_script_bert_tweet.py\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-2-5h12m\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"]}\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_CHANNELS=[\"test\",\"train\",\"validation\"]\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_CURRENT_HOST=algo-2-5h12m\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_MODULE_NAME=tf_script_bert_tweet\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:04:55,611 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"current_host\": \"algo-1-5h12m\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"algo-1-5h12m\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"algo-2-5h12m\"\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"learning_rate\": 1e-05,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"epsilon\": 1e-08,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"train_batch_size\": 128,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"validation_batch_size\": 128,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"test_batch_size\": 128,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"train_steps_per_epoch\": 10,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"validation_steps\": 100,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"test_steps\": 100,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"use_xla\": \"True\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"use_amp\": \"True\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"max_seq_length\": 128,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"freeze_bert_layer\": \"False\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"enable_checkpointing\": \"True\"\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"test\": {\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"job_name\": \"bert2tweet-2020-06-28-07-04-50-691\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"master_hostname\": \"algo-1-5h12m\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"module_name\": \"tf_script_bert_tweet\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"current_host\": \"algo-1-5h12m\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m             \"algo-1-5h12m\",\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m             \"algo-2-5h12m\"\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     \"user_entry_point\": \"tf_script_bert_tweet.py\"\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HOSTS=[\"algo-1-5h12m\",\"algo-2-5h12m\"]\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HPS={\"enable_checkpointing\":\"True\",\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":\"False\",\"learning_rate\":1e-05,\"max_seq_length\":128,\"test_batch_size\":128,\"test_steps\":100,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":\"True\",\"use_xla\":\"True\",\"validation_batch_size\":128,\"validation_steps\":100}\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_USER_ENTRY_POINT=tf_script_bert_tweet.py\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-5h12m\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"]}\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_CHANNELS=[\"test\",\"train\",\"validation\"]\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_CURRENT_HOST=algo-1-5h12m\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_MODULE_NAME=tf_script_bert_tweet\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-5h12m\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"],\"hyperparameters\":{\"enable_checkpointing\":\"True\",\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":\"False\",\"learning_rate\":1e-05,\"max_seq_length\":128,\"test_batch_size\":128,\"test_steps\":100,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":\"True\",\"use_xla\":\"True\",\"validation_batch_size\":128,\"validation_steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bert2tweet-2020-06-28-07-04-50-691\",\"log_level\":20,\"master_hostname\":\"algo-1-5h12m\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-5h12m\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_USER_ARGS=[\"--enable_checkpointing\",\"True\",\"--epochs\",\"1\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"1e-05\",\"--max_seq_length\",\"128\",\"--test_batch_size\",\"128\",\"--test_steps\",\"100\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"10\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"100\"]\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_LEARNING_RATE=1e-05\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_EPSILON=1e-08\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_TRAIN_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_VALIDATION_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_TEST_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_TRAIN_STEPS_PER_EPOCH=10\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_VALIDATION_STEPS=100\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_TEST_STEPS=100\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_USE_XLA=True\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_USE_AMP=True\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_MAX_SEQ_LENGTH=128\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_FREEZE_BERT_LAYER=False\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m SM_HP_ENABLE_CHECKPOINTING=True\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m /usr/bin/python3 tf_script_bert_tweet.py --enable_checkpointing True --epochs 1 --epsilon 1e-08 --freeze_bert_layer False --learning_rate 1e-05 --max_seq_length 128 --test_batch_size 128 --test_steps 100 --train_batch_size 128 --train_steps_per_epoch 10 --use_amp True --use_xla True --validation_batch_size 128 --validation_steps 100\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-2-5h12m\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"],\"hyperparameters\":{\"enable_checkpointing\":\"True\",\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":\"False\",\"learning_rate\":1e-05,\"max_seq_length\":128,\"test_batch_size\":128,\"test_steps\":100,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":\"True\",\"use_xla\":\"True\",\"validation_batch_size\":128,\"validation_steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"bert2tweet-2020-06-28-07-04-50-691\",\"log_level\":20,\"master_hostname\":\"algo-1-5h12m\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2-5h12m\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_USER_ARGS=[\"--enable_checkpointing\",\"True\",\"--epochs\",\"1\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"1e-05\",\"--max_seq_length\",\"128\",\"--test_batch_size\",\"128\",\"--test_steps\",\"100\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"10\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"100\"]\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_LEARNING_RATE=1e-05\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_EPSILON=1e-08\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_TRAIN_BATCH_SIZE=128\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_VALIDATION_BATCH_SIZE=128\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_TEST_BATCH_SIZE=128\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_TRAIN_STEPS_PER_EPOCH=10\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_VALIDATION_STEPS=100\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_TEST_STEPS=100\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_USE_XLA=True\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_USE_AMP=True\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_MAX_SEQ_LENGTH=128\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_FREEZE_BERT_LAYER=False\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m SM_HP_ENABLE_CHECKPOINTING=True\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m /usr/bin/python3 tf_script_bert_tweet.py --enable_checkpointing True --epochs 1 --epsilon 1e-08 --freeze_bert_layer False --learning_rate 1e-05 --max_seq_length 128 --test_batch_size 128 --test_steps 100 --train_batch_size 128 --train_steps_per_epoch 10 --use_amp True --use_xla True --validation_batch_size 128 --validation_steps 100\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.0.43)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.14.8)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.1.91)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.46.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2020.6.8)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.5.2)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.22.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2020.6.8)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: botocore<1.18.0,>=1.17.8 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.17.8)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.5.2)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.1.91)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.0.43)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.14.8)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.25.9)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.22.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.8)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.6.20)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3->transformers==2.8.0) (2.8.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3->transformers==2.8.0) (0.15.2)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.46.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: botocore<1.18.0,>=1.17.8 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.17.8)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.25.9)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.8)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.6.20)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3->transformers==2.8.0) (0.15.2)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3->transformers==2.8.0) (2.8.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: sagemaker-tensorflow==2.1.0.1.0.0 in /usr/local/lib/python3.6/dist-packages (2.1.0.1.0.0)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: sagemaker-tensorflow==2.1.0.1.0.0 in /usr/local/lib/python3.6/dist-packages (2.1.0.1.0.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Collecting smdebug==0.8.0\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Collecting smdebug==0.8.0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m   Downloading smdebug-0.8.0-py2.py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 4.6 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m   Downloading smdebug-0.8.0-py2.py3-none-any.whl (166 kB)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (3.12.2)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (20.4)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (1.18.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: boto3>=1.10.32 in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (1.14.8)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->smdebug==0.8.0) (1.15.0)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 4.6 MB/s eta 0:00:01\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->smdebug==0.8.0) (47.3.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->smdebug==0.8.0) (2.4.7)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: botocore<1.18.0,>=1.17.8 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.10.32->smdebug==0.8.0) (1.17.8)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (1.18.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: boto3>=1.10.32 in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (1.14.8)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (20.4)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (3.12.2)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: botocore<1.18.0,>=1.17.8 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.10.32->smdebug==0.8.0) (1.17.8)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.10.32->smdebug==0.8.0) (0.10.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.10.32->smdebug==0.8.0) (0.3.3)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3>=1.10.32->smdebug==0.8.0) (2.8.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.10.32->smdebug==0.8.0) (0.10.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3>=1.10.32->smdebug==0.8.0) (0.15.2)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.10.32->smdebug==0.8.0) (0.3.3)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->smdebug==0.8.0) (1.15.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3>=1.10.32->smdebug==0.8.0) (1.25.9)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->smdebug==0.8.0) (2.4.7)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->smdebug==0.8.0) (47.3.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3>=1.10.32->smdebug==0.8.0) (2.8.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3>=1.10.32->smdebug==0.8.0) (1.25.9)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.8->boto3>=1.10.32->smdebug==0.8.0) (0.15.2)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Installing collected packages: smdebug\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m   Attempting uninstall: smdebug\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     Found existing installation: smdebug 0.8.1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     Uninstalling smdebug-0.8.1:\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Installing collected packages: smdebug\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m   Attempting uninstall: smdebug\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     Found existing installation: smdebug 0.8.1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m       Successfully uninstalled smdebug-0.8.1\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     Uninstalling smdebug-0.8.1:\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m       Successfully uninstalled smdebug-0.8.1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Successfully installed smdebug-0.8.0\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Successfully installed smdebug-0.8.0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Collecting scikit-learn==0.23.1\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Collecting scikit-learn==0.23.1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m   Downloading scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m   Downloading scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.18.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (0.15.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.4.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Collecting threadpoolctl>=2.0.0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m   Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m   Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.4.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.18.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (0.15.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Installing collected packages: threadpoolctl, scikit-learn\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Installing collected packages: threadpoolctl, scikit-learn\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m   Attempting uninstall: scikit-learn\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     Found existing installation: scikit-learn 0.22\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m   Attempting uninstall: scikit-learn\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     Found existing installation: scikit-learn 0.22\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m     Uninstalling scikit-learn-0.22:\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m     Uninstalling scikit-learn-0.22:\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m       Successfully uninstalled scikit-learn-0.22\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m       Successfully uninstalled scikit-learn-0.22\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Successfully installed scikit-learn-0.23.1 threadpoolctl-2.1.0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Successfully installed scikit-learn-0.23.1 threadpoolctl-2.1.0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Collecting matplotlib==3.2.1\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Collecting matplotlib==3.2.1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m   Downloading matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m   Downloading matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (1.18.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Collecting kiwisolver>=1.0.1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m   Downloading kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88 kB)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m   Downloading kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 9.6 MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 88 kB 7.3 MB/s  eta 0:00:01\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (1.18.1)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (2.4.7)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (2.8.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m \u001b[?25hCollecting cycler>=0.10\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Collecting cycler>=0.10\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m   Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m   Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (2.4.7)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (2.8.1)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib==3.2.1) (1.15.0)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib==3.2.1) (1.15.0)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.2.1\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.2.1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m ################ Args: #######################\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Namespace(checkpoint_base_path='/opt/ml/checkpoints', current_host='algo-2-5h12m', enable_checkpointing=True, epochs=1, epsilon=1e-08, freeze_bert_layer=False, hosts=['algo-1-5h12m', 'algo-2-5h12m'], learning_rate=1e-05, max_seq_length=128, model_dir='/opt/ml/model', num_gpus=0, output_dir='/opt/ml/output', run_sample_predictions=False, run_test=False, run_validation=False, test_batch_size=128, test_data='/opt/ml/input/data/test', test_steps=100, train_batch_size=128, train_data='/opt/ml/input/data/train', train_steps_per_epoch=10, use_amp=True, use_xla=True, validation_batch_size=128, validation_data='/opt/ml/input/data/validation', validation_steps=100)\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m ################ Environment Variables: ################\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m {'AWS_REGION': 'us-west-2',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'CUDA_PKG_VERSION': '10-1=10.1.243-1',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'CUDA_VERSION': '10.1.243',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'CURRENT_HOST': 'algo-2-5h12m',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'DEBCONF_NONINTERACTIVE_SEEN': 'true',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'DEBIAN_FRONTEND': 'noninteractive',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'HOME': '/root',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'HOSTNAME': 'b6f09256965c',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'KMP_AFFINITY': 'granularity=fine,compact,1,0',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'KMP_BLOCKTIME': '1',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'KMP_DUPLICATE_LIB_OK': 'True',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'KMP_INIT_AT_FORK': 'FALSE',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'KMP_SETTINGS': '0',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'LANG': 'C.UTF-8',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'LC_ALL': 'C.UTF-8',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'LD_LIBRARY_PATH': '/usr/local/cuda/lib64/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/openmpi/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'NVIDIA_REQUIRE_CUDA': 'cuda>=10.1 '\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m                         'brand=tesla,driver>=384,driver<385 '\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m                         'brand=tesla,driver>=396,driver<397 '\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m                         'brand=tesla,driver>=410,driver<411',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'NVIDIA_VISIBLE_DEVICES': 'all',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'PATH': '/opt/ml/code:/usr/local/nvidia/bin:/usr/local/openmpi/bin/:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'PYTHONDONTWRITEBYTECODE': 'TRUE',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'PYTHONIOENCODING': 'UTF-8',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'PYTHONPATH': '/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'PYTHONUNBUFFERED': 'TRUE',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'S3_REGION': '',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'S3_USE_HTTPS': '1',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SAGEMAKER_JOB_NAME': '',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SAGEMAKER_PROGRAM': 'tf_script_bert_tweet.py',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SAGEMAKER_REGION': '',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SAGEMAKER_TRAINING_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_CHANNELS': '[\"test\",\"train\",\"validation\"]',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_CHANNEL_TEST': '/opt/ml/input/data/test',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_CHANNEL_VALIDATION': '/opt/ml/input/data/validation',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_CURRENT_HOST': 'algo-2-5h12m',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_FRAMEWORK_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_FRAMEWORK_PARAMS': '{}',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HOSTS': '[\"algo-1-5h12m\",\"algo-2-5h12m\"]',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HPS': '{\"enable_checkpointing\":\"True\",\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":\"False\",\"learning_rate\":1e-05,\"max_seq_length\":128,\"test_batch_size\":128,\"test_steps\":100,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":\"True\",\"use_xla\":\"True\",\"validation_batch_size\":128,\"validation_steps\":100}',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_ENABLE_CHECKPOINTING': 'True',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_EPOCHS': '1',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_EPSILON': '1e-08',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_FREEZE_BERT_LAYER': 'False',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_LEARNING_RATE': '1e-05',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_MAX_SEQ_LENGTH': '128',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_TEST_BATCH_SIZE': '128',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_TEST_STEPS': '100',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_TRAIN_BATCH_SIZE': '128',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_TRAIN_STEPS_PER_EPOCH': '10',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_USE_AMP': 'True',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_USE_XLA': 'True',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_VALIDATION_BATCH_SIZE': '128',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_HP_VALIDATION_STEPS': '100',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_INPUT_DATA_CONFIG': '{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_INPUT_DIR': '/opt/ml/input',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_LOG_LEVEL': '20',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_MODEL_DIR': '/opt/ml/model',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_MODULE_DIR': '/opt/ml/code',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_MODULE_NAME': 'tf_script_bert_tweet',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_NETWORK_INTERFACE_NAME': 'eth0',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_NUM_CPUS': '4',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_NUM_GPUS': '0',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_OUTPUT_DIR': '/opt/ml/output',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-2-5h12m\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"]}',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-2-5h12m\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"],\"hyperparameters\":{\"enable_checkpointing\":\"True\",\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":\"False\",\"learning_rate\":1e-05,\"max_seq_length\":128,\"test_batch_size\":128,\"test_steps\":100,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":\"True\",\"use_xla\":\"True\",\"validation_batch_size\":128,\"validation_steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"bert2tweet-2020-06-28-07-04-50-691\",\"log_level\":20,\"master_hostname\":\"algo-1-5h12m\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2-5h12m\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_USER_ARGS': '[\"--enable_checkpointing\",\"True\",\"--epochs\",\"1\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"1e-05\",\"--max_seq_length\",\"128\",\"--test_batch_size\",\"128\",\"--test_steps\",\"100\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"10\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"100\"]',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'SM_USER_ENTRY_POINT': 'tf_script_bert_tweet.py',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'TERM': 'xterm',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'TF_CPP_MIN_LOG_LEVEL': '1',\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  'TRAINING_JOB_NAME': 'bert2tweet-2020-06-28-07-04-50-691'}\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m ################ Extract varaibles from Command Args #######################\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m is_master True\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m train_data /opt/ml/input/data/train\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m validation_data /opt/ml/input/data/validation\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m test_data /opt/ml/input/data/test\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m local_model_dir /opt/ml/model\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m output_dir /opt/ml/output\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m hosts ['algo-1-5h12m', 'algo-2-5h12m']\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m current_host algo-2-5h12m\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m num_gpus 0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m job_name \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m use_xla True\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m use_amp True\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m max_seq_length 128\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m train_batch_size 128\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m validation_batch_size 128\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m test_batch_size 128\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m epochs 1\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m learning_rate 1e-05\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m epsilon 1e-08\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m train_steps_per_epoch 10\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m validation_steps 100\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m test_steps 100\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m freeze_bert_layer False\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m run_validation False\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m run_test False\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m run_sample_predictions False\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m enable_checkpointing True\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m checkpoint_base_path /opt/ml/checkpoints\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m  ################ Set Checkpoint path: ################\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m checkpoint_path /opt/ml/checkpoints\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Using pipe_mode: False\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m ################ Mirrored distributed_strategy ################\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:05:10.029291: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/openmpi/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:05:10.029328: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m ################ Args: #######################\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Namespace(checkpoint_base_path='/opt/ml/checkpoints', current_host='algo-1-5h12m', enable_checkpointing=True, epochs=1, epsilon=1e-08, freeze_bert_layer=False, hosts=['algo-1-5h12m', 'algo-2-5h12m'], learning_rate=1e-05, max_seq_length=128, model_dir='/opt/ml/model', num_gpus=0, output_dir='/opt/ml/output', run_sample_predictions=False, run_test=False, run_validation=False, test_batch_size=128, test_data='/opt/ml/input/data/test', test_steps=100, train_batch_size=128, train_data='/opt/ml/input/data/train', train_steps_per_epoch=10, use_amp=True, use_xla=True, validation_batch_size=128, validation_data='/opt/ml/input/data/validation', validation_steps=100)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m ################ Environment Variables: ################\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m {'AWS_REGION': 'us-west-2',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'CUDA_PKG_VERSION': '10-1=10.1.243-1',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'CUDA_VERSION': '10.1.243',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'CURRENT_HOST': 'algo-1-5h12m',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'DEBCONF_NONINTERACTIVE_SEEN': 'true',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'DEBIAN_FRONTEND': 'noninteractive',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'HOME': '/root',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'HOSTNAME': '0b409f546fc4',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'KMP_AFFINITY': 'granularity=fine,compact,1,0',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'KMP_BLOCKTIME': '1',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'KMP_DUPLICATE_LIB_OK': 'True',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'KMP_INIT_AT_FORK': 'FALSE',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'KMP_SETTINGS': '0',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'LANG': 'C.UTF-8',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'LC_ALL': 'C.UTF-8',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'LD_LIBRARY_PATH': '/usr/local/cuda/lib64/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/openmpi/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'NVIDIA_REQUIRE_CUDA': 'cuda>=10.1 '\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m                         'brand=tesla,driver>=384,driver<385 '\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m                         'brand=tesla,driver>=396,driver<397 '\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m                         'brand=tesla,driver>=410,driver<411',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'NVIDIA_VISIBLE_DEVICES': 'all',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'PATH': '/opt/ml/code:/usr/local/nvidia/bin:/usr/local/openmpi/bin/:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'PYTHONDONTWRITEBYTECODE': 'TRUE',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'PYTHONIOENCODING': 'UTF-8',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'PYTHONPATH': '/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'PYTHONUNBUFFERED': 'TRUE',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'S3_REGION': '',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'S3_USE_HTTPS': '1',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SAGEMAKER_JOB_NAME': '',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SAGEMAKER_PROGRAM': 'tf_script_bert_tweet.py',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SAGEMAKER_REGION': '',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SAGEMAKER_TRAINING_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_CHANNELS': '[\"test\",\"train\",\"validation\"]',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_CHANNEL_TEST': '/opt/ml/input/data/test',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_CHANNEL_VALIDATION': '/opt/ml/input/data/validation',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_CURRENT_HOST': 'algo-1-5h12m',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_FRAMEWORK_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_FRAMEWORK_PARAMS': '{}',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HOSTS': '[\"algo-1-5h12m\",\"algo-2-5h12m\"]',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HPS': '{\"enable_checkpointing\":\"True\",\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":\"False\",\"learning_rate\":1e-05,\"max_seq_length\":128,\"test_batch_size\":128,\"test_steps\":100,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":\"True\",\"use_xla\":\"True\",\"validation_batch_size\":128,\"validation_steps\":100}',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_ENABLE_CHECKPOINTING': 'True',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_EPOCHS': '1',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_EPSILON': '1e-08',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_FREEZE_BERT_LAYER': 'False',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_LEARNING_RATE': '1e-05',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_MAX_SEQ_LENGTH': '128',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_TEST_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_TEST_STEPS': '100',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_TRAIN_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_TRAIN_STEPS_PER_EPOCH': '10',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_USE_AMP': 'True',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_USE_XLA': 'True',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_VALIDATION_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_HP_VALIDATION_STEPS': '100',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_INPUT_DATA_CONFIG': '{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_INPUT_DIR': '/opt/ml/input',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_LOG_LEVEL': '20',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_MODEL_DIR': '/opt/ml/model',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_MODULE_DIR': '/opt/ml/code',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_MODULE_NAME': 'tf_script_bert_tweet',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_NETWORK_INTERFACE_NAME': 'eth0',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_NUM_CPUS': '4',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_NUM_GPUS': '0',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_OUTPUT_DIR': '/opt/ml/output',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-5h12m\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"]}',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-5h12m\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"],\"hyperparameters\":{\"enable_checkpointing\":\"True\",\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":\"False\",\"learning_rate\":1e-05,\"max_seq_length\":128,\"test_batch_size\":128,\"test_steps\":100,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":\"True\",\"use_xla\":\"True\",\"validation_batch_size\":128,\"validation_steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bert2tweet-2020-06-28-07-04-50-691\",\"log_level\":20,\"master_hostname\":\"algo-1-5h12m\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-5h12m\",\"hosts\":[\"algo-1-5h12m\",\"algo-2-5h12m\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_USER_ARGS': '[\"--enable_checkpointing\",\"True\",\"--epochs\",\"1\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"1e-05\",\"--max_seq_length\",\"128\",\"--test_batch_size\",\"128\",\"--test_steps\",\"100\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"10\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"100\"]',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'SM_USER_ENTRY_POINT': 'tf_script_bert_tweet.py',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'TERM': 'xterm',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'TF_CPP_MIN_LOG_LEVEL': '1',\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  'TRAINING_JOB_NAME': 'bert2tweet-2020-06-28-07-04-50-691'}\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m ################ Extract varaibles from Command Args #######################\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m is_master True\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m train_data /opt/ml/input/data/train\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m validation_data /opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m test_data /opt/ml/input/data/test\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m local_model_dir /opt/ml/model\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m output_dir /opt/ml/output\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m hosts ['algo-1-5h12m', 'algo-2-5h12m']\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m current_host algo-1-5h12m\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m num_gpus 0\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m job_name \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m use_xla True\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m use_amp True\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m max_seq_length 128\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m train_batch_size 128\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m validation_batch_size 128\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m test_batch_size 128\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m epochs 1\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m learning_rate 1e-05\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m epsilon 1e-08\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m train_steps_per_epoch 10\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m validation_steps 100\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m test_steps 100\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m freeze_bert_layer False\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m run_validation False\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m run_test False\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m run_sample_predictions False\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m enable_checkpointing True\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m checkpoint_base_path /opt/ml/checkpoints\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m  ################ Set Checkpoint path: ################\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m checkpoint_path /opt/ml/checkpoints\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Using pipe_mode: False\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m ################ Mirrored distributed_strategy ################\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:05:10.044740: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/openmpi/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:05:10.044784: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m train_data_filenames ['/opt/ml/input/data/train/part-unknown-tweet_file_01.tfrecord', '/opt/ml/input/data/train/part-unknown-tweet_file_02.tfrecord']\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m ***** Using input_filenames ['/opt/ml/input/data/train/part-unknown-tweet_file_01.tfrecord', '/opt/ml/input/data/train/part-unknown-tweet_file_02.tfrecord']\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m train_data_filenames ['/opt/ml/input/data/train/part-unknown-tweet_file_01.tfrecord', '/opt/ml/input/data/train/part-unknown-tweet_file_02.tfrecord']\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m ***** Using input_filenames ['/opt/ml/input/data/train/part-unknown-tweet_file_01.tfrecord', '/opt/ml/input/data/train/part-unknown-tweet_file_02.tfrecord']\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:From tf_script_bert_tweet.py:89: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:From tf_script_bert_tweet.py:89: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 954kB/s] \n",
      "Downloading: 100% 232k/232k [00:00<00:00, 852kB/s] \n",
      "Downloading: 100% 442/442 [00:00<00:00, 320kB/s]\n",
      "Downloading: 100% 442/442 [00:00<00:00, 307kB/s]\n",
      "Downloading: 100% 363M/363M [00:16<00:00, 21.9MB/s] \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:05:29.309465: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Downloading: 100% 363M/363M [00:16<00:00, 21.6MB/s] \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:05:29.541418: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Sucessfully downloaded after 0 retries.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m ***** Checkpoint enabled *****\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m *** CHECKPOINT CALLBACK <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4408766d68> ***\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m ** use_amp True\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m *** OPTIMIZER <tensorflow.python.keras.mixed_precision.experimental.loss_scale_optimizer.LossScaleOptimizer object at 0x7f44087e11d0> ***\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Compiled model <transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification object at 0x7f44087a10f0>\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m distilbert (TFDistilBertMain multiple                  66362880  \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m pre_classifier (Dense)       multiple                  590592    \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m classifier (Dense)           multiple                  7690      \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m dropout_19 (Dropout)         multiple                  0         \n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Total params: 66,961,162\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Trainable params: 66,961,162\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Non-trainable params: 0\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m None\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Starting Training (Without Validation)...\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Sucessfully downloaded after 0 retries.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m ***** Checkpoint enabled *****\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m *** CHECKPOINT CALLBACK <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5bfc115390> ***\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m ** use_amp True\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m *** OPTIMIZER <tensorflow.python.keras.mixed_precision.experimental.loss_scale_optimizer.LossScaleOptimizer object at 0x7f5bfc155208> ***\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Compiled model <transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification object at 0x7f5bfc0ca518>\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m =================================================================\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m distilbert (TFDistilBertMain multiple                  66362880  \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m pre_classifier (Dense)       multiple                  590592    \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m classifier (Dense)           multiple                  7690      \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m dropout_19 (Dropout)         multiple                  0         \n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m =================================================================\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Total params: 66,961,162\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Trainable params: 66,961,162\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Non-trainable params: 0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m None\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Starting Training (Without Validation)...\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Train for 10 steps\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Train for 10 steps\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:05:51.359935: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1892] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:05:52.783957: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1892] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:05:52.969561: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1574] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:05:55.054041: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1574] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      " 9/10 [==========================>...] - ETA: 1:29 - loss: 2.2139 - accuracy: 0.2157\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Epoch 00001: saving model to /opt/ml/checkpoints/tf_model_00001.h5\n",
      "10/10 [==============================] - 893s 89s/step - loss: 2.2068 - accuracy: 0.2168\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:20:30.662310: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m <tensorflow.python.keras.callbacks.History object at 0x7f43c9f0b8d0>\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m ########  Save the Fine-Yuned Transformers Model as a New Pre-Trained Model ##########\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m transformer_fine_tuned_model_path /opt/ml/model/transformers/fine-tuned/\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m INFO:transformers.configuration_utils:Configuration saved in /opt/ml/model/transformers/fine-tuned/config.json\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m INFO:transformers.modeling_tf_utils:Model weights saved in /opt/ml/model/transformers/fine-tuned/tf_model.h5\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m ########  Save the TensorFlow SavedModel for Serving Predictions Model ##########\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m tensorflow_saved_model_path /opt/ml/model/tensorflow/saved_model/0\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4408766eb8>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4408766eb8>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4408734710>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4408734710>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4400703dd8>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4400703dd8>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f440071f4e0>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f440071f4e0>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4400354ba8>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4400354ba8>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4408785278>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f4408785278>, because it is not built.\n",
      " 9/10 [==========================>...] - ETA: 1:31 - loss: 2.2422 - accuracy: 0.1875\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Epoch 00001: saving model to /opt/ml/checkpoints/tf_model_00001.h5\n",
      "10/10 [==============================] - 907s 91s/step - loss: 2.2351 - accuracy: 0.1914\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m 2020-06-28 07:20:44.378571: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m <tensorflow.python.keras.callbacks.History object at 0x7f5bc80668d0>\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m ########  Save the Fine-Yuned Transformers Model as a New Pre-Trained Model ##########\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m transformer_fine_tuned_model_path /opt/ml/model/transformers/fine-tuned/\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m INFO:transformers.configuration_utils:Configuration saved in /opt/ml/model/transformers/fine-tuned/config.json\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m INFO:transformers.modeling_tf_utils:Model weights saved in /opt/ml/model/transformers/fine-tuned/tf_model.h5\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m ########  Save the TensorFlow SavedModel for Serving Predictions Model ##########\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m tensorflow_saved_model_path /opt/ml/model/tensorflow/saved_model/0\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bfc073c88>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bfc073c88>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bec068710>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bec068710>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bfc092dd8>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bfc092dd8>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bfc0ac4e0>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bfc0ac4e0>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bc9495ba8>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bc9495ba8>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bfc0f9278>, because it is not built.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f5bfc0f9278>, because it is not built.\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/tensorflow/saved_model/0/assets\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/tensorflow/saved_model/0/assets\n",
      "\u001b[36malgo-1-5h12m_1  |\u001b[0m 2020-06-28 07:20:50,301 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/tensorflow/saved_model/0/assets\n",
      "\u001b[33malgo-2-5h12m_1  |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/tensorflow/saved_model/0/assets\n",
      "\u001b[36mtmp_ocg58_6_algo-1-5h12m_1 exited with code 0\n",
      "\u001b[0mStopping tmp_ocg58_6_algo-2-5h12m_1 ... \n",
      "\u001b[1BAborting on container exit..._1 ... \u001b[32mdone\u001b[0m\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "# inputs={'train': s3_input_train_data, \n",
    "#         'validation': s3_input_validation_data,\n",
    "#          'test': s3_input_test_data\n",
    "#               }\n",
    "inputs = {'train': f'file://{train_dir}',\n",
    "          'validation': f'file://{validation_dir}',\n",
    "          'test': f'file://{test_dir}'}\n",
    "\n",
    "estimator.fit(inputs,)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
