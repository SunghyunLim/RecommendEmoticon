{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.2.1] Inference Custom Docker Image 생성 및 ECR 퍼블리시\n",
    "\n",
    "이 노트북은 Docker 이미지를 생성하고, Amazon ECR(Elastic Container Registry)에 퍼블리스를 합니다.\n",
    "SageMaker 는 Custom Tensorflow Serving 이미지를 만들 수 있게 필요한 리소스(Dockerfile등)을 제공 합니다.\n",
    "\n",
    "아래와 같은 작업을 진행 합니다.\n",
    "- [SageMaker TensorFlow Serving Container](https://github.com/aws/sagemaker-tensorflow-serving-container) 을 Git Clone을 하여 다운로드 (**이 과정은 이미 다운로드 하여 현재의 Git 복사가 되어 있어서 생략 합니다.**)\n",
    "- 주어지는 여러가지 버전의 Dockerfile 중에서 2.0-cpu 를 사용\n",
    "    - 다른 버전을 사용하셔도 됩니다.(예: 2.0-gpu)\n",
    "- 필요한 Package인 tensorflow:2.1.0 과 transformers:2.8.0을 추가\n",
    "- docker image를 빌드\n",
    "- ECR에 퍼블리시\n",
    "\n",
    "\n",
    "---\n",
    "노트북의 소요 시간은 약 10분 걸립니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker TensorFlow Serving Container 다운로드\n",
    "**이 부분은 이미 다운로드 했기에 진행하지 않습니다.**\n",
    "\n",
    "* https://github.com/aws/sagemaker-tensorflow-serving-container\n",
    "```\n",
    "# ! git clone https://github.com/aws/sagemaker-tensorflow-serving-container\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile 수정 (tfs:2.0-cpu)\n",
    "다운로드 받은 폴더에서 아래 파일을 수정 하겠습니다.\n",
    "- sagemaker-tensorflow-serving-container/docker/2.0/Dockerfile.cpu\n",
    "- Dockerfile 안에 아래를 추가 하겠습니다.\n",
    "```\n",
    "#################\n",
    "# 추가 사항\n",
    "# Install tensorflow 2.1 and transformer\n",
    "#################\n",
    "RUN ${PIP} install --no-cache-dir \\\n",
    "    tensorflow==2.1.0 \\\n",
    "    transformers==2.8.0\n",
    "#################\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sagemaker-tensorflow-serving-container/docker/2.0/Dockerfile.cpu\n"
     ]
    }
   ],
   "source": [
    "%%writefile sagemaker-tensorflow-serving-container/docker/2.0/Dockerfile.cpu \n",
    "\n",
    "FROM ubuntu:18.04\n",
    "\n",
    "LABEL maintainer=\"Amazon AI\"\n",
    "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "ARG PYTHON=python3\n",
    "ARG PIP=pip3\n",
    "ARG TFS_SHORT_VERSION=2.0.1\n",
    "ARG TFS_URL=https://tensorflow-aws.s3-us-west-2.amazonaws.com/${TFS_SHORT_VERSION}/Serving/CPU-WITH-MKL/tensorflow_model_server\n",
    "\n",
    "# See http://bugs.python.org/issue19846\n",
    "ENV LANG=C.UTF-8\n",
    "# Python won’t try to write .pyc or .pyo files on the import of source modules\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV SAGEMAKER_TFS_VERSION=\"${TFS_SHORT_VERSION}\"\n",
    "ENV PATH=\"$PATH:/sagemaker\"\n",
    "ENV LD_LIBRARY_PATH='/usr/local/lib:$LD_LIBRARY_PATH'\n",
    "ENV MODEL_BASE_PATH=/models\n",
    "# The only required piece is the model name in order to differentiate endpoints\n",
    "ENV MODEL_NAME=model\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "# nginx + njs\n",
    "RUN apt-get update \\\n",
    " && apt-get -y install --no-install-recommends \\\n",
    "    curl \\\n",
    "    gnupg2 \\\n",
    "    ca-certificates \\\n",
    "    git \\\n",
    "    wget \\\n",
    "    vim \\\n",
    "    build-essential \\\n",
    "    zlib1g-dev \\\n",
    " && curl -s http://nginx.org/keys/nginx_signing.key | apt-key add - \\\n",
    " && echo 'deb http://nginx.org/packages/ubuntu/ bionic nginx' >> /etc/apt/sources.list \\\n",
    " && apt-get update \\\n",
    " && apt-get -y install --no-install-recommends \\\n",
    "    nginx \\\n",
    "    nginx-module-njs \\\n",
    "    python3 \\\n",
    "    python3-pip \\\n",
    "    python3-setuptools \\\n",
    " && apt-get clean \\\n",
    " && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN ${PIP} --no-cache-dir install --upgrade pip setuptools\n",
    "\n",
    "# cython, falcon, gunicorn, grpc\n",
    "RUN ${PIP} install --no-cache-dir \\\n",
    "    awscli==1.16.303 \\\n",
    "    cython==0.29.14 \\\n",
    "    falcon==2.0.0 \\\n",
    "    gunicorn==20.0.4 \\\n",
    "    gevent==1.4.0 \\\n",
    "    requests==2.22.0 \\\n",
    "    grpcio==1.26.0 \\\n",
    "    protobuf==3.11.1 \\\n",
    "# using --no-dependencies to avoid installing tensorflow binary\n",
    " && ${PIP} install --no-dependencies --no-cache-dir \\\n",
    "    tensorflow-serving-api==2.0\n",
    "\n",
    "#################\n",
    "# 추가 사항\n",
    "# Install tensorflow 2.1 and transformer\n",
    "#################\n",
    "RUN ${PIP} install --no-cache-dir \\\n",
    "    tensorflow==2.1.0 \\\n",
    "    transformers==2.8.0\n",
    "#################\n",
    "\n",
    "\n",
    "COPY ./sagemaker /sagemaker\n",
    "\n",
    "# Some TF tools expect a \"python\" binary\n",
    "RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
    "\n",
    "RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libiomp5.so -o /usr/local/lib/libiomp5.so\n",
    "RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libmklml_intel.so -o /usr/local/lib/libmklml_intel.so\n",
    "\n",
    "RUN curl $TFS_URL -o /usr/bin/tensorflow_model_server \\\n",
    " && chmod 555 /usr/bin/tensorflow_model_server\n",
    "\n",
    "# Expose ports\n",
    "# gRPC and REST\n",
    "EXPOSE 8500 8501\n",
    "\n",
    "# Set where models should be stored in the container\n",
    "RUN mkdir -p ${MODEL_BASE_PATH}\n",
    "\n",
    "# Create a script that runs the model server so we can use environment variables\n",
    "# while also passing in arguments from the docker command line\n",
    "RUN echo '#!/bin/bash \\n\\n' > /usr/bin/tf_serving_entrypoint.sh \\\n",
    " && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"' >> /usr/bin/tf_serving_entrypoint.sh \\\n",
    " && chmod +x /usr/bin/tf_serving_entrypoint.sh\n",
    "\n",
    "ADD https://raw.githubusercontent.com/aws/aws-deep-learning-containers-utils/master/deep_learning_container.py /usr/local/bin/deep_learning_container.py\n",
    "\n",
    "RUN chmod +x /usr/local/bin/deep_learning_container.py\n",
    "\n",
    "RUN curl https://aws-dlc-licenses.s3.amazonaws.com/tensorflow-2.0.1/license.txt -o /license.txt\n",
    "\n",
    "CMD [\"/usr/bin/tf_serving_entrypoint.sh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custome Docker 생성\n",
    "아래 셀 스크립트를 실행하면 이미지가 생성이 됩니다. \n",
    "```\n",
    "./scripts/build.sh --version 2.0.0 --arch cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_version = \"2.0.0\"\n",
    "cpu_type = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling previous image for layer cache... \n",
      "building image... \n",
      "Sending build context to Docker daemon  88.58kB\n",
      "Step 1/32 : FROM ubuntu:18.04\n",
      " ---> 2eb2d388e1a2\n",
      "Step 2/32 : LABEL maintainer=\"Amazon AI\"\n",
      " ---> Using cache\n",
      " ---> c961c04d3240\n",
      "Step 3/32 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> 1d0cee56648e\n",
      "Step 4/32 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> 3334f2a6dcc9\n",
      "Step 5/32 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> cd8b503fe2b9\n",
      "Step 6/32 : ARG TFS_SHORT_VERSION=2.0.1\n",
      " ---> Using cache\n",
      " ---> baeb3fba08af\n",
      "Step 7/32 : ARG TFS_URL=https://tensorflow-aws.s3-us-west-2.amazonaws.com/${TFS_SHORT_VERSION}/Serving/CPU-WITH-MKL/tensorflow_model_server\n",
      " ---> Using cache\n",
      " ---> ff7d43dd4b17\n",
      "Step 8/32 : ENV LANG=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> e4e3b44c6d13\n",
      "Step 9/32 : ENV PYTHONDONTWRITEBYTECODE=1\n",
      " ---> Using cache\n",
      " ---> 814ea2e34901\n",
      "Step 10/32 : ENV PYTHONUNBUFFERED=1\n",
      " ---> Using cache\n",
      " ---> 5420d149880e\n",
      "Step 11/32 : ENV SAGEMAKER_TFS_VERSION=\"${TFS_SHORT_VERSION}\"\n",
      " ---> Using cache\n",
      " ---> fda012249276\n",
      "Step 12/32 : ENV PATH=\"$PATH:/sagemaker\"\n",
      " ---> Using cache\n",
      " ---> 3b1d5633b44d\n",
      "Step 13/32 : ENV LD_LIBRARY_PATH='/usr/local/lib:$LD_LIBRARY_PATH'\n",
      " ---> Using cache\n",
      " ---> cd8ca634fca2\n",
      "Step 14/32 : ENV MODEL_BASE_PATH=/models\n",
      " ---> Using cache\n",
      " ---> 1011b18dfd92\n",
      "Step 15/32 : ENV MODEL_NAME=model\n",
      " ---> Using cache\n",
      " ---> 64a688f735b7\n",
      "Step 16/32 : ENV DEBIAN_FRONTEND=noninteractive\n",
      " ---> Using cache\n",
      " ---> 0d0adefcfb1c\n",
      "Step 17/32 : RUN apt-get update  && apt-get -y install --no-install-recommends     curl     gnupg2     ca-certificates     git     wget     vim     build-essential     zlib1g-dev  && curl -s http://nginx.org/keys/nginx_signing.key | apt-key add -  && echo 'deb http://nginx.org/packages/ubuntu/ bionic nginx' >> /etc/apt/sources.list  && apt-get update  && apt-get -y install --no-install-recommends     nginx     nginx-module-njs     python3     python3-pip     python3-setuptools  && apt-get clean  && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 6efb4a8e3ea7\n",
      "Step 18/32 : RUN ${PIP} --no-cache-dir install --upgrade pip setuptools\n",
      " ---> Using cache\n",
      " ---> b7ffb877dfe9\n",
      "Step 19/32 : RUN ${PIP} install --no-cache-dir     awscli==1.16.303     cython==0.29.14     falcon==2.0.0     gunicorn==20.0.4     gevent==1.4.0     requests==2.22.0     grpcio==1.26.0     protobuf==3.11.1  && ${PIP} install --no-dependencies --no-cache-dir     tensorflow-serving-api==2.0\n",
      " ---> Using cache\n",
      " ---> fd698733a2d9\n",
      "Step 20/32 : RUN ${PIP} install --no-cache-dir     tensorflow==2.1.0     transformers==2.8.0\n",
      " ---> Using cache\n",
      " ---> 94662a35e304\n",
      "Step 21/32 : COPY ./sagemaker /sagemaker\n",
      " ---> Using cache\n",
      " ---> b362eba0f245\n",
      "Step 22/32 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 486db133998a\n",
      "Step 23/32 : RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libiomp5.so -o /usr/local/lib/libiomp5.so\n",
      " ---> Using cache\n",
      " ---> 3fb35e28f953\n",
      "Step 24/32 : RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libmklml_intel.so -o /usr/local/lib/libmklml_intel.so\n",
      " ---> Using cache\n",
      " ---> 169146d38f55\n",
      "Step 25/32 : RUN curl $TFS_URL -o /usr/bin/tensorflow_model_server  && chmod 555 /usr/bin/tensorflow_model_server\n",
      " ---> Using cache\n",
      " ---> bf1311639732\n",
      "Step 26/32 : EXPOSE 8500 8501\n",
      " ---> Using cache\n",
      " ---> 7773b2014762\n",
      "Step 27/32 : RUN mkdir -p ${MODEL_BASE_PATH}\n",
      " ---> Using cache\n",
      " ---> bc2c050fd4e0\n",
      "Step 28/32 : RUN echo '#!/bin/bash \\n\\n' > /usr/bin/tf_serving_entrypoint.sh  && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"' >> /usr/bin/tf_serving_entrypoint.sh  && chmod +x /usr/bin/tf_serving_entrypoint.sh\n",
      " ---> Using cache\n",
      " ---> db154af70dc5\n",
      "Step 29/32 : ADD https://raw.githubusercontent.com/aws/aws-deep-learning-containers-utils/master/deep_learning_container.py /usr/local/bin/deep_learning_container.py\n",
      "\n",
      " ---> Using cache\n",
      " ---> 78daeaacf152\n",
      "Step 30/32 : RUN chmod +x /usr/local/bin/deep_learning_container.py\n",
      " ---> Using cache\n",
      " ---> dcb5ececb225\n",
      "Step 31/32 : RUN curl https://aws-dlc-licenses.s3.amazonaws.com/tensorflow-2.0.1/license.txt -o /license.txt\n",
      " ---> Using cache\n",
      " ---> 1bcefc12eeb9\n",
      "Step 32/32 : CMD [\"/usr/bin/tf_serving_entrypoint.sh\"]\n",
      " ---> Using cache\n",
      " ---> b59c20772b2d\n",
      "[Warning] One or more build-args [TFS_VERSION] were not consumed\n",
      "Successfully built b59c20772b2d\n",
      "Successfully tagged sagemaker-tensorflow-serving:2.0.0-cpu\n",
      "Successfully tagged sagemaker-tensorflow-serving:2.0-cpu\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {region} {tfs_version} {cpu_type}\n",
    "\n",
    "AWS_DEFAULT_REGION=$1\n",
    "export AWS_DEFAULT_REGION\n",
    "TFS_VERION=$2\n",
    "CPU_TYPE=$3\n",
    "\n",
    "cd sagemaker-tensorflow-serving-container\n",
    "\n",
    "./scripts/build.sh --version $TFS_VERION --arch $CPU_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Serving:2.0.0-cpu 를 ECR에 퍼블리시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 셀 스크립트를 실행하면 위에서 생성한 이미지가 ECR에 퍼블리시 됩니다.\n",
    "```\n",
    "./scripts/publish.sh --version 1.13 --arch cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 (2020/07) ECR에 해당 이미지가 없으면  publish.sh 에서 에러가 발생하여 아래 코드 추가 함\n",
    "```\n",
    "aws ecr describe-repositories --repository-names $repository > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name $repository > /dev/null\n",
    "fi\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sagemaker-tensorflow-serving-container/scripts/publish.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile sagemaker-tensorflow-serving-container/scripts/publish.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#\n",
    "# Publish images to your ECR account.\n",
    "\n",
    "# 기존 소스에서 아래 주석 처리 함\n",
    "# set -euo pipefail\n",
    "\n",
    "source scripts/shared.sh\n",
    "\n",
    "parse_std_args \"$@\"\n",
    "\n",
    "aws ecr get-login-password --region ${aws_region} \\\n",
    "    | docker login \\\n",
    "        --password-stdin \\\n",
    "        --username AWS \\\n",
    "        \"${aws_account}.dkr.ecr.${aws_region}.amazonaws.com/${repository}\"\n",
    "\n",
    "aws ecr describe-repositories --repository-names $repository > /dev/null 2>&1\n",
    "\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name $repository > /dev/null\n",
    "fi\n",
    "\n",
    "docker tag $repository:$full_version-$device $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$full_version-$device\n",
    "docker tag $repository:$full_version-$device $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$short_version-$device\n",
    "docker push $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$full_version-$device\n",
    "docker push $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$short_version-$device\n",
    "docker logout https://$aws_account.dkr.ecr.$aws_region.amazonaws.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving]\n",
      "c199d5ed61b3: Preparing\n",
      "da7aeb116caf: Preparing\n",
      "a44da842b64a: Preparing\n",
      "a8eb1b1cfaa5: Preparing\n",
      "041a151aec69: Preparing\n",
      "a66d80c62c48: Preparing\n",
      "3b0b9f2a71bd: Preparing\n",
      "7359a30e430f: Preparing\n",
      "0139c615f94b: Preparing\n",
      "d4caed3a0029: Preparing\n",
      "1c314df8e01d: Preparing\n",
      "42ed2a654b21: Preparing\n",
      "a6f6a25f874c: Preparing\n",
      "b3b617b03c51: Preparing\n",
      "8682f9a74649: Preparing\n",
      "d3a6da143c91: Preparing\n",
      "83f4287e1f04: Preparing\n",
      "7ef368776582: Preparing\n",
      "7359a30e430f: Waiting\n",
      "a66d80c62c48: Waiting\n",
      "1c314df8e01d: Waiting\n",
      "0139c615f94b: Waiting\n",
      "d4caed3a0029: Waiting\n",
      "3b0b9f2a71bd: Waiting\n",
      "d3a6da143c91: Waiting\n",
      "a6f6a25f874c: Waiting\n",
      "b3b617b03c51: Waiting\n",
      "83f4287e1f04: Waiting\n",
      "7ef368776582: Waiting\n",
      "da7aeb116caf: Layer already exists\n",
      "a8eb1b1cfaa5: Layer already exists\n",
      "a44da842b64a: Layer already exists\n",
      "c199d5ed61b3: Layer already exists\n",
      "041a151aec69: Layer already exists\n",
      "a66d80c62c48: Layer already exists\n",
      "3b0b9f2a71bd: Layer already exists\n",
      "7359a30e430f: Layer already exists\n",
      "0139c615f94b: Layer already exists\n",
      "1c314df8e01d: Layer already exists\n",
      "d4caed3a0029: Layer already exists\n",
      "42ed2a654b21: Layer already exists\n",
      "a6f6a25f874c: Layer already exists\n",
      "b3b617b03c51: Layer already exists\n",
      "8682f9a74649: Layer already exists\n",
      "d3a6da143c91: Layer already exists\n",
      "83f4287e1f04: Layer already exists\n",
      "7ef368776582: Layer already exists\n",
      "2.0.0-cpu: digest: sha256:3f08604cbfbf1cda66d65519c6224401722d9b68ef237a129a9e4da7948c0ce8 size: 4090\n",
      "The push refers to repository [343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving]\n",
      "c199d5ed61b3: Preparing\n",
      "da7aeb116caf: Preparing\n",
      "a44da842b64a: Preparing\n",
      "a8eb1b1cfaa5: Preparing\n",
      "041a151aec69: Preparing\n",
      "a66d80c62c48: Preparing\n",
      "3b0b9f2a71bd: Preparing\n",
      "7359a30e430f: Preparing\n",
      "0139c615f94b: Preparing\n",
      "d4caed3a0029: Preparing\n",
      "1c314df8e01d: Preparing\n",
      "42ed2a654b21: Preparing\n",
      "a6f6a25f874c: Preparing\n",
      "b3b617b03c51: Preparing\n",
      "8682f9a74649: Preparing\n",
      "d3a6da143c91: Preparing\n",
      "83f4287e1f04: Preparing\n",
      "7ef368776582: Preparing\n",
      "a66d80c62c48: Waiting\n",
      "42ed2a654b21: Waiting\n",
      "a6f6a25f874c: Waiting\n",
      "3b0b9f2a71bd: Waiting\n",
      "b3b617b03c51: Waiting\n",
      "7359a30e430f: Waiting\n",
      "8682f9a74649: Waiting\n",
      "0139c615f94b: Waiting\n",
      "d3a6da143c91: Waiting\n",
      "d4caed3a0029: Waiting\n",
      "83f4287e1f04: Waiting\n",
      "1c314df8e01d: Waiting\n",
      "a44da842b64a: Layer already exists\n",
      "a8eb1b1cfaa5: Layer already exists\n",
      "da7aeb116caf: Layer already exists\n",
      "c199d5ed61b3: Layer already exists\n",
      "041a151aec69: Layer already exists\n",
      "a66d80c62c48: Layer already exists\n",
      "3b0b9f2a71bd: Layer already exists\n",
      "7359a30e430f: Layer already exists\n",
      "0139c615f94b: Layer already exists\n",
      "d4caed3a0029: Layer already exists\n",
      "1c314df8e01d: Layer already exists\n",
      "42ed2a654b21: Layer already exists\n",
      "a6f6a25f874c: Layer already exists\n",
      "8682f9a74649: Layer already exists\n",
      "b3b617b03c51: Layer already exists\n",
      "83f4287e1f04: Layer already exists\n",
      "d3a6da143c91: Layer already exists\n",
      "7ef368776582: Layer already exists\n",
      "2.0-cpu: digest: sha256:3f08604cbfbf1cda66d65519c6224401722d9b68ef237a129a9e4da7948c0ce8 size: 4090\n",
      "Removing login credentials for 343441690612.dkr.ecr.ap-northeast-2.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {region} {tfs_version} {cpu_type}\n",
    "\n",
    "AWS_DEFAULT_REGION=$1\n",
    "export AWS_DEFAULT_REGION\n",
    "TFS_VERION=$2\n",
    "CPU_TYPE=$3\n",
    "\n",
    "cd sagemaker-tensorflow-serving-container\n",
    "\n",
    "./scripts/publish.sh --version $TFS_VERION --arch $CPU_TYPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Inference Image 저장\n",
    "<font color=\"red\">아래의 그림처럼 계정 및 지역이 다르다면 수정해야 합니다.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ecr-infer-container](img/ecr-infer-container.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecr_infer_custom_image_tf_serving_20_cpu: \n",
      " 343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:2.0.0-cpu\n"
     ]
    }
   ],
   "source": [
    "account = '343441690612'\n",
    "ecr_infer_custom_image_tf_serving_20_cpu = '{}.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:{}-{}'.format(\n",
    "    account,\n",
    "    tfs_version,\n",
    "    cpu_type\n",
    ")\n",
    "print(\"ecr_infer_custom_image_tf_serving_20_cpu: \\n\", ecr_infer_custom_image_tf_serving_20_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 다음 노트북에서 사용하기 위하여 저장 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ecr_infer_custom_image_tf_serving_20_cpu' (str)\n"
     ]
    }
   ],
   "source": [
    "%store ecr_infer_custom_image_tf_serving_20_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
