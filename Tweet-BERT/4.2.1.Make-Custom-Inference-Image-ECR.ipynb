{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.2.1] Inference Custom Docker Image 생성 및 ECR 퍼블리시\n",
    "\n",
    "이 노트북은 Docker 이미지를 생성하고, Amazon ECR(Elastic Container Registry)에 퍼블리스를 합니다.\n",
    "SageMaker 는 Custom Tensorflow Serving 이미지를 만들 수 있게 필요한 리소스(Dockerfile등)을 제공 합니다.\n",
    "\n",
    "아래와 같은 작업을 진행 합니다.\n",
    "- [SageMaker TensorFlow Serving Container](https://github.com/aws/sagemaker-tensorflow-serving-container) 을 Git Clone을 하여 다운로드 (**이 과정은 이미 다운로드 하여 현재의 Git 복사가 되어 있어서 생략 합니다.**)\n",
    "- 주어지는 여러가지 버전의 Dockerfile 중에서 2.0-cpu 를 사용\n",
    "    - 다른 버전을 사용하셔도 됩니다.(예: 2.0-gpu)\n",
    "- 필요한 Package인 tensorflow:2.1.0 과 transformers:2.8.0을 추가\n",
    "- docker image를 빌드\n",
    "- ECR에 퍼블리시\n",
    "\n",
    "\n",
    "---\n",
    "노트북의 소요 시간은 약 10분 걸립니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker TensorFlow Serving Container 다운로드\n",
    "**이 부분은 이미 다운로드 했기에 진행하지 않습니다.**\n",
    "\n",
    "* https://github.com/aws/sagemaker-tensorflow-serving-container\n",
    "```\n",
    "# ! git clone https://github.com/aws/sagemaker-tensorflow-serving-container\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile 수정 (tfs:2.0-cpu)\n",
    "다운로드 받은 폴더에서 아래 파일을 수정 하겠습니다.\n",
    "- sagemaker-tensorflow-serving-container/docker/2.0/Dockerfile.cpu\n",
    "- Dockerfile 안에 아래를 추가 하겠습니다.\n",
    "```\n",
    "#################\n",
    "# 추가 사항\n",
    "# Install tensorflow 2.1 and transformer\n",
    "#################\n",
    "RUN ${PIP} install --no-cache-dir \\\n",
    "    tensorflow==2.1.0 \\\n",
    "    transformers==2.8.0\n",
    "#################\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sagemaker-tensorflow-serving-container/docker/2.0/Dockerfile.cpu\n"
     ]
    }
   ],
   "source": [
    "%%writefile sagemaker-tensorflow-serving-container/docker/2.0/Dockerfile.cpu \n",
    "\n",
    "FROM ubuntu:18.04\n",
    "\n",
    "LABEL maintainer=\"Amazon AI\"\n",
    "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "ARG PYTHON=python3\n",
    "ARG PIP=pip3\n",
    "ARG TFS_SHORT_VERSION=2.0.1\n",
    "ARG TFS_URL=https://tensorflow-aws.s3-us-west-2.amazonaws.com/${TFS_SHORT_VERSION}/Serving/CPU-WITH-MKL/tensorflow_model_server\n",
    "\n",
    "# See http://bugs.python.org/issue19846\n",
    "ENV LANG=C.UTF-8\n",
    "# Python won’t try to write .pyc or .pyo files on the import of source modules\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV SAGEMAKER_TFS_VERSION=\"${TFS_SHORT_VERSION}\"\n",
    "ENV PATH=\"$PATH:/sagemaker\"\n",
    "ENV LD_LIBRARY_PATH='/usr/local/lib:$LD_LIBRARY_PATH'\n",
    "ENV MODEL_BASE_PATH=/models\n",
    "# The only required piece is the model name in order to differentiate endpoints\n",
    "ENV MODEL_NAME=model\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "# nginx + njs\n",
    "RUN apt-get update \\\n",
    " && apt-get -y install --no-install-recommends \\\n",
    "    curl \\\n",
    "    gnupg2 \\\n",
    "    ca-certificates \\\n",
    "    git \\\n",
    "    wget \\\n",
    "    vim \\\n",
    "    build-essential \\\n",
    "    zlib1g-dev \\\n",
    " && curl -s http://nginx.org/keys/nginx_signing.key | apt-key add - \\\n",
    " && echo 'deb http://nginx.org/packages/ubuntu/ bionic nginx' >> /etc/apt/sources.list \\\n",
    " && apt-get update \\\n",
    " && apt-get -y install --no-install-recommends \\\n",
    "    nginx \\\n",
    "    nginx-module-njs \\\n",
    "    python3 \\\n",
    "    python3-pip \\\n",
    "    python3-setuptools \\\n",
    " && apt-get clean \\\n",
    " && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN ${PIP} --no-cache-dir install --upgrade pip setuptools\n",
    "\n",
    "# cython, falcon, gunicorn, grpc\n",
    "RUN ${PIP} install --no-cache-dir \\\n",
    "    awscli==1.16.303 \\\n",
    "    cython==0.29.14 \\\n",
    "    falcon==2.0.0 \\\n",
    "    gunicorn==20.0.4 \\\n",
    "    gevent==1.4.0 \\\n",
    "    requests==2.22.0 \\\n",
    "    grpcio==1.26.0 \\\n",
    "    protobuf==3.11.1 \\\n",
    "# using --no-dependencies to avoid installing tensorflow binary\n",
    " && ${PIP} install --no-dependencies --no-cache-dir \\\n",
    "    tensorflow-serving-api==2.0\n",
    "\n",
    "#################\n",
    "# 추가 사항\n",
    "# Install tensorflow 2.1 and transformer\n",
    "#################\n",
    "RUN ${PIP} install --no-cache-dir \\\n",
    "    tensorflow==2.1.0 \\\n",
    "    transformers==2.8.0\n",
    "#################\n",
    "\n",
    "\n",
    "COPY ./sagemaker /sagemaker\n",
    "\n",
    "# Some TF tools expect a \"python\" binary\n",
    "RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
    "\n",
    "RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libiomp5.so -o /usr/local/lib/libiomp5.so\n",
    "RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libmklml_intel.so -o /usr/local/lib/libmklml_intel.so\n",
    "\n",
    "RUN curl $TFS_URL -o /usr/bin/tensorflow_model_server \\\n",
    " && chmod 555 /usr/bin/tensorflow_model_server\n",
    "\n",
    "# Expose ports\n",
    "# gRPC and REST\n",
    "EXPOSE 8500 8501\n",
    "\n",
    "# Set where models should be stored in the container\n",
    "RUN mkdir -p ${MODEL_BASE_PATH}\n",
    "\n",
    "# Create a script that runs the model server so we can use environment variables\n",
    "# while also passing in arguments from the docker command line\n",
    "RUN echo '#!/bin/bash \\n\\n' > /usr/bin/tf_serving_entrypoint.sh \\\n",
    " && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"' >> /usr/bin/tf_serving_entrypoint.sh \\\n",
    " && chmod +x /usr/bin/tf_serving_entrypoint.sh\n",
    "\n",
    "ADD https://raw.githubusercontent.com/aws/aws-deep-learning-containers-utils/master/deep_learning_container.py /usr/local/bin/deep_learning_container.py\n",
    "\n",
    "RUN chmod +x /usr/local/bin/deep_learning_container.py\n",
    "\n",
    "RUN curl https://aws-dlc-licenses.s3.amazonaws.com/tensorflow-2.0.1/license.txt -o /license.txt\n",
    "\n",
    "CMD [\"/usr/bin/tf_serving_entrypoint.sh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custome Docker 생성\n",
    "아래 셀 스크립트를 실행하면 이미지가 생성이 됩니다. \n",
    "```\n",
    "./scripts/build.sh --version 2.0.0 --arch cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_version = \"2.0.0\"\n",
    "cpu_type = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling previous image for layer cache... \n",
      "building image... \n",
      "Sending build context to Docker daemon  88.58kB\n",
      "Step 1/32 : FROM ubuntu:18.04\n",
      " ---> 6526a1858e5d\n",
      "Step 2/32 : LABEL maintainer=\"Amazon AI\"\n",
      " ---> Using cache\n",
      " ---> dcee4ad7f5d2\n",
      "Step 3/32 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> 60840a97e0bf\n",
      "Step 4/32 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> d1a0d2565efb\n",
      "Step 5/32 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 230ac67e8779\n",
      "Step 6/32 : ARG TFS_SHORT_VERSION=2.0.1\n",
      " ---> Using cache\n",
      " ---> c597fd2bd758\n",
      "Step 7/32 : ARG TFS_URL=https://tensorflow-aws.s3-us-west-2.amazonaws.com/${TFS_SHORT_VERSION}/Serving/CPU-WITH-MKL/tensorflow_model_server\n",
      " ---> Using cache\n",
      " ---> 4e394ef5ff7a\n",
      "Step 8/32 : ENV LANG=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 5d0c916d4c18\n",
      "Step 9/32 : ENV PYTHONDONTWRITEBYTECODE=1\n",
      " ---> Using cache\n",
      " ---> 3731495125fa\n",
      "Step 10/32 : ENV PYTHONUNBUFFERED=1\n",
      " ---> Using cache\n",
      " ---> 25e22cb6ec31\n",
      "Step 11/32 : ENV SAGEMAKER_TFS_VERSION=\"${TFS_SHORT_VERSION}\"\n",
      " ---> Using cache\n",
      " ---> 60b5250cc40f\n",
      "Step 12/32 : ENV PATH=\"$PATH:/sagemaker\"\n",
      " ---> Using cache\n",
      " ---> c950198eb5f9\n",
      "Step 13/32 : ENV LD_LIBRARY_PATH='/usr/local/lib:$LD_LIBRARY_PATH'\n",
      " ---> Using cache\n",
      " ---> 91557b7ac974\n",
      "Step 14/32 : ENV MODEL_BASE_PATH=/models\n",
      " ---> Using cache\n",
      " ---> faa5ec7d8870\n",
      "Step 15/32 : ENV MODEL_NAME=model\n",
      " ---> Using cache\n",
      " ---> 8ebfea5544de\n",
      "Step 16/32 : ENV DEBIAN_FRONTEND=noninteractive\n",
      " ---> Using cache\n",
      " ---> 88d68428698f\n",
      "Step 17/32 : RUN apt-get update  && apt-get -y install --no-install-recommends     curl     gnupg2     ca-certificates     git     wget     vim     build-essential     zlib1g-dev  && curl -s http://nginx.org/keys/nginx_signing.key | apt-key add -  && echo 'deb http://nginx.org/packages/ubuntu/ bionic nginx' >> /etc/apt/sources.list  && apt-get update  && apt-get -y install --no-install-recommends     nginx     nginx-module-njs     python3     python3-pip     python3-setuptools  && apt-get clean  && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 28871fdc2e26\n",
      "Step 18/32 : RUN ${PIP} --no-cache-dir install --upgrade pip setuptools\n",
      " ---> Using cache\n",
      " ---> 7a09eb708c5f\n",
      "Step 19/32 : RUN ${PIP} install --no-cache-dir     awscli==1.16.303     cython==0.29.14     falcon==2.0.0     gunicorn==20.0.4     gevent==1.4.0     requests==2.22.0     grpcio==1.26.0     protobuf==3.11.1  && ${PIP} install --no-dependencies --no-cache-dir     tensorflow-serving-api==2.0\n",
      " ---> Using cache\n",
      " ---> b4898115bdf3\n",
      "Step 20/32 : RUN ${PIP} install --no-cache-dir     tensorflow==2.1.0     transformers==2.8.0\n",
      " ---> Using cache\n",
      " ---> b8d0ad255ca1\n",
      "Step 21/32 : COPY ./sagemaker /sagemaker\n",
      " ---> Using cache\n",
      " ---> 810ccff87d4f\n",
      "Step 22/32 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 9463e27213b1\n",
      "Step 23/32 : RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libiomp5.so -o /usr/local/lib/libiomp5.so\n",
      " ---> Using cache\n",
      " ---> f49b1333de85\n",
      "Step 24/32 : RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libmklml_intel.so -o /usr/local/lib/libmklml_intel.so\n",
      " ---> Using cache\n",
      " ---> 92a558f69221\n",
      "Step 25/32 : RUN curl $TFS_URL -o /usr/bin/tensorflow_model_server  && chmod 555 /usr/bin/tensorflow_model_server\n",
      " ---> Using cache\n",
      " ---> b8b4d8b40746\n",
      "Step 26/32 : EXPOSE 8500 8501\n",
      " ---> Using cache\n",
      " ---> 060137a87075\n",
      "Step 27/32 : RUN mkdir -p ${MODEL_BASE_PATH}\n",
      " ---> Using cache\n",
      " ---> 244afe28a38d\n",
      "Step 28/32 : RUN echo '#!/bin/bash \\n\\n' > /usr/bin/tf_serving_entrypoint.sh  && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"' >> /usr/bin/tf_serving_entrypoint.sh  && chmod +x /usr/bin/tf_serving_entrypoint.sh\n",
      " ---> Using cache\n",
      " ---> 017040359fa5\n",
      "Step 29/32 : ADD https://raw.githubusercontent.com/aws/aws-deep-learning-containers-utils/master/deep_learning_container.py /usr/local/bin/deep_learning_container.py\n",
      "\n",
      " ---> Using cache\n",
      " ---> 7eedd96f49ce\n",
      "Step 30/32 : RUN chmod +x /usr/local/bin/deep_learning_container.py\n",
      " ---> Using cache\n",
      " ---> 59b992335c60\n",
      "Step 31/32 : RUN curl https://aws-dlc-licenses.s3.amazonaws.com/tensorflow-2.0.1/license.txt -o /license.txt\n",
      " ---> Using cache\n",
      " ---> a53a86156a46\n",
      "Step 32/32 : CMD [\"/usr/bin/tf_serving_entrypoint.sh\"]\n",
      " ---> Using cache\n",
      " ---> 9627238f8c12\n",
      "[Warning] One or more build-args [TFS_VERSION] were not consumed\n",
      "Successfully built 9627238f8c12\n",
      "Successfully tagged sagemaker-tensorflow-serving:2.0.0-cpu\n",
      "Successfully tagged sagemaker-tensorflow-serving:2.0-cpu\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {region} {tfs_version} {cpu_type}\n",
    "\n",
    "AWS_DEFAULT_REGION=$1\n",
    "export AWS_DEFAULT_REGION\n",
    "TFS_VERION=$2\n",
    "CPU_TYPE=$3\n",
    "\n",
    "cd sagemaker-tensorflow-serving-container\n",
    "\n",
    "./scripts/build.sh --version $TFS_VERION --arch $CPU_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Serving:2.0.0-cpu 를 ECR에 퍼블리시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 셀 스크립트를 실행하면 위에서 생성한 이미지가 ECR에 퍼블리시 됩니다.\n",
    "```\n",
    "./scripts/publish.sh --version 1.13 --arch cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 (2020/07) ECR에 해당 이미지가 없으면  publish.sh 에서 에러가 발생하여 아래 코드 추가 함\n",
    "```\n",
    "aws ecr describe-repositories --repository-names $repository > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name $repository > /dev/null\n",
    "fi\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sagemaker-tensorflow-serving-container/scripts/publish.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile sagemaker-tensorflow-serving-container/scripts/publish.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#\n",
    "# Publish images to your ECR account.\n",
    "\n",
    "# 기존 소스에서 아래 주석 처리 함\n",
    "# set -euo pipefail\n",
    "\n",
    "source scripts/shared.sh\n",
    "\n",
    "parse_std_args \"$@\"\n",
    "\n",
    "aws ecr get-login-password --region ${aws_region} \\\n",
    "    | docker login \\\n",
    "        --password-stdin \\\n",
    "        --username AWS \\\n",
    "        \"${aws_account}.dkr.ecr.${aws_region}.amazonaws.com/${repository}\"\n",
    "\n",
    "aws ecr describe-repositories --repository-names $repository > /dev/null 2>&1\n",
    "\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name $repository > /dev/null\n",
    "fi\n",
    "\n",
    "docker tag $repository:$full_version-$device $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$full_version-$device\n",
    "docker tag $repository:$full_version-$device $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$short_version-$device\n",
    "docker push $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$full_version-$device\n",
    "docker push $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$short_version-$device\n",
    "docker logout https://$aws_account.dkr.ecr.$aws_region.amazonaws.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [057716757052.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving]\n",
      "27ad256900e2: Preparing\n",
      "3a09520723c8: Preparing\n",
      "af5b6438532e: Preparing\n",
      "a0687c452f98: Preparing\n",
      "48838a30321c: Preparing\n",
      "e814f0abc0d3: Preparing\n",
      "c128d5a19263: Preparing\n",
      "b1f8aa56790d: Preparing\n",
      "1066a9f9097f: Preparing\n",
      "a7a05cc084a1: Preparing\n",
      "20462666fdd8: Preparing\n",
      "ee8a8520673c: Preparing\n",
      "bd09e4e679fc: Preparing\n",
      "8f4be5d31636: Preparing\n",
      "001e4a80973b: Preparing\n",
      "2ba5b91ca2b0: Preparing\n",
      "2f37d1102187: Preparing\n",
      "79bde4d54386: Preparing\n",
      "ee8a8520673c: Waiting\n",
      "c128d5a19263: Waiting\n",
      "a7a05cc084a1: Waiting\n",
      "bd09e4e679fc: Waiting\n",
      "20462666fdd8: Waiting\n",
      "b1f8aa56790d: Waiting\n",
      "1066a9f9097f: Waiting\n",
      "8f4be5d31636: Waiting\n",
      "e814f0abc0d3: Waiting\n",
      "001e4a80973b: Waiting\n",
      "2ba5b91ca2b0: Waiting\n",
      "79bde4d54386: Waiting\n",
      "2f37d1102187: Waiting\n",
      "27ad256900e2: Layer already exists\n",
      "3a09520723c8: Layer already exists\n",
      "af5b6438532e: Layer already exists\n",
      "48838a30321c: Layer already exists\n",
      "a0687c452f98: Layer already exists\n",
      "c128d5a19263: Layer already exists\n",
      "e814f0abc0d3: Layer already exists\n",
      "b1f8aa56790d: Layer already exists\n",
      "1066a9f9097f: Layer already exists\n",
      "a7a05cc084a1: Layer already exists\n",
      "20462666fdd8: Layer already exists\n",
      "ee8a8520673c: Layer already exists\n",
      "bd09e4e679fc: Layer already exists\n",
      "8f4be5d31636: Layer already exists\n",
      "001e4a80973b: Layer already exists\n",
      "2f37d1102187: Layer already exists\n",
      "2ba5b91ca2b0: Layer already exists\n",
      "79bde4d54386: Layer already exists\n",
      "2.0.0-cpu: digest: sha256:b62f6172c21b768907db941a76c4a6d73cca9c22b7c46b0827da0784634cd490 size: 4090\n",
      "The push refers to repository [057716757052.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving]\n",
      "27ad256900e2: Preparing\n",
      "3a09520723c8: Preparing\n",
      "af5b6438532e: Preparing\n",
      "a0687c452f98: Preparing\n",
      "48838a30321c: Preparing\n",
      "e814f0abc0d3: Preparing\n",
      "c128d5a19263: Preparing\n",
      "b1f8aa56790d: Preparing\n",
      "1066a9f9097f: Preparing\n",
      "a7a05cc084a1: Preparing\n",
      "20462666fdd8: Preparing\n",
      "ee8a8520673c: Preparing\n",
      "bd09e4e679fc: Preparing\n",
      "8f4be5d31636: Preparing\n",
      "001e4a80973b: Preparing\n",
      "2ba5b91ca2b0: Preparing\n",
      "2f37d1102187: Preparing\n",
      "79bde4d54386: Preparing\n",
      "1066a9f9097f: Waiting\n",
      "e814f0abc0d3: Waiting\n",
      "b1f8aa56790d: Waiting\n",
      "a7a05cc084a1: Waiting\n",
      "c128d5a19263: Waiting\n",
      "ee8a8520673c: Waiting\n",
      "20462666fdd8: Waiting\n",
      "79bde4d54386: Waiting\n",
      "001e4a80973b: Waiting\n",
      "8f4be5d31636: Waiting\n",
      "27ad256900e2: Layer already exists\n",
      "3a09520723c8: Layer already exists\n",
      "af5b6438532e: Layer already exists\n",
      "48838a30321c: Layer already exists\n",
      "a0687c452f98: Layer already exists\n",
      "c128d5a19263: Layer already exists\n",
      "e814f0abc0d3: Layer already exists\n",
      "b1f8aa56790d: Layer already exists\n",
      "a7a05cc084a1: Layer already exists\n",
      "1066a9f9097f: Layer already exists\n",
      "20462666fdd8: Layer already exists\n",
      "bd09e4e679fc: Layer already exists\n",
      "ee8a8520673c: Layer already exists\n",
      "8f4be5d31636: Layer already exists\n",
      "001e4a80973b: Layer already exists\n",
      "2ba5b91ca2b0: Layer already exists\n",
      "2f37d1102187: Layer already exists\n",
      "79bde4d54386: Layer already exists\n",
      "2.0-cpu: digest: sha256:b62f6172c21b768907db941a76c4a6d73cca9c22b7c46b0827da0784634cd490 size: 4090\n",
      "Removing login credentials for 057716757052.dkr.ecr.ap-northeast-2.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {region} {tfs_version} {cpu_type}\n",
    "\n",
    "AWS_DEFAULT_REGION=$1\n",
    "export AWS_DEFAULT_REGION\n",
    "TFS_VERION=$2\n",
    "CPU_TYPE=$3\n",
    "\n",
    "cd sagemaker-tensorflow-serving-container\n",
    "\n",
    "./scripts/publish.sh --version $TFS_VERION --arch $CPU_TYPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Inference Image 저장\n",
    "<font color=\"red\">아래의 그림처럼 계정 및 지역이 다르다면 수정해야 합니다.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ecr-infer-container](img/ecr-infer-container.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecr_infer_custom_image_tf_serving_20_cpu: \n",
      " 057716757052.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:2.0.0-cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "account = account_id\n",
    "ecr_infer_custom_image_tf_serving_20_cpu = '{}.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:{}-{}'.format(\n",
    "    account,\n",
    "    tfs_version,\n",
    "    cpu_type\n",
    ")\n",
    "print(\"ecr_infer_custom_image_tf_serving_20_cpu: \\n\", ecr_infer_custom_image_tf_serving_20_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 다음 노트북에서 사용하기 위하여 저장 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ecr_infer_custom_image_tf_serving_20_cpu' (str)\n"
     ]
    }
   ],
   "source": [
    "%store ecr_infer_custom_image_tf_serving_20_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
