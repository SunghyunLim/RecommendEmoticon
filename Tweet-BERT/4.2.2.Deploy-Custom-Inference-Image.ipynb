{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.2.2] inference on custem tf serving image\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 진행 합니다.\n",
    "- Custom Inference Docker Image를 사용하여, SageMaker Model을 생성\n",
    "- 위의 SageMaker Model를 통해서 Deploy 하여 Endpoint를 생성 합니다.\n",
    "- Endpoint에 Predictor를 생성 합니다.\n",
    "- 추론을 하여 상위 5개의 높은 스코어를 가진 것을 이모팀콘으로 변경하여 5개 추천 합니다.\n",
    "\n",
    "---\n",
    "이 노트북은 약 10 분 정도 시간이 소요 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert2tweet-2020-08-17-10-11-25-431\n"
     ]
    }
   ],
   "source": [
    "# training_job_name = 'bert2tweet-2020-07-08-07-58-27-895'\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_image:  343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:2.0.0-cpu\n"
     ]
    }
   ],
   "source": [
    "inference_image = ecr_infer_custom_image_tf_serving_20_cpu\n",
    "print(\"inference_image: \", inference_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custome TFS Docker Image 및 Inference code 로 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data='s3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name),\n",
    "              role=role,\n",
    "              entry_point='inference.py',\n",
    "              image = inference_image\n",
    "             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:2.0.0-cpu\n",
      "<bound method Model.serving_image_uri of <sagemaker.tensorflow.serving.Model object at 0x7fcbf1560588>>\n",
      "s3://sagemaker-ap-northeast-2-343441690612/bert2tweet-2020-08-17-10-11-25-431/output/model.tar.gz\n",
      "None\n",
      "tensorflow-serving\n"
     ]
    }
   ],
   "source": [
    "print(model.image)\n",
    "print(model.serving_image_uri)\n",
    "print(model.model_data)\n",
    "print(model.name)\n",
    "print(model.FRAMEWORK_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엔드포인트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 1min 4s, sys: 11 s, total: 1min 15s\n",
      "Wall time: 7min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "instance_type='ml.m4.xlarge'\n",
    "deployed_model = model.deploy(initial_instance_count = 1,\n",
    "                             instance_type = instance_type,\n",
    "                             wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Creation on the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-tensorflow-serving-2020-08-17-10-30-49-226\n"
     ]
    }
   ],
   "source": [
    "# tweet_bert_endpoint_name = 'train_text, train_label, test_text, test_label = tweet_data.split_train_test_data(texts, labels, 0.9)\n",
    "tweet_bert_endpoint_name = deployed_model.endpoint\n",
    "print(tweet_bert_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "\n",
    "predictor = Predictor(endpoint_name = tweet_bert_endpoint_name,\n",
    "                      sagemaker_session = sess,\n",
    "                      content_type = 'application/json',\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji_to_idx is loaded\n",
      "😂\n"
     ]
    }
   ],
   "source": [
    "from TweetUtil import TweetUtil\n",
    "\n",
    "tweet_util = TweetUtil()\n",
    "tweet_util.load_emoji_data('emoji_to_idx.pickle')\n",
    "emoji = tweet_util.get_emo_class_label(3)\n",
    "print(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>bitches be hating on me and haven't even met me</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>i'm so lost without you</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>in case anyone needs this i love this</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>gucci said he wanna work with 21 savage im re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>rt yall lettin niggas who shoot like this beat</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>had your first kiss sadly no</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7670</th>\n",
       "      <td>purpose tour</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>the lady at the hair cuttery just called me he...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>super proud of tonight witchoooo grown asss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>i'm very normal i'm an approachable standoffi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  LABEL\n",
       "2004    bitches be hating on me and haven't even met me      6\n",
       "5004                            i'm so lost without you      6\n",
       "7144              in case anyone needs this i love this      0\n",
       "3141   gucci said he wanna work with 21 savage im re...      2\n",
       "2862    rt yall lettin niggas who shoot like this beat       7\n",
       "3260                       had your first kiss sadly no      6\n",
       "7670                                       purpose tour      2\n",
       "2906  the lady at the hair cuttery just called me he...      8\n",
       "3396        super proud of tonight witchoooo grown asss      2\n",
       "7485   i'm very normal i'm an approachable standoffi...      8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "sample_df = test_df.sample(10)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_N_label(score_list, topN):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    top_n_idx = np.argsort(score_list)[-topN:]\n",
    "    top_n_values = [score_list[i] for i in top_n_idx]\n",
    "    \n",
    "    top_n_idx_list = top_n_idx.tolist()\n",
    "    top_n_idx_list.reverse()\n",
    "    top_n_values = [score_list[i] for i in top_n_idx_list]    \n",
    "    \n",
    "    return top_n_idx_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 이모티콘 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet: \n",
      " [\" bitches be hating on me and haven't even met me\"]\n",
      "tweet:  bitches be hating on me and haven't even met me \n",
      "Ground_truth- 6:😩\n",
      " \n",
      "Prediction: 6,😩,8,🙄,7,😭,5,😍,1,💕 \n",
      " \n",
      "tweet: \n",
      " [\" i'm so lost without you\"]\n",
      "tweet:  i'm so lost without you \n",
      "Ground_truth- 6:😩\n",
      " \n",
      "Prediction: 6,😩,1,💕,7,😭,5,😍,9,🤔 \n",
      " \n",
      "tweet: \n",
      " [' in case anyone needs this i love this']\n",
      "tweet:  in case anyone needs this i love this \n",
      "Ground_truth- 0:❤\n",
      " \n",
      "Prediction: 5,😍,6,😩,1,💕,7,😭,0,❤ \n",
      " \n",
      "tweet: \n",
      " [' gucci said he wanna work with 21 savage im ready for that']\n",
      "tweet:  gucci said he wanna work with 21 savage im ready for that \n",
      "Ground_truth- 2:🔥\n",
      " \n",
      "Prediction: 1,💕,2,🔥,0,❤,7,😭,9,🤔 \n",
      " \n",
      "tweet: \n",
      " ['rt yall lettin niggas who shoot like this beat ']\n",
      "tweet: rt yall lettin niggas who shoot like this beat  \n",
      "Ground_truth- 7:😭\n",
      " \n",
      "Prediction: 7,😭,3,😂,5,😍,1,💕,2,🔥 \n",
      " \n",
      "tweet: \n",
      " ['had your first kiss sadly no']\n",
      "tweet: had your first kiss sadly no \n",
      "Ground_truth- 6:😩\n",
      " \n",
      "Prediction: 5,😍,6,😩,0,❤,1,💕,8,🙄 \n",
      " \n",
      "tweet: \n",
      " [' purpose tour']\n",
      "tweet:  purpose tour \n",
      "Ground_truth- 2:🔥\n",
      " \n",
      "Prediction: 1,💕,2,🔥,7,😭,6,😩,9,🤔 \n",
      " \n",
      "tweet: \n",
      " ['the lady at the hair cuttery just called me her pretty so cute i needed some positivity today but puppies babies are cute ']\n",
      "tweet: the lady at the hair cuttery just called me her pretty so cute i needed some positivity today but puppies babies are cute  \n",
      "Ground_truth- 8:🙄\n",
      " \n",
      "Prediction: 7,😭,5,😍,4,😊,8,🙄,6,😩 \n",
      " \n",
      "tweet: \n",
      " [' super proud of tonight witchoooo grown asss']\n",
      "tweet:  super proud of tonight witchoooo grown asss \n",
      "Ground_truth- 2:🔥\n",
      " \n",
      "Prediction: 0,❤,5,😍,1,💕,7,😭,3,😂 \n",
      " \n",
      "tweet: \n",
      " [\" i'm very normal i'm an approachable standoffish yet welcoming nonsocial but outgoing loner type of person \"]\n",
      "tweet:  i'm very normal i'm an approachable standoffish yet welcoming nonsocial but outgoing loner type of person  \n",
      "Ground_truth- 8:🙄\n",
      " \n",
      "Prediction: 7,😭,5,😍,4,😊,2,🔥,3,😂 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "columns = ['TWEET', 'LABEL']\n",
    "topN = 5\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    # print(\"label: {}, tweet: {}\".format(label, tweet))\n",
    "    \n",
    "    reviews = [tweet]\n",
    "    \n",
    "    print(\"tweet: \\n\", reviews)\n",
    "\n",
    "\n",
    "\n",
    "    predicted_classes = predictor.predict(reviews)[0]\n",
    "    predicted_classes = show_top_N_label(predicted_classes, topN)\n",
    "\n",
    "    print('tweet: {} \\nGround_truth- {}:{}\\n '.format(\n",
    "        tweet,\n",
    "        label, \n",
    "        tweet_util.get_emo_class_label(label))\n",
    "         )    \n",
    "    \n",
    "\n",
    "    print('Prediction: {},{},{},{},{},{},{},{},{},{} \\n '.format(\n",
    "        predicted_classes[0], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[0]),\n",
    "        predicted_classes[1], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[1]),\n",
    "        predicted_classes[2], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[2]),   \n",
    "        predicted_classes[3], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[3]),                                      \n",
    "        predicted_classes[4], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[4]),                                      \n",
    "        \n",
    "        ))    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tweet_bert_endpoint_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store tweet_bert_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
