{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.1] Deploy Built-in TFS Image\n",
    "\n",
    "\n",
    "Ïó¨Í∏∞ÏÑúÎäî Îã§ÏùåÍ≥º Í∞ôÏùÄ ÏûëÏóÖÏùÑ Ìï©ÎãàÎã§.\n",
    "\n",
    "- Î™®Îç∏ ÏïÑÌã∞ÌéôÌä∏ (model.tar.gz) ÌååÏùºÏùÑ S3ÏóêÏÑú Î°úÏª¨Ïóê Îã§Ïö¥Î°úÎìú\n",
    "- TF Saved_Model Ïùò Ï†ïÏùòÎ•º ÌôïÏù∏\n",
    "- SageMaker Model ÏÉùÏÑ±\n",
    "- Endpoint ÏÉùÏÑ±\n",
    "- InferenceÏùò Request Serializer and Deserializer ÏÉùÏÑ±\n",
    "- ÌîÑÎ¶¨ÎîïÌÑ∞ ÏÉùÏÑ±\n",
    "- ÏÖàÌîå Îç∞Ïù¥ÌÉÄÎ°ú Ï∂îÎ°†\n",
    "\n",
    "---\n",
    "Ïù¥ ÎÖ∏Ìä∏Î∂ÅÏùÄ ÏïΩ 10Î∂Ñ Ï†ïÎèÑ ÏÜåÏöî Îê©ÎãàÎã§.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÌïÑÏöîÌïú ÌîÑÎ°úÍ∑∏Îû® ÏÑ§Ïπò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "astroid 2.3.3 requires wrapt==1.11.*, but you'll have wrapt 1.12.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install -q wrapt --upgrade --ignore-installed\n",
    "!pip install -q tensorflow==2.1.0\n",
    "!pip install -q transformers==2.8.0\n",
    "!pip install -q sagemaker==1.56.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Model to the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-2020-08-16-01-08-59-496\n"
     ]
    }
   ],
   "source": [
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_download = 'model'\n",
    "os.makedirs(model_download, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-16-01-08-59-496/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz {model_download}/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xvzf   {model_download}/model.tar.gz\n",
    "# !saved_model_cli show --all --dir ./tensorflow/saved_model/0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Model ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data='s3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name),\n",
    "              role=role,\n",
    "              framework_version='2.0.0') # Elastic Inference does not yet support TF 2.1.0 as of sagemaker==1.56.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "instance_type='ml.m4.xlarge'\n",
    "\n",
    "deployed_model = model.deploy(initial_instance_count = 1,\n",
    "                             instance_type = instance_type,\n",
    "                             wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name:  tensorflow-inference-2020-08-16-01-43-10-321\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = deployed_model.endpoint\n",
    "print('Endpoint name:  {}'.format(endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Request Serializer and Deserializer ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestHandler(object):\n",
    "    import json\n",
    "    \n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __call__(self, instances):\n",
    "        transformed_instances = []\n",
    "\n",
    "        for instance in instances:\n",
    "            encode_plus_tokens = tokenizer.encode_plus(instance,\n",
    "                                                       pad_to_max_length=True,\n",
    "                                                       max_length=self.max_seq_length)\n",
    "\n",
    "            input_ids = encode_plus_tokens['input_ids']\n",
    "            input_mask = encode_plus_tokens['attention_mask']\n",
    "            segment_ids = [0] * self.max_seq_length\n",
    "\n",
    "            transformed_instance = {\"input_ids\": input_ids, \n",
    "                                    \"input_mask\": input_mask, \n",
    "                                    \"segment_ids\": segment_ids}\n",
    "\n",
    "            transformed_instances.append(transformed_instance)\n",
    "\n",
    "        transformed_data = {\"instances\": transformed_instances}\n",
    "\n",
    "        return json.dumps(transformed_data)\n",
    "    \n",
    "class ResponseHandler(object):\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "    \n",
    "    def __call__(self, response, accept_header):\n",
    "        import tensorflow as tf\n",
    "\n",
    "        response_body = response.read().decode('utf-8')\n",
    "\n",
    "        response_json = json.loads(response_body)\n",
    "\n",
    "        log_probabilities = response_json[\"predictions\"]\n",
    "\n",
    "#        predicted_classes = []\n",
    "\n",
    "        # Convert log_probabilities => softmax (all probabilities add up to 1) => argmax (final prediction)\n",
    "#         for log_probability in log_probabilities:\n",
    "#             softmax = tf.nn.softmax(log_probability)    \n",
    "#             predicted_class_idx = tf.argmax(softmax, axis=-1, output_type=tf.int32)\n",
    "#             predicted_class = self.classes[predicted_class_idx]\n",
    "#             predicted_classes.append(predicted_class)\n",
    "\n",
    "        return log_probabilities    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "request_handler = RequestHandler(tokenizer=tokenizer,\n",
    "                                 max_seq_length=32)\n",
    "\n",
    "response_handler = ResponseHandler(classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name,\n",
    "                      sagemaker_session=sess,\n",
    "                      serializer=request_handler,\n",
    "                      deserializer=response_handler,\n",
    "                      content_type='application/json',\n",
    "                      model_name='saved_model',\n",
    "                      model_version=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Ïã§Ìñâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji_to_idx is loaded\n",
      "üòÇ\n"
     ]
    }
   ],
   "source": [
    "from TweetUtil import TweetUtil\n",
    "\n",
    "tweet_util = TweetUtil()\n",
    "tweet_util.load_emoji_data('emoji_to_idx.pickle')\n",
    "emoji = tweet_util.get_emo_class_label(3)\n",
    "print(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>yo this procrastination is real i didn't go o...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8830</th>\n",
       "      <td>overnight kila bes merlengggg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>x x me we smacked this bih we jus getting sta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410</th>\n",
       "      <td>yes you did ny is your home and you should be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>his jersey sleeves is the reason c'mon everyon...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>one day promise intime myart</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>too much luv for tuna pasta n sweetcorn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>going from waking up at 3 pm everyday to waki...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9360</th>\n",
       "      <td>which</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>love it sis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  LABEL\n",
       "2824   yo this procrastination is real i didn't go o...      7\n",
       "8830                      overnight kila bes merlengggg      0\n",
       "1969   x x me we smacked this bih we jus getting sta...      2\n",
       "5410   yes you did ny is your home and you should be...      1\n",
       "1604  his jersey sleeves is the reason c'mon everyon...      3\n",
       "2338                       one day promise intime myart      4\n",
       "2970            too much luv for tuna pasta n sweetcorn      1\n",
       "936    going from waking up at 3 pm everyday to waki...      6\n",
       "9360                                              which      9\n",
       "748                                         love it sis      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "sample_df = test_df.sample(10)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_N_label(score_list, topN):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    top_n_idx = np.argsort(score_list)[-topN:]\n",
    "    top_n_values = [score_list[i] for i in top_n_idx]\n",
    "    \n",
    "    top_n_idx_list = top_n_idx.tolist()\n",
    "    top_n_idx_list.reverse()\n",
    "    top_n_values = [score_list[i] for i in top_n_idx_list]    \n",
    "    \n",
    "    return top_n_idx_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  yo this procrastination is real i didn't go out all weekend and have complete zero homework i have a problem \n",
      "Ground_truth- 7:üò≠\n",
      " \n",
      "Prediction: 8,üôÑ,9,ü§î,3,üòÇ \n",
      " \n",
      "tweet: overnight kila bes merlengggg \n",
      "Ground_truth- 0:‚ù§\n",
      " \n",
      "Prediction: 6,üò©,3,üòÇ,5,üòç \n",
      " \n",
      "tweet:  x x me we smacked this bih we jus getting started \n",
      "Ground_truth- 2:üî•\n",
      " \n",
      "Prediction: 6,üò©,3,üòÇ,2,üî• \n",
      " \n",
      "tweet:  yes you did ny is your home and you should be there no where else ms sherri \n",
      "Ground_truth- 1:üíï\n",
      " \n",
      "Prediction: 1,üíï,4,üòä,3,üòÇ \n",
      " \n",
      "tweet: his jersey sleeves is the reason c'mon everyone knows that \n",
      "Ground_truth- 3:üòÇ\n",
      " \n",
      "Prediction: 6,üò©,3,üòÇ,0,‚ù§ \n",
      " \n",
      "tweet:  one day promise intime myart \n",
      "Ground_truth- 4:üòä\n",
      " \n",
      "Prediction: 8,üôÑ,7,üò≠,9,ü§î \n",
      " \n",
      "tweet: too much luv for tuna pasta n sweetcorn \n",
      "Ground_truth- 1:üíï\n",
      " \n",
      "Prediction: 6,üò©,5,üòç,8,üôÑ \n",
      " \n",
      "tweet:  going from waking up at 3 pm everyday to waking up at 6 am \n",
      "Ground_truth- 6:üò©\n",
      " \n",
      "Prediction: 8,üôÑ,9,ü§î,7,üò≠ \n",
      " \n",
      "tweet:  which \n",
      "Ground_truth- 9:ü§î\n",
      " \n",
      "Prediction: 0,‚ù§,1,üíï,9,ü§î \n",
      " \n",
      "tweet: love it sis \n",
      "Ground_truth- 0:‚ù§\n",
      " \n",
      "Prediction: 5,üòç,0,‚ù§,2,üî• \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "columns = ['TWEET', 'LABEL']\n",
    "topN = 3\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    # print(\"label: {}, tweet: {}\".format(label, tweet))\n",
    "    \n",
    "    reviews = [tweet]\n",
    "    \n",
    "#     print(\"reviews: \\n\", reviews)\n",
    "\n",
    "\n",
    "\n",
    "    predicted_classes = predictor.predict(reviews)[0]\n",
    "#    predicted_classes = predictor.predict(reviews)    \n",
    "    predicted_classes = show_top_N_label(predicted_classes, topN)\n",
    "\n",
    "    print('tweet: {} \\nGround_truth- {}:{}\\n '.format(\n",
    "        tweet,\n",
    "        label, \n",
    "        tweet_util.get_emo_class_label(label))\n",
    "         )    \n",
    "    \n",
    "\n",
    "    print('Prediction: {},{},{},{},{},{} \\n '.format(\n",
    "        predicted_classes[0], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[0]),\n",
    "        predicted_classes[1], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[1]),\n",
    "        predicted_classes[2], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[2])                                       \n",
    "        ))    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Past Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.400611103, -1.16453958, -1.89889371, 4.70898628, -2.37440658, -1.60534883, 3.95935464, -1.55257404, -1.79060662, -1.94558775]]\n",
      "[[-1.20432031, -1.82773113, -0.391512632, 0.703009248, -1.59350145, -0.565404058, 7.18686295, -1.97893572, -1.2113502, -1.69550371]]\n",
      "[[-1.83954346, -2.39527082, 1.8454771, -0.571332097, -2.09438753, 0.175423399, 5.93926525, -2.12616, 0.507222772, -1.90001047]]\n",
      "[[-1.51556039, 1.99300051, -2.42727852, 4.90277386, -1.01229858, -1.762568, 0.475168973, -1.92735767, -1.88486302, -1.84640229]]\n",
      "[[-0.78829211, -1.94221628, -0.810397327, 2.82171583, -2.31329346, -2.84787273, 2.85517621, -1.29353356, 1.69144058, -1.90860903]]\n",
      "[[-2.38983226, -1.91434097, -1.83881164, -0.366253287, -2.17718744, -2.49873948, 0.49742192, -0.975801587, 7.15242624, -0.499093056]]\n",
      "[[-0.329123735, -1.50071621, -1.88950539, 1.39940095, -0.332201302, 5.98732853, -1.2794199, -1.39521348, -2.3023181, -1.70894337]]\n",
      "[[-1.21936142, -0.279880226, -1.39440358, 1.44727635, -2.01546574, -1.44794595, 6.88877726, -1.83698177, -1.65431273, -1.66562271]]\n",
      "[[-2.11682844, -2.02689, -2.14486647, 1.16001773, -2.54199862, -2.41462564, 3.27118182, 2.23096752, 1.43830442, -1.37946236]]\n",
      "[[-1.30538464, -2.21708298, -1.13893819, 5.85535717, -2.06209946, -2.1981349, 1.46633255, -1.26528025, 0.533265412, -1.75763834]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "sample_df = test_df.sample(10)\n",
    "columns = ['TWEET', 'LABEL']\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    # print(\"label: {}, tweet: {}\".format(label, tweet))\n",
    "    \n",
    "    reviews = [tweet]\n",
    "\n",
    "    predicted_classes = predictor.predict(reviews)\n",
    "    print(predicted_classes)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction, Ground_truth- [3.77719784, 3.43111205, -1.69310737, -2.02781153, -1.97104251, -1.358307, 1.63716865, -2.22402334, -2.48495936, -1.99037027]:None, 4:üòä \n",
      " tweet:  thank you i am so happy \n",
      "Prediction, Ground_truth- [-1.0546068, 3.20887256, -3.05958223, 0.414651603, -1.70333171, -1.96098542, 1.28481448, 1.59856355, -2.34978557, -1.74867749]:None, 6:üò© \n",
      " tweet:  i will never understand how a friendship like kalin and myles just ends\n",
      "Prediction, Ground_truth- [0.0448568128, -0.307889551, -2.46420431, -0.81351316, 0.686781883, 6.1663456, -2.12994337, -0.655496597, -2.31159425, -1.73348486]:None, 5:üòç \n",
      " tweet: mrs sonakshidixit is looking so beautiful devakshikishaadi krpkab\n",
      "Prediction, Ground_truth- [0.607466161, 0.0160209909, -1.20571065, -1.29471827, -1.30522609, -2.12841, -0.0549491271, -1.85945106, -1.2868154, 3.62702799]:None, 4:üòä \n",
      " tweet:  start deleting career's on his games start deleting career's on his games start deleting career's on his games\n",
      "Prediction, Ground_truth- [-0.994389236, -2.1172061, -1.71504986, 4.92222929, -0.910291433, -1.08319116, -2.40935302, 2.35265255, -0.559154809, -1.30547321]:None, 6:üò© \n",
      " tweet: damn mr joseph coulda cleaned the pool one last time i know it's after labor day but for the culture bih i wanna dip my feet in\n",
      "Prediction, Ground_truth- [-1.59074, -1.77168345, 3.21746182, -0.908232093, 0.0651212633, 4.78105402, -0.790910721, -1.68286443, -2.51639414, -2.07848835]:None, 7:üò≠ \n",
      " tweet:  awe omg\n",
      "Prediction, Ground_truth- [-1.47764444, -1.68326509, -0.279236972, 0.0349086821, -1.74282134, -1.05617106, 6.66040182, -2.11120868, 0.560632288, -2.00837612]:None, 6:üò© \n",
      " tweet:  ok were buying today \n",
      "Prediction, Ground_truth- [0.119276933, -1.28982401, -1.19065809, -1.29988921, -0.765585721, 7.62507677, -0.965223253, -1.12941217, -2.0775373, -1.78552771]:None, 2:üî• \n",
      " tweet:  dope barberart\n",
      "Prediction, Ground_truth- [-2.71506, -1.15409446, -2.37870026, 1.63655603, -2.57402372, -3.25329304, 1.06013179, 1.03622782, 3.76032305, -0.746837258]:None, 4:üòä \n",
      " tweet:  well we're spreading awareness so i'll keep quiet\n",
      "Prediction, Ground_truth- [0.761111677, -1.9695667, 1.31063282, -0.122789517, -1.80919206, 4.01854181, 2.07862329, -2.76461387, -2.49749231, -2.24417424]:None, 7:üò≠ \n",
      " tweet: another finger these guys dont give up felix is the mvp this episode rezero rezero anime\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "sample_df = test_df.sample(10)\n",
    "columns = ['TWEET', 'LABEL']\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    # print(\"label: {}, tweet: {}\".format(label, tweet))\n",
    "    \n",
    "    reviews = [tweet]\n",
    "\n",
    "    predicted_classes = predictor.predict(reviews)[0]\n",
    "    print('Prediction, Ground_truth- {}:{}, {}:{} \\n tweet: {}'.format(\n",
    "        predicted_classes, \n",
    "        tweet_util.get_emo_class_label(predicted_classes),\n",
    "        label, \n",
    "        tweet_util.get_emo_class_label(label),        \n",
    "        tweet))    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
