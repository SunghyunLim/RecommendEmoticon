{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On a LocalMode, Train a BERT Model with Tensorflow\n",
    "- 스크립트 모드를 사용하기 위해서 아래의 API 문서 참고 하세요\n",
    "- Script Mode Ref:\n",
    "    - https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#train-a-model-with-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  로컬모드 (Local Mode) 학습 <a class=\"anchor\" id=\"LocalModeTraining\">\n",
    "\n",
    "SageMaker에서 로컬 모드는, 여러분이 작성한 코드를 SageMaker에서 관리되는 보다 강력한 클러스터에서 실행하기 전에, 여러분의 코드가 기대한 방식으로 동작하는 지 로컬에서 확인할 수 있는 편리한 방식입니다. 로컬모드 학습을 위해서는 docker-compose 또는 nvidia-docker-compose (GPU 인스턴스인 경우)의 설치가 필요합니다. 다음 셀의 명령은 본 노트북환경에 docker-compose 또는 nvidia-docker-compose를 설치하고 구성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/local_mode_setup.sh\n",
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/daemon.json    \n",
    "!/bin/bash ./local_mode_setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_input_train_data = sagemaker.s3_input(s3_data=processed_train_data_s3_uri, \n",
    "#                                          distribution='ShardedByS3Key') \n",
    "# s3_input_validation_data = sagemaker.s3_input(s3_data=processed_validation_data_s3_uri, \n",
    "#                                               distribution='ShardedByS3Key')\n",
    "# s3_input_test_data = sagemaker.s3_input(s3_data=processed_test_data_s3_uri, \n",
    "#                                         distribution='ShardedByS3Key')\n",
    "\n",
    "# print(s3_input_train_data.config)\n",
    "# print(s3_input_validation_data.config)\n",
    "# print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/output/bert/train'\n",
    "validation_dir = 'data/output/bert/validation'\n",
    "test_dir = 'data/output/bert/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "checkpoint_s3_prefix = 'checkpoints/{}'.format(str(uuid.uuid4()))\n",
    "checkpoint_s3_uri = 's3://{}/{}/'.format(bucket, checkpoint_s3_prefix)\n",
    "\n",
    "print(checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "     {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'train:accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "max_seq_length = 128\n",
    "learning_rate=0.00001\n",
    "epsilon=0.00000001\n",
    "model_dir = checkpoint_s3_uri\n",
    "\n",
    "train_batch_size=128\n",
    "validation_batch_size=128\n",
    "test_batch_size=128\n",
    "# train_steps_per_epoch=1000\n",
    "train_steps_per_epoch=1\n",
    "# validation_steps=100\n",
    "validation_steps=1\n",
    "# test_steps=100\n",
    "test_steps=1\n",
    "# train_instance_count=2 # modified by gonsoo\n",
    "# train_instance_type='ml.p3.2xlarge'\n",
    "train_instance_type='local'\n",
    "train_instance_count=1\n",
    "train_volume_size=1024\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "freeze_bert_layer=False\n",
    "enable_sagemaker_debugger=False\n",
    "enable_checkpointing=True\n",
    "# enable_tensorboard=True\n",
    "# input_mode='Pipe'\n",
    "input_mode='File'\n",
    "# run_validation=True\n",
    "run_test=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "local_estimator = TensorFlow(entry_point='tf_script_BERT_tweet.py', \n",
    "#                       source_dir='src', # put requirements.txt in this directory and it gets picked up\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       train_instance_count=train_instance_count, # Make sure you have at least this number of input files or the ShardedByS3Key distibution strategy will fail the job due to no data available\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       train_volume_size=train_volume_size,\n",
    "#                        train_use_spot_instances=True,\n",
    "#                        train_max_wait=7200, # Seconds to wait for spot instances to become available\n",
    "#                        checkpoint_s3_uri=checkpoint_s3_uri, # Not support in local mode\n",
    "                       model_dir = model_dir,\n",
    "                       py_version='py3',\n",
    "                       framework_version='2.1.0',\n",
    "                       script_mode = True,\n",
    "                       hyperparameters={'epochs': epochs,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'epsilon': epsilon,\n",
    "                                        'model_dir': model_dir,\n",
    "                                        'train_batch_size': train_batch_size,\n",
    "                                        'validation_batch_size': validation_batch_size,\n",
    "                                        'test_batch_size': test_batch_size,                                             \n",
    "                                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                                        'validation_steps': validation_steps,\n",
    "                                        'test_steps': test_steps,\n",
    "                                        'use_xla': use_xla,\n",
    "                                        'use_amp': use_amp,                                             \n",
    "                                        'max_seq_length': max_seq_length,\n",
    "                                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                                        'enable_checkpointing': enable_checkpointing\n",
    "                                        },\n",
    "                       input_mode=input_mode,\n",
    "                       metric_definitions=metrics_definitions\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpjp3bxgut_algo-1-w6n6d_1 ... \n",
      "\u001b[1BAttaching to tmpjp3bxgut_algo-1-w6n6d_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:37:56,128 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:37:56,137 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:37:56,311 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:37:56,328 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:37:56,343 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:37:56,352 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"current_host\": \"algo-1-w6n6d\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"algo-1-w6n6d\"\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"learning_rate\": 1e-05,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"epsilon\": 1e-08,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"model_dir\": \"s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"train_batch_size\": 128,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"validation_batch_size\": 128,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"test_batch_size\": 128,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"train_steps_per_epoch\": 1,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"validation_steps\": 1,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"test_steps\": 1,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"use_xla\": true,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"use_amp\": true,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"max_seq_length\": 128,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"freeze_bert_layer\": false,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"enable_checkpointing\": true\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"test\": {\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"job_name\": \"tensorflow-training-2020-06-26-23-37-52-507\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"master_hostname\": \"algo-1-w6n6d\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-2-057716757052/tensorflow-training-2020-06-26-23-37-52-507/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"module_name\": \"tf_script_BERT_tweet\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"num_cpus\": 16,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"current_host\": \"algo-1-w6n6d\",\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m             \"algo-1-w6n6d\"\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     \"user_entry_point\": \"tf_script_BERT_tweet.py\"\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HOSTS=[\"algo-1-w6n6d\"]\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HPS={\"enable_checkpointing\":true,\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":1e-05,\"max_seq_length\":128,\"model_dir\":\"s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\",\"test_batch_size\":128,\"test_steps\":1,\"train_batch_size\":128,\"train_steps_per_epoch\":1,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":1}\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_USER_ENTRY_POINT=tf_script_BERT_tweet.py\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-w6n6d\",\"hosts\":[\"algo-1-w6n6d\"]}\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_CHANNELS=[\"test\",\"train\",\"validation\"]\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_CURRENT_HOST=algo-1-w6n6d\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_MODULE_NAME=tf_script_BERT_tweet\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_NUM_CPUS=16\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-2-057716757052/tensorflow-training-2020-06-26-23-37-52-507/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-w6n6d\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-w6n6d\"],\"hyperparameters\":{\"enable_checkpointing\":true,\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":1e-05,\"max_seq_length\":128,\"model_dir\":\"s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\",\"test_batch_size\":128,\"test_steps\":1,\"train_batch_size\":128,\"train_steps_per_epoch\":1,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-06-26-23-37-52-507\",\"log_level\":20,\"master_hostname\":\"algo-1-w6n6d\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-057716757052/tensorflow-training-2020-06-26-23-37-52-507/source/sourcedir.tar.gz\",\"module_name\":\"tf_script_BERT_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-w6n6d\",\"hosts\":[\"algo-1-w6n6d\"]},\"user_entry_point\":\"tf_script_BERT_tweet.py\"}\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_USER_ARGS=[\"--enable_checkpointing\",\"True\",\"--epochs\",\"1\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"1e-05\",\"--max_seq_length\",\"128\",\"--model_dir\",\"s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\",\"--test_batch_size\",\"128\",\"--test_steps\",\"1\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"1\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"1\"]\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_LEARNING_RATE=1e-05\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_EPSILON=1e-08\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_TRAIN_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_VALIDATION_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_TEST_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_TRAIN_STEPS_PER_EPOCH=1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_VALIDATION_STEPS=1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_TEST_STEPS=1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_USE_XLA=true\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_USE_AMP=true\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_MAX_SEQ_LENGTH=128\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_FREEZE_BERT_LAYER=false\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m SM_HP_ENABLE_CHECKPOINTING=true\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m /usr/bin/python3 tf_script_BERT_tweet.py --enable_checkpointing True --epochs 1 --epsilon 1e-08 --freeze_bert_layer False --learning_rate 1e-05 --max_seq_length 128 --model_dir s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/ --test_batch_size 128 --test_steps 1 --train_batch_size 128 --train_steps_per_epoch 1 --use_amp True --use_xla True --validation_batch_size 128 --validation_steps 1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting transformers==2.8.0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading transformers-2.8.0-py3-none-any.whl (563 kB)\n",
      "\u001b[K     |████████████████████████████████| 563 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hCollecting sentencepiece\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 8.0 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hCollecting filelock\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting tqdm>=4.27\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading tqdm-4.46.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 3.8 MB/s  eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hCollecting sacremoses\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 16.2 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting tokenizers==0.5.2\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 14.4 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hCollecting dataclasses; python_version < \"3.7\"\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading dataclasses-0.7-py3-none-any.whl (18 kB)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.12.43)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting regex!=2019.12.17\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading regex-2020.6.8-cp36-cp36m-manylinux2010_x86_64.whl (660 kB)\n",
      "\u001b[K     |████████████████████████████████| 660 kB 46.0 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.22.0)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.14.0)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.14.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.9.5)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.15.43)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.25.9)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.8)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers==2.8.0) (0.15.2)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers==2.8.0) (2.8.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Building wheels for collected packages: sacremoses\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=daccaee9844324ef927bae8e1411441988f30d2b9aaf52a38596c5bc3c004cf9\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Successfully built sacremoses\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Installing collected packages: sentencepiece, filelock, tqdm, regex, sacremoses, tokenizers, dataclasses, transformers\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Successfully installed dataclasses-0.7 filelock-3.0.12 regex-2020.6.8 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.5.2 tqdm-4.46.1 transformers-2.8.0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: sagemaker-tensorflow==2.1.0.1.0.0 in /usr/local/lib/python3.6/dist-packages (2.1.0.1.0.0)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting smdebug==0.8.0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading smdebug-0.8.0-py2.py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (1.18.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: boto3>=1.10.32 in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (1.12.43)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (3.11.3)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from smdebug==0.8.0) (20.3)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.10.32->smdebug==0.8.0) (1.15.43)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.10.32->smdebug==0.8.0) (0.3.3)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.10.32->smdebug==0.8.0) (0.9.5)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->smdebug==0.8.0) (1.14.0)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->smdebug==0.8.0) (46.1.3)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->smdebug==0.8.0) (2.4.7)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3>=1.10.32->smdebug==0.8.0) (2.8.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3>=1.10.32->smdebug==0.8.0) (1.25.9)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3>=1.10.32->smdebug==0.8.0) (0.15.2)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Installing collected packages: smdebug\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Attempting uninstall: smdebug\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     Found existing installation: smdebug 0.7.2\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     Uninstalling smdebug-0.7.2:\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m       Successfully uninstalled smdebug-0.7.2\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Successfully installed smdebug-0.8.0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting scikit-learn==0.23.1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (0.14.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.4.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.18.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting threadpoolctl>=2.0.0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Installing collected packages: threadpoolctl, scikit-learn\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Attempting uninstall: scikit-learn\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     Found existing installation: scikit-learn 0.22\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m     Uninstalling scikit-learn-0.22:\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m       Successfully uninstalled scikit-learn-0.22\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Successfully installed scikit-learn-0.23.1 threadpoolctl-2.1.0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting matplotlib==3.2.1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (1.18.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting kiwisolver>=1.0.1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 14.5 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (2.8.1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Collecting cycler>=0.10\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m   Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (2.4.7)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib==3.2.1) (1.14.0)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.2.1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m ################ Args: #######################\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Namespace(checkpoint_base_path='/opt/ml/checkpoints', current_host='algo-1-w6n6d', enable_checkpointing=True, epochs=1, epsilon=1e-08, freeze_bert_layer=False, hosts=['algo-1-w6n6d'], learning_rate=1e-05, max_seq_length=128, model_dir='s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/', num_gpus=0, output_dir='/opt/ml/output', run_sample_predictions=False, run_test=False, run_validation=False, test_batch_size=128, test_data='/opt/ml/input/data/test', test_steps=1, train_batch_size=128, train_data='/opt/ml/input/data/train', train_steps_per_epoch=1, use_amp=True, use_xla=True, validation_batch_size=128, validation_data='/opt/ml/input/data/validation', validation_steps=1)\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m ################ Environment Variables: ################\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m {'AWS_REGION': 'us-east-2',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'CURRENT_HOST': 'algo-1-w6n6d',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'DEBCONF_NONINTERACTIVE_SEEN': 'true',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'DEBIAN_FRONTEND': 'noninteractive',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'HOME': '/root',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'HOSTNAME': '84486904f4be',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'KMP_AFFINITY': 'granularity=fine,compact,1,0',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'KMP_BLOCKTIME': '1',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'KMP_DUPLICATE_LIB_OK': 'True',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'KMP_INIT_AT_FORK': 'FALSE',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'KMP_SETTINGS': '0',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'LANG': 'C.UTF-8',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'LC_ALL': 'C.UTF-8',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'LD_LIBRARY_PATH': '/usr/local/openmpi/lib:',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'PATH': '/usr/local/openmpi/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'PYTHONDONTWRITEBYTECODE': '1',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'PYTHONIOENCODING': 'UTF-8',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'PYTHONPATH': '/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'PYTHONUNBUFFERED': '1',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'S3_REGION': 'us-east-2',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'S3_USE_HTTPS': '1',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SAGEMAKER_JOB_NAME': 'tensorflow-training-2020-06-26-23-37-52-507',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SAGEMAKER_REGION': 'us-east-2',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SAGEMAKER_TRAINING_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_CHANNELS': '[\"test\",\"train\",\"validation\"]',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_CHANNEL_TEST': '/opt/ml/input/data/test',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_CHANNEL_VALIDATION': '/opt/ml/input/data/validation',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_CURRENT_HOST': 'algo-1-w6n6d',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_FRAMEWORK_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_FRAMEWORK_PARAMS': '{}',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HOSTS': '[\"algo-1-w6n6d\"]',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HPS': '{\"enable_checkpointing\":true,\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":1e-05,\"max_seq_length\":128,\"model_dir\":\"s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\",\"test_batch_size\":128,\"test_steps\":1,\"train_batch_size\":128,\"train_steps_per_epoch\":1,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":1}',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_ENABLE_CHECKPOINTING': 'true',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_EPOCHS': '1',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_EPSILON': '1e-08',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_FREEZE_BERT_LAYER': 'false',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_LEARNING_RATE': '1e-05',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_MAX_SEQ_LENGTH': '128',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_MODEL_DIR': 's3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_TEST_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_TEST_STEPS': '1',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_TRAIN_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_TRAIN_STEPS_PER_EPOCH': '1',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_USE_AMP': 'true',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_USE_XLA': 'true',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_VALIDATION_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_HP_VALIDATION_STEPS': '1',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_INPUT_DATA_CONFIG': '{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_INPUT_DIR': '/opt/ml/input',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_LOG_LEVEL': '20',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_MODEL_DIR': '/opt/ml/model',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_MODULE_DIR': 's3://sagemaker-us-east-2-057716757052/tensorflow-training-2020-06-26-23-37-52-507/source/sourcedir.tar.gz',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_MODULE_NAME': 'tf_script_BERT_tweet',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_NETWORK_INTERFACE_NAME': 'eth0',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_NUM_CPUS': '16',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_NUM_GPUS': '0',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_OUTPUT_DIR': '/opt/ml/output',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-w6n6d\",\"hosts\":[\"algo-1-w6n6d\"]}',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-w6n6d\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-w6n6d\"],\"hyperparameters\":{\"enable_checkpointing\":true,\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":1e-05,\"max_seq_length\":128,\"model_dir\":\"s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\",\"test_batch_size\":128,\"test_steps\":1,\"train_batch_size\":128,\"train_steps_per_epoch\":1,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-06-26-23-37-52-507\",\"log_level\":20,\"master_hostname\":\"algo-1-w6n6d\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-057716757052/tensorflow-training-2020-06-26-23-37-52-507/source/sourcedir.tar.gz\",\"module_name\":\"tf_script_BERT_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-w6n6d\",\"hosts\":[\"algo-1-w6n6d\"]},\"user_entry_point\":\"tf_script_BERT_tweet.py\"}',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_USER_ARGS': '[\"--enable_checkpointing\",\"True\",\"--epochs\",\"1\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"1e-05\",\"--max_seq_length\",\"128\",\"--model_dir\",\"s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\",\"--test_batch_size\",\"128\",\"--test_steps\",\"1\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"1\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"1\"]',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'SM_USER_ENTRY_POINT': 'tf_script_BERT_tweet.py',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'TERM': 'xterm',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'TF_CPP_MIN_LOG_LEVEL': '1',\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  'TRAINING_JOB_NAME': 'tensorflow-training-2020-06-26-23-37-52-507'}\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m ################ Extract varaibles from Command Args #######################\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m is_master True\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m train_data /opt/ml/input/data/train\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m validation_data /opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m test_data /opt/ml/input/data/test\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m local_model_dir s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m output_dir /opt/ml/output\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m hosts ['algo-1-w6n6d']\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m current_host algo-1-w6n6d\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m num_gpus 0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m job_name tensorflow-training-2020-06-26-23-37-52-507\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m use_xla True\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m use_amp True\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m max_seq_length 128\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m train_batch_size 128\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m validation_batch_size 128\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m test_batch_size 128\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m epochs 1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m learning_rate 1e-05\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m epsilon 1e-08\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m train_steps_per_epoch 1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m validation_steps 1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m test_steps 1\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m freeze_bert_layer False\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m run_validation False\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m run_test False\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m run_sample_predictions False\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m enable_checkpointing True\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m checkpoint_base_path /opt/ml/checkpoints\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m  ################ Set Checkpoint path: ################\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m checkpoint_path /opt/ml/checkpoints\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Using pipe_mode: False\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m ################ Mirrored distributed_strategy ################\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m train_data_filenames ['/opt/ml/input/data/train/part-unknown-tweet_file_02.tfrecord', '/opt/ml/input/data/train/part-unknown-tweet_file_01.tfrecord']\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m ***** Using input_filenames ['/opt/ml/input/data/train/part-unknown-tweet_file_02.tfrecord', '/opt/ml/input/data/train/part-unknown-tweet_file_01.tfrecord']\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:From tf_script_BERT_tweet.py:88: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 5.10MB/s]\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Retry #1.  Sleeping for 4 seconds\n",
      "Downloading: 100% 442/442 [00:00<00:00, 392kB/s]\n",
      "Downloading: 100% 363M/363M [00:05<00:00, 63.5MB/s] \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:38:35.068829: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Sucessfully downloaded after 1 retries.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m ***** Checkpoint enabled *****\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m *** CHECKPOINT CALLBACK <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb9d40ee908> ***\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m ** use_amp True\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m *** OPTIMIZER <tensorflow.python.keras.mixed_precision.experimental.loss_scale_optimizer.LossScaleOptimizer object at 0x7fb9d403b208> ***\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Compiled model <transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification object at 0x7fb9d40f4dd8>\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m distilbert (TFDistilBertMain multiple                  66362880  \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m pre_classifier (Dense)       multiple                  590592    \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m classifier (Dense)           multiple                  7690      \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m dropout_19 (Dropout)         multiple                  0         \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Total params: 66,961,162\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Trainable params: 66,961,162\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Non-trainable params: 0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m None\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Starting Training (Without Validation)...\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Train for 1 steps\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:38:46.767111: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1892] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:38:48.025501: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1574] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m \n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Epoch 00001: saving model to /opt/ml/checkpoints/tf_model_00001.h5\n",
      "1/1 [==============================] - 25s 25s/step - loss: 2.3019 - accuracy: 0.0938\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:39:03.615078: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m <tensorflow.python.keras.callbacks.History object at 0x7fb96430a898>\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m transformer_fine_tuned_model_path s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/transformers/fine-tuned/\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m INFO:transformers.configuration_utils:Configuration saved in s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/transformers/fine-tuned/config.json\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m INFO:transformers.modeling_tf_utils:Model weights saved in s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/transformers/fine-tuned/tf_model.h5\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m ##################### Write Saved Model ###############################\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m tensorflow_saved_model_path s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/0\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9d40f7ef0>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9d40f7ef0>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9985ff8d0>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9985ff8d0>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb998518f98>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb998518f98>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9985306a0>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9985306a0>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9cc165d68>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9cc165d68>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9cc17e470>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fb9cc17e470>, because it is not built.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m INFO:tensorflow:Assets written to: s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/0/assets\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m INFO:tensorflow:Assets written to: s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/0/assets\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:39:18,789 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m For details of how to construct your training script see:\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m https://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\n",
      "\u001b[36malgo-1-w6n6d_1  |\u001b[0m 2020-06-26 23:39:18,789 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpjp3bxgut_algo-1-w6n6d_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "inputs = {'train': f'file://{train_dir}',\n",
    "          'validation': f'file://{validation_dir}',\n",
    "          'test': f'file://{test_dir}'}\n",
    "local_estimator.fit(inputs)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 ls {checkpoint_s3_uri}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-26 23:39:13          0 checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/\n",
      "2020-06-26 23:39:13          0 checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/\n",
      "2020-06-26 23:39:13          0 checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/\n",
      "2020-06-26 23:39:13          0 checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/0/\n",
      "2020-06-26 23:39:18          0 checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/0/assets/\n",
      "2020-06-26 23:39:18    4787957 checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/0/saved_model.pb\n",
      "2020-06-26 23:39:13          0 checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/0/variables/\n",
      "2020-06-26 23:39:16  803602808 checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/0/variables/variables.data-00000-of-00001\n",
      "2020-06-26 23:39:17      23052 checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/tensorflow/saved_model/0/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls s3://sagemaker-us-east-2-057716757052/checkpoints/007a0b72-c4dc-4b82-9658-d5d513380525/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
