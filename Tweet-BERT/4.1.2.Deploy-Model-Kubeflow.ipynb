{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.1.2] inference on model from Kubeflow\n",
    "\n",
    "\n",
    "---\n",
    "이 노트북은 약 10정도 시간이 소요 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Train Model from KubeFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker train job from KubeFlow: \n",
      " s3://sagemaker-ap-northeast-2-343441690612/sagemaker-scikit-learn-2020-08-02-01-14-52-546/model/TrainingJob-20200802135153-A952/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data = 's3://sagemaker-ap-northeast-2-343441690612/sagemaker-scikit-learn-2020-08-02-01-14-52-546/model/TrainingJob-20200802135153-A952/output/model.tar.gz'\n",
    "print('sagemaker train job from KubeFlow: \\n', model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_image:  343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:2.0.0-cpu\n"
     ]
    }
   ],
   "source": [
    "inference_image = '343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:2.0.0-cpu'\n",
    "print(\"inference_image: \", inference_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엔드포인트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!CPU times: user 1min 4s, sys: 11.2 s, total: 1min 15s\n",
      "Wall time: 8min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data= model_data,\n",
    "              role=role,\n",
    "              entry_point='inference.py',\n",
    "              image = inference_image\n",
    "             ) \n",
    "\n",
    "instance_type='ml.m4.xlarge'\n",
    "deployed_model = model.deploy(initial_instance_count = 1,\n",
    "                             instance_type = instance_type,\n",
    "                             wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Creation on the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-tensorflow-serving-2020-08-02-14-33-21-637\n"
     ]
    }
   ],
   "source": [
    "# tweet_bert_endpoint_name = 'train_text, train_label, test_text, test_label = tweet_data.split_train_test_data(texts, labels, 0.9)\n",
    "tweet_bert_endpoint_name = deployed_model.endpoint\n",
    "print(tweet_bert_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "\n",
    "predictor = Predictor(endpoint_name = tweet_bert_endpoint_name,\n",
    "                      sagemaker_session = sess,\n",
    "                      content_type = 'application/json',\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji_to_idx is loaded\n",
      "😂\n"
     ]
    }
   ],
   "source": [
    "from TweetUtil import TweetUtil\n",
    "\n",
    "tweet_util = TweetUtil()\n",
    "tweet_util.load_emoji_data('emoji_to_idx.pickle')\n",
    "emoji = tweet_util.get_emo_class_label(3)\n",
    "print(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>if high school musical was fifty shades of grey</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>my whole check is gone i haven't even got pai...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8541</th>\n",
       "      <td>just better be upset</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>thats why i fired yo bitch ass at auntie annie's</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>jumping at camera hates his pic took staffies...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5785</th>\n",
       "      <td>i love you you made my day thank you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>stomach killing me</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>jewelcandle a jewel in every candle mondaymoti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7268</th>\n",
       "      <td>lost my homework from work because mfs wanna t...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>i'm not check bio</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  LABEL\n",
       "8104    if high school musical was fifty shades of grey      7\n",
       "4788   my whole check is gone i haven't even got pai...      8\n",
       "8541                               just better be upset      8\n",
       "8914   thats why i fired yo bitch ass at auntie annie's      8\n",
       "39     jumping at camera hates his pic took staffies...      0\n",
       "5785              i love you you made my day thank you       0\n",
       "4660                                 stomach killing me      7\n",
       "4093  jewelcandle a jewel in every candle mondaymoti...      1\n",
       "7268  lost my homework from work because mfs wanna t...      8\n",
       "8513                                  i'm not check bio      3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "sample_df = test_df.sample(10)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_N_label(score_list, topN):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    top_n_idx = np.argsort(score_list)[-topN:]\n",
    "    top_n_values = [score_list[i] for i in top_n_idx]\n",
    "    \n",
    "    top_n_idx_list = top_n_idx.tolist()\n",
    "    top_n_idx_list.reverse()\n",
    "    top_n_values = [score_list[i] for i in top_n_idx_list]    \n",
    "    \n",
    "    return top_n_idx_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 이모티콘 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  if high school musical was fifty shades of grey \n",
      "Ground_truth- 7:😭\n",
      " \n",
      "Prediction: 5,😍,7,😭,0,❤,2,🔥,4,😊 \n",
      " \n",
      "tweet:  my whole check is gone i haven't even got paid yet \n",
      "Ground_truth- 8:🙄\n",
      " \n",
      "Prediction: 4,😊,8,🙄,7,😭,0,❤,9,🤔 \n",
      " \n",
      "tweet:  just better be upset \n",
      "Ground_truth- 8:🙄\n",
      " \n",
      "Prediction: 6,😩,8,🙄,9,🤔,3,😂,7,😭 \n",
      " \n",
      "tweet: thats why i fired yo bitch ass at auntie annie's \n",
      "Ground_truth- 8:🙄\n",
      " \n",
      "Prediction: 8,🙄,9,🤔,7,😭,2,🔥,4,😊 \n",
      " \n",
      "tweet:  jumping at camera hates his pic took staffiesaturday fishface \n",
      "Ground_truth- 0:❤\n",
      " \n",
      "Prediction: 7,😭,8,🙄,9,🤔,4,😊,3,😂 \n",
      " \n",
      "tweet:  i love you you made my day thank you  \n",
      "Ground_truth- 0:❤\n",
      " \n",
      "Prediction: 1,💕,0,❤,4,😊,5,😍,9,🤔 \n",
      " \n",
      "tweet: stomach killing me \n",
      "Ground_truth- 7:😭\n",
      " \n",
      "Prediction: 7,😭,5,😍,3,😂,0,❤,8,🙄 \n",
      " \n",
      "tweet: jewelcandle a jewel in every candle mondaymotivation firstdayofschool \n",
      "Ground_truth- 1:💕\n",
      " \n",
      "Prediction: 4,😊,5,😍,0,❤,1,💕,2,🔥 \n",
      " \n",
      "tweet: lost my homework from work because mfs wanna touch it and then put it somewhere it wasn't at \n",
      "Ground_truth- 8:🙄\n",
      " \n",
      "Prediction: 8,🙄,9,🤔,7,😭,6,😩,4,😊 \n",
      " \n",
      "tweet:  i'm not check bio \n",
      "Ground_truth- 3:😂\n",
      " \n",
      "Prediction: 4,😊,7,😭,8,🙄,3,😂,5,😍 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "columns = ['TWEET', 'LABEL']\n",
    "topN = 5\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    tweets = [tweet]    \n",
    "    predicted_classes = predictor.predict(tweets)[0]\n",
    "    predicted_classes = show_top_N_label(predicted_classes, topN)\n",
    "\n",
    "    print('tweet: {} \\nGround_truth- {}:{}\\n '.format(\n",
    "        tweet,\n",
    "        label, \n",
    "        tweet_util.get_emo_class_label(label))\n",
    "         )    \n",
    "    print('Prediction: {},{},{},{},{},{},{},{},{},{} \\n '.format(\n",
    "        predicted_classes[0], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[0]),\n",
    "        predicted_classes[1], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[1]),\n",
    "        predicted_classes[2], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[2]),   \n",
    "        predicted_classes[3], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[3]),                                      \n",
    "        predicted_classes[4], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[4]),                                      \n",
    "        ))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
