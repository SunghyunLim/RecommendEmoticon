{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 3.2] On a Local Mode, Train a BERT Model with Tensorflow\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 진행 합니다. 로컬 모드를 사용하는 이유는 Train Script의 로직이 맞는지를 주로 확인하는데 사용 합니다. 로컬 모드로 로직 확인이 완료 되면 Script Mode (BYOS, Bring Your Own Script)혹은 필요할 경우에 BYOC(Bring Your Own Container)로 학습을 합니다.\n",
    "\n",
    "- 학습할 데이타를 S3로 지정\n",
    "- Train 학습 파리미터 설정\n",
    "- Estimator를 생성하고 tf_script_bert_tweet.py Train Script를 지정\n",
    "- Estimator를 를 로컬 모드로 실행\n",
    "    \n",
    "---\n",
    "이 노트북은 약 3분 소요 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  로컬모드 (Local Mode) 학습 <a class=\"anchor\" id=\"LocalModeTraining\">\n",
    "\n",
    "SageMaker에서 로컬 모드는, 여러분이 작성한 코드를 SageMaker에서 관리되는 보다 강력한 클러스터에서 실행하기 전에, 여러분의 코드가 기대한 방식으로 동작하는 지 로컬에서 확인할 수 있는 편리한 방식입니다. 로컬모드 학습을 위해서는 docker-compose 또는 nvidia-docker-compose (GPU 인스턴스인 경우)의 설치가 필요합니다. 다음 셀의 명령은 본 노트북환경에 docker-compose 또는 nvidia-docker-compose를 설치하고 구성합니다. \n",
    "    \n",
    "스크립트 모드를 사용하기 위해서 아래의 API 문서 참고 하세요\n",
    "- Script Mode Ref:\n",
    "    - https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#train-a-model-with-tensorflow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/local_mode_setup.sh\n",
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/daemon.json    \n",
    "!/bin/bash ./local_mode_setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-ap-northeast-2-343441690612/sagemaker-scikit-learn-2020-08-17-09-41-31-333/output/bert-train', 'S3DataDistributionType': 'FullyReplicated'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-ap-northeast-2-343441690612/sagemaker-scikit-learn-2020-08-17-09-41-31-333/output/bert-validation', 'S3DataDistributionType': 'FullyReplicated'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-ap-northeast-2-343441690612/sagemaker-scikit-learn-2020-08-17-09-41-31-333/output/bert-test', 'S3DataDistributionType': 'FullyReplicated'}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s3_input_train_data = sagemaker.s3_input(s3_data=processed_train_data_s3_uri) \n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=processed_validation_data_s3_uri)\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=processed_test_data_s3_uri)\n",
    "\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uuid를 생성하여 checkpoint 파일이 저장될 폴더를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-northeast-2-343441690612/checkpoints/760f4189-c5cb-4b74-97ce-f1966ca7e58f/\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "checkpoint_s3_prefix = 'checkpoints/{}'.format(str(uuid.uuid4()))\n",
    "checkpoint_s3_uri = 's3://{}/{}/'.format(bucket, checkpoint_s3_prefix)\n",
    "\n",
    "print(checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics를 정의하여 CloudWatch에서 모니터링을 할 수 있게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "     {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'train:accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "max_seq_length = 32\n",
    "learning_rate=0.00001\n",
    "epsilon=0.00000001\n",
    "\n",
    "train_batch_size=128\n",
    "validation_batch_size=128\n",
    "test_batch_size=128\n",
    "\n",
    "train_steps_per_epoch=1\n",
    "validation_steps=1\n",
    "test_steps=1\n",
    "\n",
    "train_instance_type='local'\n",
    "train_instance_count=1\n",
    "train_volume_size=1024\n",
    "\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "\n",
    "freeze_bert_layer=False\n",
    "\n",
    "enable_sagemaker_debugger=False\n",
    "enable_checkpointing=True\n",
    "\n",
    "# input_mode='Pipe'\n",
    "input_mode='File'\n",
    "run_validation=True\n",
    "run_test=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "local_estimator = TensorFlow(entry_point='tf_script_bert_tweet.py', \n",
    "#                       source_dir='src', # put requirements.txt in this directory and it gets picked up\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       train_instance_count=train_instance_count, # Make sure you have at least this number of input files or the ShardedByS3Key distibution strategy will fail the job due to no data available\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       train_volume_size=train_volume_size,\n",
    "#                        train_use_spot_instances=True, # Not support in local mode\n",
    "#                        train_max_wait=7200, # Seconds to wait for spot instances to become available\n",
    "#                        checkpoint_s3_uri=checkpoint_s3_uri, # Not support in local mode\n",
    "                       py_version='py3',\n",
    "                       framework_version='2.1.0',\n",
    "                       script_mode = True,\n",
    "                       hyperparameters={'epochs': epochs,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'epsilon': epsilon,\n",
    "                                        'train_batch_size': train_batch_size,\n",
    "                                        'validation_batch_size': validation_batch_size,\n",
    "                                        'test_batch_size': test_batch_size,                                             \n",
    "                                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                                        'validation_steps': validation_steps,\n",
    "                                        'test_steps': test_steps,\n",
    "                                        'use_xla': use_xla,\n",
    "                                        'use_amp': use_amp,                                             \n",
    "                                        'max_seq_length': max_seq_length,\n",
    "                                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                                        'enable_checkpointing': enable_checkpointing\n",
    "                                        },\n",
    "                       input_mode=input_mode,\n",
    "                       metric_definitions=metrics_definitions\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input 위치 지정하고 Train 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpikr_h4cd_algo-1-usz92_1 ... \n",
      "\u001b[1BAttaching to tmpikr_h4cd_algo-1-usz92_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:53:25,369 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:53:25,376 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:53:25,566 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:53:25,580 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:53:25,592 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:53:25,601 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"current_host\": \"algo-1-usz92\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"algo-1-usz92\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"learning_rate\": 1e-05,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"epsilon\": 1e-08,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"train_batch_size\": 128,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"validation_batch_size\": 128,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"test_batch_size\": 128,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"train_steps_per_epoch\": 1,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"validation_steps\": 1,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"test_steps\": 1,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"use_xla\": true,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"use_amp\": true,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"max_seq_length\": 32,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"freeze_bert_layer\": false,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"enable_checkpointing\": true,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"model_dir\": \"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"test\": {\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"job_name\": \"tensorflow-training-2020-08-17-09-53-21-050\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"master_hostname\": \"algo-1-usz92\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"module_name\": \"tf_script_bert_tweet\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"current_host\": \"algo-1-usz92\",\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m             \"algo-1-usz92\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     \"user_entry_point\": \"tf_script_bert_tweet.py\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HOSTS=[\"algo-1-usz92\"]\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HPS={\"enable_checkpointing\":true,\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":1e-05,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model\",\"test_batch_size\":128,\"test_steps\":1,\"train_batch_size\":128,\"train_steps_per_epoch\":1,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":1}\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_USER_ENTRY_POINT=tf_script_bert_tweet.py\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-usz92\",\"hosts\":[\"algo-1-usz92\"]}\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_CHANNELS=[\"test\",\"train\",\"validation\"]\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_CURRENT_HOST=algo-1-usz92\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_MODULE_NAME=tf_script_bert_tweet\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-usz92\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-usz92\"],\"hyperparameters\":{\"enable_checkpointing\":true,\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":1e-05,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model\",\"test_batch_size\":128,\"test_steps\":1,\"train_batch_size\":128,\"train_steps_per_epoch\":1,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-08-17-09-53-21-050\",\"log_level\":20,\"master_hostname\":\"algo-1-usz92\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/source/sourcedir.tar.gz\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-usz92\",\"hosts\":[\"algo-1-usz92\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_USER_ARGS=[\"--enable_checkpointing\",\"True\",\"--epochs\",\"1\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"1e-05\",\"--max_seq_length\",\"32\",\"--model_dir\",\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model\",\"--test_batch_size\",\"128\",\"--test_steps\",\"1\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"1\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"1\"]\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_LEARNING_RATE=1e-05\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_EPSILON=1e-08\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_TRAIN_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_VALIDATION_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_TEST_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_TRAIN_STEPS_PER_EPOCH=1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_VALIDATION_STEPS=1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_TEST_STEPS=1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_USE_XLA=true\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_USE_AMP=true\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_MAX_SEQ_LENGTH=32\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_FREEZE_BERT_LAYER=false\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_ENABLE_CHECKPOINTING=true\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m /usr/bin/python3 tf_script_bert_tweet.py --enable_checkpointing True --epochs 1 --epsilon 1e-08 --freeze_bert_layer False --learning_rate 1e-05 --max_seq_length 32 --model_dir s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model --test_batch_size 128 --test_steps 1 --train_batch_size 128 --train_steps_per_epoch 1 --use_amp True --use_xla True --validation_batch_size 128 --validation_steps 1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Collecting transformers==2.8.0\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading transformers-2.8.0-py3-none-any.whl (563 kB)\n",
      "\u001b[K     |████████████████████████████████| 563 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[?25hCollecting sacremoses\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[?25hCollecting dataclasses; python_version < \"3.7\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading dataclasses-0.7-py3-none-any.whl (18 kB)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Collecting regex!=2019.12.17\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660 kB)\n",
      "\u001b[K     |████████████████████████████████| 660 kB 6.9 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[?25hCollecting tqdm>=4.27\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 6.3 MB/s eta 0:00:011\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.12.43)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Collecting tokenizers==0.5.2\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 7.0 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[?25hCollecting sentencepiece\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 16.3 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.1)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.22.0)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Collecting filelock\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.14.0)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.1)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.14.1)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.9.5)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.15.43)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.8)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.25.9)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers==2.8.0) (2.8.1)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers==2.8.0) (0.15.2)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Building wheels for collected packages: sacremoses\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=ad30517c7a2dc855dc74dc48e35a1da9e62c0354c585823d358143b83a3e0080\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Successfully built sacremoses\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Installing collected packages: regex, tqdm, sacremoses, dataclasses, tokenizers, sentencepiece, filelock, transformers\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Successfully installed dataclasses-0.7 filelock-3.0.12 regex-2020.7.14 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.5.2 tqdm-4.48.2 transformers-2.8.0\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: sagemaker-tensorflow==2.1.0.1.0.0 in /usr/local/lib/python3.6/dist-packages (2.1.0.1.0.0)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Collecting scikit-learn==0.23.1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (0.14.1)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Collecting threadpoolctl>=2.0.0\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.4.1)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.18.1)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Installing collected packages: threadpoolctl, scikit-learn\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m   Attempting uninstall: scikit-learn\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     Found existing installation: scikit-learn 0.22\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m     Uninstalling scikit-learn-0.22:\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m       Successfully uninstalled scikit-learn-0.22\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Successfully installed scikit-learn-0.23.1 threadpoolctl-2.1.0\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m ################ Args: #######################\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Namespace(checkpoint_base_path='/opt/ml/checkpoints', current_host='algo-1-usz92', enable_checkpointing=True, epochs=1, epsilon=1e-08, freeze_bert_layer=False, hosts=['algo-1-usz92'], learning_rate=1e-05, max_seq_length=32, model_dir='s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model', num_gpus=0, output_dir='/opt/ml/output', run_sample_predictions=False, run_test=False, run_validation=False, test_batch_size=128, test_data='/opt/ml/input/data/test', test_steps=1, train_batch_size=128, train_data='/opt/ml/input/data/train', train_steps_per_epoch=1, use_amp=True, use_xla=True, validation_batch_size=128, validation_data='/opt/ml/input/data/validation', validation_steps=1)\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m ################ Environment Variables: ################\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m {'AWS_REGION': 'ap-northeast-2',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'CURRENT_HOST': 'algo-1-usz92',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'DEBCONF_NONINTERACTIVE_SEEN': 'true',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'DEBIAN_FRONTEND': 'noninteractive',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'HOME': '/root',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'HOSTNAME': '29290621fbca',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'KMP_AFFINITY': 'granularity=fine,compact,1,0',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'KMP_BLOCKTIME': '1',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'KMP_DUPLICATE_LIB_OK': 'True',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'KMP_INIT_AT_FORK': 'FALSE',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'KMP_SETTINGS': '0',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'LANG': 'C.UTF-8',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'LC_ALL': 'C.UTF-8',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'LD_LIBRARY_PATH': '/usr/local/openmpi/lib:',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'PATH': '/usr/local/openmpi/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'PYTHONDONTWRITEBYTECODE': '1',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'PYTHONIOENCODING': 'UTF-8',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'PYTHONPATH': '/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'PYTHONUNBUFFERED': '1',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'S3_REGION': 'ap-northeast-2',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'S3_USE_HTTPS': '1',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SAGEMAKER_JOB_NAME': 'tensorflow-training-2020-08-17-09-53-21-050',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SAGEMAKER_REGION': 'ap-northeast-2',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SAGEMAKER_TRAINING_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_CHANNELS': '[\"test\",\"train\",\"validation\"]',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_CHANNEL_TEST': '/opt/ml/input/data/test',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_CHANNEL_VALIDATION': '/opt/ml/input/data/validation',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_CURRENT_HOST': 'algo-1-usz92',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_FRAMEWORK_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_FRAMEWORK_PARAMS': '{}',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HOSTS': '[\"algo-1-usz92\"]',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HPS': '{\"enable_checkpointing\":true,\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":1e-05,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model\",\"test_batch_size\":128,\"test_steps\":1,\"train_batch_size\":128,\"train_steps_per_epoch\":1,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":1}',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_ENABLE_CHECKPOINTING': 'true',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_EPOCHS': '1',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_EPSILON': '1e-08',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_FREEZE_BERT_LAYER': 'false',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_LEARNING_RATE': '1e-05',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_MAX_SEQ_LENGTH': '32',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_MODEL_DIR': 's3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_TEST_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_TEST_STEPS': '1',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_TRAIN_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_TRAIN_STEPS_PER_EPOCH': '1',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_USE_AMP': 'true',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_USE_XLA': 'true',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_VALIDATION_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_HP_VALIDATION_STEPS': '1',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_INPUT_DATA_CONFIG': '{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_INPUT_DIR': '/opt/ml/input',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_LOG_LEVEL': '20',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_MODEL_DIR': '/opt/ml/model',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_MODULE_DIR': 's3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/source/sourcedir.tar.gz',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_MODULE_NAME': 'tf_script_bert_tweet',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_NETWORK_INTERFACE_NAME': 'eth0',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_NUM_CPUS': '8',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_NUM_GPUS': '0',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_OUTPUT_DIR': '/opt/ml/output',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-usz92\",\"hosts\":[\"algo-1-usz92\"]}',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-usz92\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-usz92\"],\"hyperparameters\":{\"enable_checkpointing\":true,\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":1e-05,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model\",\"test_batch_size\":128,\"test_steps\":1,\"train_batch_size\":128,\"train_steps_per_epoch\":1,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-08-17-09-53-21-050\",\"log_level\":20,\"master_hostname\":\"algo-1-usz92\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/source/sourcedir.tar.gz\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-usz92\",\"hosts\":[\"algo-1-usz92\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_USER_ARGS': '[\"--enable_checkpointing\",\"True\",\"--epochs\",\"1\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"1e-05\",\"--max_seq_length\",\"32\",\"--model_dir\",\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model\",\"--test_batch_size\",\"128\",\"--test_steps\",\"1\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"1\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"1\"]',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'SM_USER_ENTRY_POINT': 'tf_script_bert_tweet.py',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'TERM': 'xterm',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'TF_CPP_MIN_LOG_LEVEL': '1',\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  'TRAINING_JOB_NAME': 'tensorflow-training-2020-08-17-09-53-21-050'}\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m SM_TRAINING_ENV {\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-usz92\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-usz92\"],\"hyperparameters\":{\"enable_checkpointing\":true,\"epochs\":1,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":1e-05,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/model\",\"test_batch_size\":128,\"test_steps\":1,\"train_batch_size\":128,\"train_steps_per_epoch\":1,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-08-17-09-53-21-050\",\"log_level\":20,\"master_hostname\":\"algo-1-usz92\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-17-09-53-21-050/source/sourcedir.tar.gz\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-usz92\",\"hosts\":[\"algo-1-usz92\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m ################ Extract varaibles from Command Args #######################\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m train_data /opt/ml/input/data/train\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m validation_data /opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m test_data /opt/ml/input/data/test\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m local_model_dir /opt/ml/model\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m output_dir /opt/ml/output\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m hosts ['algo-1-usz92']\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m current_host algo-1-usz92\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m num_gpus 0\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m job_name tensorflow-training-2020-08-17-09-53-21-050\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m use_xla True\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m use_amp True\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m max_seq_length 32\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m train_batch_size 128\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m validation_batch_size 128\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m test_batch_size 128\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m epochs 1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m learning_rate 1e-05\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m epsilon 1e-08\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m train_steps_per_epoch 1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m validation_steps 1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m test_steps 1\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m freeze_bert_layer False\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m run_validation False\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m run_test False\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m run_sample_predictions False\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m enable_checkpointing True\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m checkpoint_base_path /opt/ml/checkpoints\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m  ################ Set Checkpoint path: ################\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m checkpoint_path /opt/ml/checkpoints\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Using pipe_mode: False\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m ################ Mirrored distributed_strategy ################\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m train_data_filenames ['/opt/ml/input/data/train/part-algo-1-tweet_file_01.tfrecord', '/opt/ml/input/data/train/part-algo-2-tweet_file_02.tfrecord']\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m ***** Using input_filenames ['/opt/ml/input/data/train/part-algo-1-tweet_file_01.tfrecord', '/opt/ml/input/data/train/part-algo-2-tweet_file_02.tfrecord']\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:From tf_script_bert_tweet.py:94: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 396kB/s]  \n",
      "Downloading: 100% 442/442 [00:00<00:00, 559kB/s]\n",
      "Downloading: 100% 363M/363M [00:45<00:00, 7.93MB/s]    \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:54:28.672050: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Sucessfully downloaded after 0 retries.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m ***** Checkpoint enabled *****\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m *** CHECKPOINT CALLBACK <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd96c2baf98> ***\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m ** use_amp True\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m *** OPTIMIZER <tensorflow.python.keras.mixed_precision.experimental.loss_scale_optimizer.LossScaleOptimizer object at 0x7fd96c331438> ***\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Compiled model <transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification object at 0x7fd96c2eee80>\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m distilbert (TFDistilBertMain multiple                  66362880  \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m pre_classifier (Dense)       multiple                  590592    \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m classifier (Dense)           multiple                  7690      \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m dropout_19 (Dropout)         multiple                  0         \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Total params: 66,961,162\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Trainable params: 66,961,162\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Non-trainable params: 0\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m None\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Starting Training (Without Validation)...\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Train for 1 steps\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:54:42.393067: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1892] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:54:43.345287: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1574] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m \n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Epoch 00001: saving model to /opt/ml/checkpoints/tf_model_00001.h5\n",
      "1/1 [==============================] - 23s 23s/step - loss: 2.3006 - accuracy: 0.1094\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:54:58.269154: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m <tensorflow.python.keras.callbacks.History object at 0x7fd8e8f0da58>\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m ########  Save the Fine-Yuned Transformers Model as a New Pre-Trained Model ##########\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m transformer_fine_tuned_model_path /opt/ml/model/transformers/fine-tuned/\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m INFO:transformers.configuration_utils:Configuration saved in /opt/ml/model/transformers/fine-tuned/config.json\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m INFO:transformers.modeling_tf_utils:Model weights saved in /opt/ml/model/transformers/fine-tuned/tf_model.h5\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m ########  Save the TensorFlow SavedModel for Serving Predictions Model ##########\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m tensorflow_saved_model_path /opt/ml/model/tensorflow/saved_model/0\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd96c2cbb70>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd96c2cbb70>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd92ced0940>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd92ced0940>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd9482e8048>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd9482e8048>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd9482f3710>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd9482f3710>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd96c064dd8>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd96c064dd8>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd96c3564e0>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fd96c3564e0>, because it is not built.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/tensorflow/saved_model/0/assets\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/tensorflow/saved_model/0/assets\n",
      "\u001b[36malgo-1-usz92_1  |\u001b[0m 2020-08-17 09:55:08,718 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpikr_h4cd_algo-1-usz92_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "# S3\n",
    "inputs={'train': s3_input_train_data, \n",
    "        'validation': s3_input_validation_data,\n",
    "         'test': s3_input_test_data\n",
    "              }\n",
    "\n",
    "# Local 파일을 사용한다면 아래를 Uncomment하고 사용\n",
    "# train_dir = 'data/output/bert/train'\n",
    "# validation_dir = 'data/output/bert/validation'\n",
    "# test_dir = 'data/output/bert/test'\n",
    "\n",
    "# inputs = {'train': f'file://{train_dir}',\n",
    "#           'validation': f'file://{validation_dir}',\n",
    "#           'test': f'file://{test_dir}'}\n",
    "\n",
    "local_estimator.fit(inputs)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
