{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 3.2] On a Local Mode, Train a BERT Model with Tensorflow\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 진행 합니다. 로컬 모드를 사용하는 이유는 Train Script의 로직이 맞는지를 주로 확인하는데 사용 합니다. 로컬 모드로 로직 확인이 완료 되면 Script Mode (BYOS, Bring Your Own Script)혹은 필요할 경우에 BYOC(Bring Your Own Container)로 학습을 합니다.\n",
    "\n",
    "- 학습할 데이타를 S3로 지정\n",
    "- Train 학습 파리미터 설정\n",
    "- Estimator를 생성하고 tf_script_bert_tweet.py Train Script를 지정\n",
    "- Estimator를 를 로컬 모드로 실행\n",
    "    \n",
    "---\n",
    "이 노트북은 약 3분 소요 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  로컬모드 (Local Mode) 학습 <a class=\"anchor\" id=\"LocalModeTraining\">\n",
    "\n",
    "SageMaker에서 로컬 모드는, 여러분이 작성한 코드를 SageMaker에서 관리되는 보다 강력한 클러스터에서 실행하기 전에, 여러분의 코드가 기대한 방식으로 동작하는 지 로컬에서 확인할 수 있는 편리한 방식입니다. 로컬모드 학습을 위해서는 docker-compose 또는 nvidia-docker-compose (GPU 인스턴스인 경우)의 설치가 필요합니다. 다음 셀의 명령은 본 노트북환경에 docker-compose 또는 nvidia-docker-compose를 설치하고 구성합니다. \n",
    "    \n",
    "스크립트 모드를 사용하기 위해서 아래의 API 문서 참고 하세요\n",
    "- Script Mode Ref:\n",
    "    - https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#train-a-model-with-tensorflow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/local_mode_setup.sh\n",
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/daemon.json    \n",
    "!/bin/bash ./local_mode_setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-ap-northeast-2-343441690612/sagemaker-scikit-learn-2020-08-18-03-14-58-057/output/bert-train', 'S3DataDistributionType': 'FullyReplicated'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-ap-northeast-2-343441690612/sagemaker-scikit-learn-2020-08-18-03-14-58-057/output/bert-validation', 'S3DataDistributionType': 'FullyReplicated'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-ap-northeast-2-343441690612/sagemaker-scikit-learn-2020-08-18-03-14-58-057/output/bert-test', 'S3DataDistributionType': 'FullyReplicated'}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s3_input_train_data = sagemaker.s3_input(s3_data=processed_train_data_s3_uri) \n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=processed_validation_data_s3_uri)\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=processed_test_data_s3_uri)\n",
    "\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uuid를 생성하여 checkpoint 파일이 저장될 폴더를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-northeast-2-343441690612/checkpoints/12f717a5-c3fd-453d-9cdb-aac2853cf292/\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "checkpoint_s3_prefix = 'checkpoints/{}'.format(str(uuid.uuid4()))\n",
    "checkpoint_s3_uri = 's3://{}/{}/'.format(bucket, checkpoint_s3_prefix)\n",
    "\n",
    "print(checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics를 정의하여 CloudWatch에서 모니터링을 할 수 있게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "     {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'train:accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= 20\n",
    "\n",
    "steps = 10\n",
    "train_steps_per_epoch= steps\n",
    "validation_steps= int(steps / 2)\n",
    "test_steps= int(steps / 2)\n",
    "\n",
    "\n",
    "\n",
    "max_seq_length = 32\n",
    "learning_rate= 4e-4\n",
    "epsilon=0.00000001\n",
    "\n",
    "train_batch_size=128\n",
    "validation_batch_size=128\n",
    "test_batch_size=128\n",
    "\n",
    "\n",
    "train_instance_type='local'\n",
    "train_instance_count=1\n",
    "train_volume_size=1024\n",
    "\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "\n",
    "freeze_bert_layer= True\n",
    "\n",
    "enable_sagemaker_debugger=False\n",
    "enable_checkpointing=True\n",
    "\n",
    "# input_mode='Pipe'\n",
    "input_mode='File'\n",
    "run_validation=True\n",
    "run_test=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "local_estimator = TensorFlow(entry_point='tf_script_bert_tweet.py', \n",
    "#                       source_dir='src', # put requirements.txt in this directory and it gets picked up\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       train_instance_count=train_instance_count, # Make sure you have at least this number of input files or the ShardedByS3Key distibution strategy will fail the job due to no data available\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       train_volume_size=train_volume_size,\n",
    "#                        train_use_spot_instances=True, # Not support in local mode\n",
    "#                        train_max_wait=7200, # Seconds to wait for spot instances to become available\n",
    "#                        checkpoint_s3_uri=checkpoint_s3_uri, # Not support in local mode\n",
    "                       py_version='py3',\n",
    "                       framework_version='2.1.0',\n",
    "                       script_mode = True,\n",
    "                       hyperparameters={'epochs': epochs,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'epsilon': epsilon,\n",
    "                                        'train_batch_size': train_batch_size,\n",
    "                                        'validation_batch_size': validation_batch_size,\n",
    "                                        'test_batch_size': test_batch_size,                                             \n",
    "                                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                                        'validation_steps': validation_steps,\n",
    "                                        'test_steps': test_steps,\n",
    "                                        'use_xla': use_xla,\n",
    "                                        'use_amp': use_amp,                                             \n",
    "                                        'max_seq_length': max_seq_length,\n",
    "                                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                                        'enable_checkpointing': enable_checkpointing\n",
    "                                        },\n",
    "                       input_mode=input_mode,\n",
    "                       metric_definitions=metrics_definitions\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input 위치 지정하고 Train 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpvg2xq9my_algo-1-8g84s_1 ... \n",
      "\u001b[1BAttaching to tmpvg2xq9my_algo-1-8g84s_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:19:54,342 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:19:54,349 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:19:54,507 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:19:54,522 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:19:54,535 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:19:54,543 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"current_host\": \"algo-1-8g84s\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"algo-1-8g84s\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"epochs\": 20,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"learning_rate\": 0.0004,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"epsilon\": 1e-08,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"train_batch_size\": 128,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"validation_batch_size\": 128,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"test_batch_size\": 128,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"train_steps_per_epoch\": 10,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"validation_steps\": 5,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"test_steps\": 5,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"use_xla\": true,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"use_amp\": true,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"max_seq_length\": 32,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"freeze_bert_layer\": false,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"enable_checkpointing\": true,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"model_dir\": \"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"test\": {\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"job_name\": \"tensorflow-training-2020-08-18-12-19-49-433\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"master_hostname\": \"algo-1-8g84s\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"module_name\": \"tf_script_bert_tweet\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"current_host\": \"algo-1-8g84s\",\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m             \"algo-1-8g84s\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     \"user_entry_point\": \"tf_script_bert_tweet.py\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HOSTS=[\"algo-1-8g84s\"]\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HPS={\"enable_checkpointing\":true,\"epochs\":20,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":0.0004,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model\",\"test_batch_size\":128,\"test_steps\":5,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":5}\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_USER_ENTRY_POINT=tf_script_bert_tweet.py\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-8g84s\",\"hosts\":[\"algo-1-8g84s\"]}\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_CHANNELS=[\"test\",\"train\",\"validation\"]\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_CURRENT_HOST=algo-1-8g84s\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_MODULE_NAME=tf_script_bert_tweet\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-8g84s\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-8g84s\"],\"hyperparameters\":{\"enable_checkpointing\":true,\"epochs\":20,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":0.0004,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model\",\"test_batch_size\":128,\"test_steps\":5,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-08-18-12-19-49-433\",\"log_level\":20,\"master_hostname\":\"algo-1-8g84s\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/source/sourcedir.tar.gz\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-8g84s\",\"hosts\":[\"algo-1-8g84s\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_USER_ARGS=[\"--enable_checkpointing\",\"True\",\"--epochs\",\"20\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"0.0004\",\"--max_seq_length\",\"32\",\"--model_dir\",\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model\",\"--test_batch_size\",\"128\",\"--test_steps\",\"5\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"10\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"5\"]\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_EPOCHS=20\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_LEARNING_RATE=0.0004\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_EPSILON=1e-08\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_TRAIN_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_VALIDATION_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_TEST_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_TRAIN_STEPS_PER_EPOCH=10\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_VALIDATION_STEPS=5\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_TEST_STEPS=5\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_USE_XLA=true\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_USE_AMP=true\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_MAX_SEQ_LENGTH=32\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_FREEZE_BERT_LAYER=false\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_ENABLE_CHECKPOINTING=true\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m /usr/bin/python3 tf_script_bert_tweet.py --enable_checkpointing True --epochs 20 --epsilon 1e-08 --freeze_bert_layer False --learning_rate 0.0004 --max_seq_length 32 --model_dir s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model --test_batch_size 128 --test_steps 5 --train_batch_size 128 --train_steps_per_epoch 10 --use_amp True --use_xla True --validation_batch_size 128 --validation_steps 5\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Collecting transformers==2.8.0\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading transformers-2.8.0-py3-none-any.whl (563 kB)\n",
      "\u001b[K     |████████████████████████████████| 563 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[?25hCollecting sacremoses\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.1)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Collecting tokenizers==0.5.2\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.22.0)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Collecting filelock\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Collecting tqdm>=4.27\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 8.2 MB/s  eta 0:00:01\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[?25hCollecting regex!=2019.12.17\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660 kB)\n",
      "\u001b[K     |████████████████████████████████| 660 kB 16.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.12.43)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Collecting sentencepiece\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 17.0 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[?25hCollecting dataclasses; python_version < \"3.7\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading dataclasses-0.7-py3-none-any.whl (18 kB)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.14.0)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.1)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.14.1)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.8)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.25.9)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.9.5)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.15.43)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers==2.8.0) (0.15.2)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers==2.8.0) (2.8.1)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Building wheels for collected packages: sacremoses\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=06fee5b6b202aa331b8f118d4d86d9fc97611a221ffa30118406988052a7c629\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Successfully built sacremoses\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Installing collected packages: regex, tqdm, sacremoses, tokenizers, filelock, sentencepiece, dataclasses, transformers\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Successfully installed dataclasses-0.7 filelock-3.0.12 regex-2020.7.14 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.5.2 tqdm-4.48.2 transformers-2.8.0\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: sagemaker-tensorflow==2.1.0.1.0.0 in /usr/local/lib/python3.6/dist-packages (2.1.0.1.0.0)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Collecting scikit-learn==0.23.1\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.4.1)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (0.14.1)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1) (1.18.1)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Installing collected packages: threadpoolctl, scikit-learn\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   Attempting uninstall: scikit-learn\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     Found existing installation: scikit-learn 0.22\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     Uninstalling scikit-learn-0.22:\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m       Successfully uninstalled scikit-learn-0.22\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Successfully installed scikit-learn-0.23.1 threadpoolctl-2.1.0\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m ################ Args: #######################\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Namespace(checkpoint_base_path='/opt/ml/checkpoints', current_host='algo-1-8g84s', enable_checkpointing=True, epochs=20, epsilon=1e-08, freeze_bert_layer=False, hosts=['algo-1-8g84s'], learning_rate=0.0004, max_seq_length=32, model_dir='s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model', num_gpus=0, output_dir='/opt/ml/output', run_sample_predictions=False, run_test=False, run_validation=False, test_batch_size=128, test_data='/opt/ml/input/data/test', test_steps=5, train_batch_size=128, train_data='/opt/ml/input/data/train', train_steps_per_epoch=10, use_amp=True, use_xla=True, validation_batch_size=128, validation_data='/opt/ml/input/data/validation', validation_steps=5)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m ################ Environment Variables: ################\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m {'AWS_REGION': 'ap-northeast-2',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'CURRENT_HOST': 'algo-1-8g84s',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'DEBCONF_NONINTERACTIVE_SEEN': 'true',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'DEBIAN_FRONTEND': 'noninteractive',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'HOME': '/root',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'HOSTNAME': '29b0d2b1cde9',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'KMP_AFFINITY': 'granularity=fine,compact,1,0',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'KMP_BLOCKTIME': '1',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'KMP_DUPLICATE_LIB_OK': 'True',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'KMP_INIT_AT_FORK': 'FALSE',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'KMP_SETTINGS': '0',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'LANG': 'C.UTF-8',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'LC_ALL': 'C.UTF-8',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'LD_LIBRARY_PATH': '/usr/local/openmpi/lib:',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'PATH': '/usr/local/openmpi/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'PYTHONDONTWRITEBYTECODE': '1',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'PYTHONIOENCODING': 'UTF-8',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'PYTHONPATH': '/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'PYTHONUNBUFFERED': '1',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'S3_REGION': 'ap-northeast-2',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'S3_USE_HTTPS': '1',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SAGEMAKER_JOB_NAME': 'tensorflow-training-2020-08-18-12-19-49-433',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SAGEMAKER_REGION': 'ap-northeast-2',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SAGEMAKER_TRAINING_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_CHANNELS': '[\"test\",\"train\",\"validation\"]',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_CHANNEL_TEST': '/opt/ml/input/data/test',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_CHANNEL_VALIDATION': '/opt/ml/input/data/validation',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_CURRENT_HOST': 'algo-1-8g84s',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_FRAMEWORK_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_FRAMEWORK_PARAMS': '{}',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HOSTS': '[\"algo-1-8g84s\"]',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HPS': '{\"enable_checkpointing\":true,\"epochs\":20,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":0.0004,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model\",\"test_batch_size\":128,\"test_steps\":5,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":5}',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_ENABLE_CHECKPOINTING': 'true',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_EPOCHS': '20',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_EPSILON': '1e-08',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_FREEZE_BERT_LAYER': 'false',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_LEARNING_RATE': '0.0004',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_MAX_SEQ_LENGTH': '32',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_MODEL_DIR': 's3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_TEST_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_TEST_STEPS': '5',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_TRAIN_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_TRAIN_STEPS_PER_EPOCH': '10',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_USE_AMP': 'true',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_USE_XLA': 'true',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_VALIDATION_BATCH_SIZE': '128',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_HP_VALIDATION_STEPS': '5',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_INPUT_DATA_CONFIG': '{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_INPUT_DIR': '/opt/ml/input',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_LOG_LEVEL': '20',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_MODEL_DIR': '/opt/ml/model',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_MODULE_DIR': 's3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/source/sourcedir.tar.gz',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_MODULE_NAME': 'tf_script_bert_tweet',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_NETWORK_INTERFACE_NAME': 'eth0',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_NUM_CPUS': '8',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_NUM_GPUS': '0',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_OUTPUT_DIR': '/opt/ml/output',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-8g84s\",\"hosts\":[\"algo-1-8g84s\"]}',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-8g84s\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-8g84s\"],\"hyperparameters\":{\"enable_checkpointing\":true,\"epochs\":20,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":0.0004,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model\",\"test_batch_size\":128,\"test_steps\":5,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-08-18-12-19-49-433\",\"log_level\":20,\"master_hostname\":\"algo-1-8g84s\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/source/sourcedir.tar.gz\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-8g84s\",\"hosts\":[\"algo-1-8g84s\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_USER_ARGS': '[\"--enable_checkpointing\",\"True\",\"--epochs\",\"20\",\"--epsilon\",\"1e-08\",\"--freeze_bert_layer\",\"False\",\"--learning_rate\",\"0.0004\",\"--max_seq_length\",\"32\",\"--model_dir\",\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model\",\"--test_batch_size\",\"128\",\"--test_steps\",\"5\",\"--train_batch_size\",\"128\",\"--train_steps_per_epoch\",\"10\",\"--use_amp\",\"True\",\"--use_xla\",\"True\",\"--validation_batch_size\",\"128\",\"--validation_steps\",\"5\"]',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'SM_USER_ENTRY_POINT': 'tf_script_bert_tweet.py',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'TERM': 'xterm',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'TF_CPP_MIN_LOG_LEVEL': '1',\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  'TRAINING_JOB_NAME': 'tensorflow-training-2020-08-18-12-19-49-433'}\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m SM_TRAINING_ENV {\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-8g84s\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-8g84s\"],\"hyperparameters\":{\"enable_checkpointing\":true,\"epochs\":20,\"epsilon\":1e-08,\"freeze_bert_layer\":false,\"learning_rate\":0.0004,\"max_seq_length\":32,\"model_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model\",\"test_batch_size\":128,\"test_steps\":5,\"train_batch_size\":128,\"train_steps_per_epoch\":10,\"use_amp\":true,\"use_xla\":true,\"validation_batch_size\":128,\"validation_steps\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-08-18-12-19-49-433\",\"log_level\":20,\"master_hostname\":\"algo-1-8g84s\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/source/sourcedir.tar.gz\",\"module_name\":\"tf_script_bert_tweet\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-8g84s\",\"hosts\":[\"algo-1-8g84s\"]},\"user_entry_point\":\"tf_script_bert_tweet.py\"}\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m ################ Extract varaibles from Command Args #######################\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m train_data /opt/ml/input/data/train\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m validation_data /opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m test_data /opt/ml/input/data/test\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m local_model_dir /opt/ml/model\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m output_dir /opt/ml/output\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m hosts ['algo-1-8g84s']\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m current_host algo-1-8g84s\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m num_gpus 0\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m job_name tensorflow-training-2020-08-18-12-19-49-433\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m use_xla True\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m use_amp True\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m max_seq_length 32\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m train_batch_size 128\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m validation_batch_size 128\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m test_batch_size 128\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m epochs 20\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m learning_rate 0.0004\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m epsilon 1e-08\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m train_steps_per_epoch 10\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m validation_steps 5\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m test_steps 5\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m freeze_bert_layer False\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m run_validation False\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m run_test False\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m run_sample_predictions False\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m enable_checkpointing True\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m checkpoint_base_path /opt/ml/checkpoints\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m  ################ Set Checkpoint path: ################\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m checkpoint_path /opt/ml/checkpoints\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Using pipe_mode: False\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m ################ Mirrored distributed_strategy ################\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m train_data_filenames ['/opt/ml/input/data/train/part-algo-1-tweet_file_01.tfrecord', '/opt/ml/input/data/train/part-algo-2-tweet_file_02.tfrecord']\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m ***** Using input_filenames ['/opt/ml/input/data/train/part-algo-1-tweet_file_01.tfrecord', '/opt/ml/input/data/train/part-algo-2-tweet_file_02.tfrecord']\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m WARNING:tensorflow:From tf_script_bert_tweet.py:94: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 390kB/s]  \n",
      "Downloading: 100% 442/442 [00:00<00:00, 458kB/s]\n",
      "Downloading: 100% 363M/363M [00:46<00:00, 7.85MB/s]   \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:20:58.144692: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Sucessfully downloaded after 0 retries.\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m ***** Checkpoint enabled *****\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m *** CHECKPOINT CALLBACK <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f99542cecf8> ***\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m ** use_amp True\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m *** OPTIMIZER <tensorflow.python.keras.mixed_precision.experimental.loss_scale_optimizer.LossScaleOptimizer object at 0x7f99543434a8> ***\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Compiled model <transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification object at 0x7f99542c16a0>\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m distilbert (TFDistilBertMain multiple                  66362880  \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m pre_classifier (Dense)       multiple                  590592    \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m classifier (Dense)           multiple                  7690      \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m dropout_19 (Dropout)         multiple                  0         \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Total params: 66,961,162\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Trainable params: 66,961,162\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Non-trainable params: 0\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m None\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Starting Training (Without Validation)...\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Train for 10 steps\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 1/20\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:21:14.037669: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1892] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:21:15.020408: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1574] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 2.3057 - accuracy: 0.1076 \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 00001: saving model to /opt/ml/checkpoints/tf_model_00001.h5\n",
      "10/10 [==============================] - 48s 5s/step - loss: 2.3023 - accuracy: 0.1148\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 2/20\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 2.3104 - accuracy: 0.1050\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 00002: saving model to /opt/ml/checkpoints/tf_model_00002.h5\n",
      "10/10 [==============================] - 28s 3s/step - loss: 2.3098 - accuracy: 0.1047\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 3/20\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 2.3111 - accuracy: 0.0929\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 00003: saving model to /opt/ml/checkpoints/tf_model_00003.h5\n",
      "10/10 [==============================] - 27s 3s/step - loss: 2.3108 - accuracy: 0.0906\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 4/20\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 2.3039 - accuracy: 0.1120\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 00004: saving model to /opt/ml/checkpoints/tf_model_00004.h5\n",
      "10/10 [==============================] - 27s 3s/step - loss: 2.3048 - accuracy: 0.1070\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 5/20\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 2.3085 - accuracy: 0.0964\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 00005: saving model to /opt/ml/checkpoints/tf_model_00005.h5\n",
      "10/10 [==============================] - 27s 3s/step - loss: 2.3087 - accuracy: 0.0945\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 6/20\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 2.3079 - accuracy: 0.1042\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 00006: saving model to /opt/ml/checkpoints/tf_model_00006.h5\n",
      "10/10 [==============================] - 29s 3s/step - loss: 2.3068 - accuracy: 0.1055\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 7/20\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 2.3155 - accuracy: 0.1016\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 00007: saving model to /opt/ml/checkpoints/tf_model_00007.h5\n",
      "10/10 [==============================] - 27s 3s/step - loss: 2.3148 - accuracy: 0.1023\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 8/20\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 2.3061 - accuracy: 0.0955\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Epoch 00008: saving model to /opt/ml/checkpoints/tf_model_00008.h5\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\", line 1107, in save_weights\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     hdf5_format.save_weights_to_hdf5_group(f, self.layers)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 636, in save_weights_to_hdf5_group\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     param_dset[:] = val\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\", line 708, in __setitem__\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/h5d.pyx\", line 222, in h5py.h5d.DatasetID.write\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_proxy.pyx\", line 132, in h5py._proxy.dset_rw\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_proxy.pyx\", line 93, in h5py._proxy.H5PY_H5Dwrite\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m OSError: Can't write data (file write failed: time = Tue Aug 18 12:25:07 2020\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m , filename = '/opt/ml/checkpoints/tf_model_00008.h5', file descriptor = 6, errno = 28, error message = 'No space left on device', buf = 0xf716f30, total write size = 9204864, bytes this sub-write = 9204864, bytes actually written = 18446744073709551615, offset = 133435392)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"tf_script_bert_tweet.py\", line 441, in <module>\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     callbacks=callbacks)                \n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 825, in fit\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     use_multiprocessing=use_multiprocessing)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 397, in fit\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     prefix='val_')\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/lib/python3.6/contextlib.py\", line 88, in __exit__\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     next(self.gen)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 771, in on_epoch\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     self.callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 302, in on_epoch_end\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     callback.on_epoch_end(epoch, logs)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 992, in on_epoch_end\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     self._save_model(epoch=epoch, logs=logs)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 1038, in _save_model\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     self.model.save_weights(filepath, overwrite=True)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\", line 1107, in save_weights\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     hdf5_format.save_weights_to_hdf5_group(f, self.layers)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\", line 461, in __exit__\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     self.close()\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\", line 443, in close\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m     h5i.dec_ref(id_)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m   File \"h5py/h5i.pyx\", line 150, in h5py.h5i.dec_ref\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m RuntimeError: Problems closing file (file write failed: time = Tue Aug 18 12:25:07 2020\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m , filename = '/opt/ml/checkpoints/tf_model_00008.h5', file descriptor = 6, errno = 28, error message = 'No space left on device', buf = 0xbb4c840, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m 2020-08-18 12:25:08,120 sagemaker-containers ERROR    ExecuteUserScriptError:\n",
      "\u001b[36malgo-1-8g84s_1  |\u001b[0m Command \"/usr/bin/python3 tf_script_bert_tweet.py --enable_checkpointing True --epochs 20 --epsilon 1e-08 --freeze_bert_layer False --learning_rate 0.0004 --max_seq_length 32 --model_dir s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-18-12-19-49-433/model --test_batch_size 128 --test_steps 5 --train_batch_size 128 --train_steps_per_epoch 10 --use_amp True --use_xla True --validation_batch_size 128 --validation_steps 5\"\n",
      "\u001b[36mtmpvg2xq9my_algo-1-8g84s_1 exited with code 1\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device: '/tmp/tmpvg2xq9my/artifacts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process exited with code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/tmp/tmpvg2xq9my/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-45a327a65d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#           'test': f'file://{test_dir}'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mlocal_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config, run_tensorboard_locally)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit_super\u001b[0;34m()\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_tensorboard_locally\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     def process(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# free up the training data directory as it may contain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mretrieve_artifacts\u001b[0;34m(self, compose_data, output_data_config, job_name)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"artifacts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mcompressed_artifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compressed_artifacts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifacts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mmodel_artifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifacts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: '/tmp/tmpvg2xq9my/artifacts'"
     ]
    }
   ],
   "source": [
    "# S3\n",
    "inputs={'train': s3_input_train_data, \n",
    "        'validation': s3_input_validation_data,\n",
    "         'test': s3_input_test_data\n",
    "              }\n",
    "\n",
    "# Local 파일을 사용한다면 아래를 Uncomment하고 사용\n",
    "# train_dir = 'data/output/bert/train'\n",
    "# validation_dir = 'data/output/bert/validation'\n",
    "# test_dir = 'data/output/bert/test'\n",
    "\n",
    "# inputs = {'train': f'file://{train_dir}',\n",
    "#           'validation': f'file://{validation_dir}',\n",
    "#           'test': f'file://{test_dir}'}\n",
    "\n",
    "local_estimator.fit(inputs)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
