{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.3.0] Inference Custom Docker Image 생성 및 ECR 퍼블리시\n",
    "\n",
    "이 노트북은 Docker 이미지를 생성하고, Amazon ECR(Elastic Container Registry)에 퍼블리스를 합니다.\n",
    "SageMaker 는 Custom Tensorflow Serving 이미지를 만들 수 있게 필요한 리소스(Dockerfile등)을 제공 합니다.\n",
    "\n",
    "아래와 같은 작업을 진행 합니다.\n",
    "- [SageMaker TensorFlow Serving Container](https://github.com/aws/sagemaker-tensorflow-serving-container) 을 Git Clone을 하여 다운로드\n",
    "- 주어지는 여러가지 버전의 Dockerfile 중에서 2.0-cpu 를 사용\n",
    "    - 다른 버전을 사용하셔도 됩니다.(예: 2.0-gpu)\n",
    "- 필요한 Package인 tensorflow:2.1.0 과 transformers:2.8.0을 추가\n",
    "- docker image를 빌드\n",
    "- ECR에 퍼블리시\n",
    "\n",
    "\n",
    "---\n",
    "노트북의 소요 시간은 약 10분 걸립니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker TensorFlow Serving Container 다운로드\n",
    "아래 Git 리파지토리를 Clone 하겠습니다.\n",
    "\n",
    "* https://github.com/aws/sagemaker-tensorflow-serving-container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'sagemaker-tensorflow-serving-container' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/aws/sagemaker-tensorflow-serving-container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile 수정 (tfs:2.0-cpu)\n",
    "다운로드 받은 폴더에서 아래 파일을 수정 하겠습니다.\n",
    "- sagemaker-tensorflow-serving-container/docker/2.0/Dockerfile.cpu\n",
    "- Dockerfile 안에 아래를 추가 하겠습니다.\n",
    "```\n",
    "#################\n",
    "# 추가 사항\n",
    "# Install tensorflow 2.1 and transformer\n",
    "#################\n",
    "RUN ${PIP} install --no-cache-dir \\\n",
    "    tensorflow==2.1.0 \\\n",
    "    transformers==2.8.0\n",
    "#################\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sagemaker-tensorflow-serving-container/docker/2.0/Dockerfile.cpu\n"
     ]
    }
   ],
   "source": [
    "%%writefile sagemaker-tensorflow-serving-container/docker/2.0/Dockerfile.cpu \n",
    "\n",
    "FROM ubuntu:18.04\n",
    "\n",
    "LABEL maintainer=\"Amazon AI\"\n",
    "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "ARG PYTHON=python3\n",
    "ARG PIP=pip3\n",
    "ARG TFS_SHORT_VERSION=2.0.1\n",
    "ARG TFS_URL=https://tensorflow-aws.s3-us-west-2.amazonaws.com/${TFS_SHORT_VERSION}/Serving/CPU-WITH-MKL/tensorflow_model_server\n",
    "\n",
    "# See http://bugs.python.org/issue19846\n",
    "ENV LANG=C.UTF-8\n",
    "# Python won’t try to write .pyc or .pyo files on the import of source modules\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV SAGEMAKER_TFS_VERSION=\"${TFS_SHORT_VERSION}\"\n",
    "ENV PATH=\"$PATH:/sagemaker\"\n",
    "ENV LD_LIBRARY_PATH='/usr/local/lib:$LD_LIBRARY_PATH'\n",
    "ENV MODEL_BASE_PATH=/models\n",
    "# The only required piece is the model name in order to differentiate endpoints\n",
    "ENV MODEL_NAME=model\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "# nginx + njs\n",
    "RUN apt-get update \\\n",
    " && apt-get -y install --no-install-recommends \\\n",
    "    curl \\\n",
    "    gnupg2 \\\n",
    "    ca-certificates \\\n",
    "    git \\\n",
    "    wget \\\n",
    "    vim \\\n",
    "    build-essential \\\n",
    "    zlib1g-dev \\\n",
    " && curl -s http://nginx.org/keys/nginx_signing.key | apt-key add - \\\n",
    " && echo 'deb http://nginx.org/packages/ubuntu/ bionic nginx' >> /etc/apt/sources.list \\\n",
    " && apt-get update \\\n",
    " && apt-get -y install --no-install-recommends \\\n",
    "    nginx \\\n",
    "    nginx-module-njs \\\n",
    "    python3 \\\n",
    "    python3-pip \\\n",
    "    python3-setuptools \\\n",
    " && apt-get clean \\\n",
    " && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN ${PIP} --no-cache-dir install --upgrade pip setuptools\n",
    "\n",
    "# cython, falcon, gunicorn, grpc\n",
    "RUN ${PIP} install --no-cache-dir \\\n",
    "    awscli==1.16.303 \\\n",
    "    cython==0.29.14 \\\n",
    "    falcon==2.0.0 \\\n",
    "    gunicorn==20.0.4 \\\n",
    "    gevent==1.4.0 \\\n",
    "    requests==2.22.0 \\\n",
    "    grpcio==1.26.0 \\\n",
    "    protobuf==3.11.1 \\\n",
    "# using --no-dependencies to avoid installing tensorflow binary\n",
    " && ${PIP} install --no-dependencies --no-cache-dir \\\n",
    "    tensorflow-serving-api==2.0\n",
    "\n",
    "#################\n",
    "# 추가 사항\n",
    "# Install tensorflow 2.1 and transformer\n",
    "#################\n",
    "RUN ${PIP} install --no-cache-dir \\\n",
    "    tensorflow==2.1.0 \\\n",
    "    transformers==2.8.0\n",
    "#################\n",
    "\n",
    "\n",
    "COPY ./sagemaker /sagemaker\n",
    "\n",
    "# Some TF tools expect a \"python\" binary\n",
    "RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
    "\n",
    "RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libiomp5.so -o /usr/local/lib/libiomp5.so\n",
    "RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libmklml_intel.so -o /usr/local/lib/libmklml_intel.so\n",
    "\n",
    "RUN curl $TFS_URL -o /usr/bin/tensorflow_model_server \\\n",
    " && chmod 555 /usr/bin/tensorflow_model_server\n",
    "\n",
    "# Expose ports\n",
    "# gRPC and REST\n",
    "EXPOSE 8500 8501\n",
    "\n",
    "# Set where models should be stored in the container\n",
    "RUN mkdir -p ${MODEL_BASE_PATH}\n",
    "\n",
    "# Create a script that runs the model server so we can use environment variables\n",
    "# while also passing in arguments from the docker command line\n",
    "RUN echo '#!/bin/bash \\n\\n' > /usr/bin/tf_serving_entrypoint.sh \\\n",
    " && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"' >> /usr/bin/tf_serving_entrypoint.sh \\\n",
    " && chmod +x /usr/bin/tf_serving_entrypoint.sh\n",
    "\n",
    "ADD https://raw.githubusercontent.com/aws/aws-deep-learning-containers-utils/master/deep_learning_container.py /usr/local/bin/deep_learning_container.py\n",
    "\n",
    "RUN chmod +x /usr/local/bin/deep_learning_container.py\n",
    "\n",
    "RUN curl https://aws-dlc-licenses.s3.amazonaws.com/tensorflow-2.0.1/license.txt -o /license.txt\n",
    "\n",
    "CMD [\"/usr/bin/tf_serving_entrypoint.sh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custome Docker 생성\n",
    "아래 셀 스크립트를 실행하면 이미지가 생성이 됩니다. \n",
    "```\n",
    "./scripts/build.sh --version 2.0.0 --arch cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_version = \"2.0.0\"\n",
    "cpu_type = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling previous image for layer cache... \n",
      "building image... \n",
      "Sending build context to Docker daemon  77.31kB\n",
      "Step 1/32 : FROM ubuntu:18.04\n",
      " ---> d27b9ffc5667\n",
      "Step 2/32 : LABEL maintainer=\"Amazon AI\"\n",
      " ---> Using cache\n",
      " ---> 6a0a86e3feed\n",
      "Step 3/32 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> b55a47cf38e9\n",
      "Step 4/32 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> a64ef9d8ae6b\n",
      "Step 5/32 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> b16114f29d32\n",
      "Step 6/32 : ARG TFS_SHORT_VERSION=2.0.1\n",
      " ---> Using cache\n",
      " ---> 822bbbb8c670\n",
      "Step 7/32 : ARG TFS_URL=https://tensorflow-aws.s3-us-west-2.amazonaws.com/${TFS_SHORT_VERSION}/Serving/CPU-WITH-MKL/tensorflow_model_server\n",
      " ---> Using cache\n",
      " ---> 651d94c10edb\n",
      "Step 8/32 : ENV LANG=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> e504dd4bf088\n",
      "Step 9/32 : ENV PYTHONDONTWRITEBYTECODE=1\n",
      " ---> Using cache\n",
      " ---> 46312ab638dd\n",
      "Step 10/32 : ENV PYTHONUNBUFFERED=1\n",
      " ---> Using cache\n",
      " ---> 44ae19dc1c59\n",
      "Step 11/32 : ENV SAGEMAKER_TFS_VERSION=\"${TFS_SHORT_VERSION}\"\n",
      " ---> Using cache\n",
      " ---> 2c3212f3d844\n",
      "Step 12/32 : ENV PATH=\"$PATH:/sagemaker\"\n",
      " ---> Using cache\n",
      " ---> 0c974b05a21f\n",
      "Step 13/32 : ENV LD_LIBRARY_PATH='/usr/local/lib:$LD_LIBRARY_PATH'\n",
      " ---> Using cache\n",
      " ---> 5648cfcff9ed\n",
      "Step 14/32 : ENV MODEL_BASE_PATH=/models\n",
      " ---> Using cache\n",
      " ---> 6750e6e0bf61\n",
      "Step 15/32 : ENV MODEL_NAME=model\n",
      " ---> Using cache\n",
      " ---> 9f62689a2017\n",
      "Step 16/32 : ENV DEBIAN_FRONTEND=noninteractive\n",
      " ---> Using cache\n",
      " ---> 91dfda968844\n",
      "Step 17/32 : RUN apt-get update  && apt-get -y install --no-install-recommends     curl     gnupg2     ca-certificates     git     wget     vim     build-essential     zlib1g-dev  && curl -s http://nginx.org/keys/nginx_signing.key | apt-key add -  && echo 'deb http://nginx.org/packages/ubuntu/ bionic nginx' >> /etc/apt/sources.list  && apt-get update  && apt-get -y install --no-install-recommends     nginx     nginx-module-njs     python3     python3-pip     python3-setuptools  && apt-get clean  && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 84f9ba759f23\n",
      "Step 18/32 : RUN ${PIP} --no-cache-dir install --upgrade pip setuptools\n",
      " ---> Using cache\n",
      " ---> 3990e802a956\n",
      "Step 19/32 : RUN ${PIP} install --no-cache-dir     awscli==1.16.303     cython==0.29.14     falcon==2.0.0     gunicorn==20.0.4     gevent==1.4.0     requests==2.22.0     grpcio==1.26.0     protobuf==3.11.1  && ${PIP} install --no-dependencies --no-cache-dir     tensorflow-serving-api==2.0\n",
      " ---> Using cache\n",
      " ---> e1f625e29e22\n",
      "Step 20/32 : RUN ${PIP} install --no-cache-dir     tensorflow==2.1.0     transformers==2.8.0\n",
      " ---> Using cache\n",
      " ---> 8ab45adb733a\n",
      "Step 21/32 : COPY ./sagemaker /sagemaker\n",
      " ---> Using cache\n",
      " ---> d6dfedc3065b\n",
      "Step 22/32 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 9ba89cfe0e99\n",
      "Step 23/32 : RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libiomp5.so -o /usr/local/lib/libiomp5.so\n",
      " ---> Using cache\n",
      " ---> 248147f6d4de\n",
      "Step 24/32 : RUN curl https://tensorflow-aws.s3-us-west-2.amazonaws.com/MKL-Libraries/libmklml_intel.so -o /usr/local/lib/libmklml_intel.so\n",
      " ---> Using cache\n",
      " ---> afc840d073f5\n",
      "Step 25/32 : RUN curl $TFS_URL -o /usr/bin/tensorflow_model_server  && chmod 555 /usr/bin/tensorflow_model_server\n",
      " ---> Using cache\n",
      " ---> 71a5a3ce56b0\n",
      "Step 26/32 : EXPOSE 8500 8501\n",
      " ---> Using cache\n",
      " ---> 0db290cbf465\n",
      "Step 27/32 : RUN mkdir -p ${MODEL_BASE_PATH}\n",
      " ---> Using cache\n",
      " ---> 9f7cfe7d9d00\n",
      "Step 28/32 : RUN echo '#!/bin/bash \\n\\n' > /usr/bin/tf_serving_entrypoint.sh  && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"' >> /usr/bin/tf_serving_entrypoint.sh  && chmod +x /usr/bin/tf_serving_entrypoint.sh\n",
      " ---> Using cache\n",
      " ---> 0b33d8a1ecd4\n",
      "Step 29/32 : ADD https://raw.githubusercontent.com/aws/aws-deep-learning-containers-utils/master/deep_learning_container.py /usr/local/bin/deep_learning_container.py\n",
      "\n",
      " ---> Using cache\n",
      " ---> e16edf370e96\n",
      "Step 30/32 : RUN chmod +x /usr/local/bin/deep_learning_container.py\n",
      " ---> Using cache\n",
      " ---> 37c38d40a1be\n",
      "Step 31/32 : RUN curl https://aws-dlc-licenses.s3.amazonaws.com/tensorflow-2.0.1/license.txt -o /license.txt\n",
      " ---> Using cache\n",
      " ---> 80ac3dd469e2\n",
      "Step 32/32 : CMD [\"/usr/bin/tf_serving_entrypoint.sh\"]\n",
      " ---> Using cache\n",
      " ---> 114e2ba0c9b3\n",
      "[Warning] One or more build-args [TFS_VERSION] were not consumed\n",
      "Successfully built 114e2ba0c9b3\n",
      "Successfully tagged sagemaker-tensorflow-serving:2.0.0-cpu\n",
      "Successfully tagged sagemaker-tensorflow-serving:2.0-cpu\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {region} {tfs_version} {cpu_type}\n",
    "\n",
    "AWS_DEFAULT_REGION=$1\n",
    "export AWS_DEFAULT_REGION\n",
    "TFS_VERION=$2\n",
    "CPU_TYPE=$3\n",
    "\n",
    "cd sagemaker-tensorflow-serving-container\n",
    "\n",
    "./scripts/build.sh --version $TFS_VERION --arch $CPU_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Serving:2.0.0-cpu 를 ECR에 퍼블리시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 셀 스크립트를 실행하면 위에서 생성한 이미지가 ECR에 퍼블리시 됩니다.\n",
    "```\n",
    "./scripts/publish.sh --version 1.13 --arch cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 (2020/07) ECR에 해당 이미지가 없으면  publish.sh 에서 에러가 발생하여 아래 코드 추가 함\n",
    "```\n",
    "aws ecr describe-repositories --repository-names $repository > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name $repository > /dev/null\n",
    "fi\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sagemaker-tensorflow-serving-container/scripts/publish.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile sagemaker-tensorflow-serving-container/scripts/publish.sh\n",
    "\n",
    "#!/bin/bash\n",
    "#\n",
    "# Publish images to your ECR account.\n",
    "\n",
    "# 기존 소스에서 아래 주석 처리 함\n",
    "# set -euo pipefail\n",
    "\n",
    "source scripts/shared.sh\n",
    "\n",
    "parse_std_args \"$@\"\n",
    "\n",
    "aws ecr get-login-password --region ${aws_region} \\\n",
    "    | docker login \\\n",
    "        --password-stdin \\\n",
    "        --username AWS \\\n",
    "        \"${aws_account}.dkr.ecr.${aws_region}.amazonaws.com/${repository}\"\n",
    "\n",
    "aws ecr describe-repositories --repository-names $repository > /dev/null 2>&1\n",
    "\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name $repository > /dev/null\n",
    "fi\n",
    "\n",
    "docker tag $repository:$full_version-$device $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$full_version-$device\n",
    "docker tag $repository:$full_version-$device $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$short_version-$device\n",
    "docker push $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$full_version-$device\n",
    "docker push $aws_account.dkr.ecr.$aws_region.amazonaws.com/$repository:$short_version-$device\n",
    "docker logout https://$aws_account.dkr.ecr.$aws_region.amazonaws.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [057716757052.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-serving]\n",
      "a5a419e6f161: Preparing\n",
      "72d3231536e5: Preparing\n",
      "944191dea43d: Preparing\n",
      "ec97cc98c791: Preparing\n",
      "729be02db8e3: Preparing\n",
      "6bbc257292ad: Preparing\n",
      "95b89006e99c: Preparing\n",
      "f9f1b43c3b2c: Preparing\n",
      "fac1d87762ad: Preparing\n",
      "dfda3c21af61: Preparing\n",
      "4bb3d2400181: Preparing\n",
      "b600471953c1: Preparing\n",
      "eec78b36739a: Preparing\n",
      "79b08455af2f: Preparing\n",
      "4b07a7bca5b7: Preparing\n",
      "2af0e1f1e531: Preparing\n",
      "6bbc257292ad: Waiting\n",
      "bf509d6bc5ec: Preparing\n",
      "88cc1a200eb9: Preparing\n",
      "fac1d87762ad: Waiting\n",
      "f9f1b43c3b2c: Waiting\n",
      "95b89006e99c: Waiting\n",
      "dfda3c21af61: Waiting\n",
      "4b07a7bca5b7: Waiting\n",
      "2af0e1f1e531: Waiting\n",
      "4bb3d2400181: Waiting\n",
      "bf509d6bc5ec: Waiting\n",
      "88cc1a200eb9: Waiting\n",
      "b600471953c1: Waiting\n",
      "eec78b36739a: Waiting\n",
      "79b08455af2f: Waiting\n",
      "944191dea43d: Layer already exists\n",
      "72d3231536e5: Layer already exists\n",
      "a5a419e6f161: Layer already exists\n",
      "ec97cc98c791: Layer already exists\n",
      "729be02db8e3: Layer already exists\n",
      "f9f1b43c3b2c: Layer already exists\n",
      "6bbc257292ad: Layer already exists\n",
      "95b89006e99c: Layer already exists\n",
      "fac1d87762ad: Layer already exists\n",
      "4bb3d2400181: Layer already exists\n",
      "eec78b36739a: Layer already exists\n",
      "b600471953c1: Layer already exists\n",
      "dfda3c21af61: Layer already exists\n",
      "79b08455af2f: Layer already exists\n",
      "4b07a7bca5b7: Layer already exists\n",
      "2af0e1f1e531: Layer already exists\n",
      "88cc1a200eb9: Layer already exists\n",
      "bf509d6bc5ec: Layer already exists\n",
      "2.0.0-cpu: digest: sha256:9c7e135a68bc657e1a17a3d46a730fbb170fac0f71d0c07effc4528cdbaa9b9d size: 4090\n",
      "The push refers to repository [057716757052.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-serving]\n",
      "a5a419e6f161: Preparing\n",
      "72d3231536e5: Preparing\n",
      "944191dea43d: Preparing\n",
      "ec97cc98c791: Preparing\n",
      "729be02db8e3: Preparing\n",
      "6bbc257292ad: Preparing\n",
      "95b89006e99c: Preparing\n",
      "f9f1b43c3b2c: Preparing\n",
      "fac1d87762ad: Preparing\n",
      "dfda3c21af61: Preparing\n",
      "4bb3d2400181: Preparing\n",
      "b600471953c1: Preparing\n",
      "eec78b36739a: Preparing\n",
      "79b08455af2f: Preparing\n",
      "4b07a7bca5b7: Preparing\n",
      "2af0e1f1e531: Preparing\n",
      "6bbc257292ad: Waiting\n",
      "bf509d6bc5ec: Preparing\n",
      "88cc1a200eb9: Preparing\n",
      "f9f1b43c3b2c: Waiting\n",
      "95b89006e99c: Waiting\n",
      "eec78b36739a: Waiting\n",
      "fac1d87762ad: Waiting\n",
      "4bb3d2400181: Waiting\n",
      "dfda3c21af61: Waiting\n",
      "79b08455af2f: Waiting\n",
      "b600471953c1: Waiting\n",
      "bf509d6bc5ec: Waiting\n",
      "4b07a7bca5b7: Waiting\n",
      "88cc1a200eb9: Waiting\n",
      "944191dea43d: Layer already exists\n",
      "a5a419e6f161: Layer already exists\n",
      "72d3231536e5: Layer already exists\n",
      "729be02db8e3: Layer already exists\n",
      "ec97cc98c791: Layer already exists\n",
      "6bbc257292ad: Layer already exists\n",
      "95b89006e99c: Layer already exists\n",
      "f9f1b43c3b2c: Layer already exists\n",
      "dfda3c21af61: Layer already exists\n",
      "fac1d87762ad: Layer already exists\n",
      "4bb3d2400181: Layer already exists\n",
      "b600471953c1: Layer already exists\n",
      "79b08455af2f: Layer already exists\n",
      "eec78b36739a: Layer already exists\n",
      "4b07a7bca5b7: Layer already exists\n",
      "bf509d6bc5ec: Layer already exists\n",
      "2af0e1f1e531: Layer already exists\n",
      "88cc1a200eb9: Layer already exists\n",
      "2.0-cpu: digest: sha256:9c7e135a68bc657e1a17a3d46a730fbb170fac0f71d0c07effc4528cdbaa9b9d size: 4090\n",
      "Removing login credentials for 057716757052.dkr.ecr.us-west-2.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {region} {tfs_version} {cpu_type}\n",
    "\n",
    "AWS_DEFAULT_REGION=$1\n",
    "export AWS_DEFAULT_REGION\n",
    "TFS_VERION=$2\n",
    "CPU_TYPE=$3\n",
    "\n",
    "cd sagemaker-tensorflow-serving-container\n",
    "\n",
    "./scripts/publish.sh --version $TFS_VERION --arch $CPU_TYPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_infer_custom_image_tf_serving_20_cpu = '057716757052.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-serving:{}-{}'.format(\n",
    "    tfs_version,\n",
    "    cpu_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 다음 노트북에서 사용하기 위하여 저장 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ecr_infer_custom_image_tf_serving_20_cpu' (str)\n"
     ]
    }
   ],
   "source": [
    "%store ecr_infer_custom_image_tf_serving_20_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
