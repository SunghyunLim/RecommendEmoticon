{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 3.4.1] Train Docker Image 생성 및 ECR 퍼블리시\n",
    "\n",
    "이 노트북은 Docker 이미지를 생성하고, Amazon ECR(Elastic Container Registry)에 퍼블리스를 합니다. <br>\n",
    "아래는 상세 내용을 기술 합니다. BYOC에 대해서 알기위해서는 아래 BYOC Reference를 참고 하세요.\n",
    "\n",
    "- Train Script를 Dockefile이 사용할 수 있게 복사\n",
    "- Dockerfile의 정의를 확인\n",
    "    - Built-in Tensorflow:2.1.1-gpu Docker Image를 가져와서 사용 \n",
    "    - transfomer 설치 명령어 기술\n",
    "- ECR에 생성된 Docker Image를 퍼블리시 함\n",
    "\n",
    "---\n",
    "노트북의 소요 시간은 약 2분 걸립니다.\n",
    "\n",
    "---\n",
    "\n",
    "## BYOC Reference:\n",
    "- Get Started: Build Your Custom Training Container with Amazon SageMaker\n",
    "    - https://docs.aws.amazon.com/sagemaker/latest/dg/build-container-to-train-script-get-started.html\n",
    "- **추천:  Building your own algorithm container: BYOC 컨테이너 (학습, 추론)**\n",
    "    - https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb\n",
    "    \n",
    "    \n",
    "- Built-in Container Image\n",
    "    - https://github.com/aws/deep-learning-containers/blob/master/available_images.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Script를 다커 폴더에 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_file = \"tf_script_bert_tweet.py\"\n",
    "! cp {bert_train_file} \"train_container/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_container 폴더의 Dockerfile \n",
    "<font color=\"red\">**해당 Region에 따라 Dockerfile을 수정해야 합니다.**</font><br>\n",
    "현재의 Dockerfile은 'ap-northeast-2' 으로 되어 있습니다.\n",
    "민일 'us-west-2' 이면 train_container 폴더를 클릭한 후에 Dockerfile 파일을 열고\n",
    "아래와 같이 Dockerfile 의 내용을 바꾸어야 합니다. <br>\n",
    "\n",
    "FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:2.1.1-gpu-py36-cu101-ubuntu18.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# 기존의  Pre-built-in TF2.1-gpu image를 가져옴\u001b[39;49;00m\n",
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33m763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-training:2.1.1-gpu-py36-cu101-ubuntu18.04\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# transformers 설치\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install \u001b[31mtransformers\u001b[39;49;00m==\u001b[34m2\u001b[39;49;00m.8.0\n",
      "\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONUNBUFFERED\u001b[39;49;00m=TRUE\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONDONTWRITEBYTECODE\u001b[39;49;00m=TRUE\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPATH\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/code:\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mPATH\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Copy training code\u001b[39;49;00m\n",
      "\u001b[34mCOPY\u001b[39;49;00m tf_script_bert_tweet.py /opt/ml/code/\n",
      " \n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /opt/ml/code\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m SAGEMAKER_PROGRAM tf_script_bert_tweet.py\n"
     ]
    }
   ],
   "source": [
    "! pygmentize train_container/Dockerfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Docker 이미지를 ECR (Elastic Container Registry) 에 Push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['train_container_name']= \"bert2tweet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap-northeast-2\n",
      "Login Succeeded\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  201.7kB\n",
      "Step 1/8 : FROM 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-training:2.1.1-gpu-py36-cu101-ubuntu18.04\n",
      " ---> edb9e75607cd\n",
      "Step 2/8 : RUN pip install transformers==2.8.0\n",
      " ---> Using cache\n",
      " ---> d3d2a62e4e68\n",
      "Step 3/8 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 3f59ae2dc8f4\n",
      "Step 4/8 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 7d663fa5b7b1\n",
      "Step 5/8 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 2e856f64c9fc\n",
      "Step 6/8 : COPY tf_script_bert_tweet.py /opt/ml/code/\n",
      " ---> 0428f7974671\n",
      "Step 7/8 : WORKDIR /opt/ml/code\n",
      " ---> Running in d5ee3d4166b1\n",
      "Removing intermediate container d5ee3d4166b1\n",
      " ---> 1eddc5e6a53b\n",
      "Step 8/8 : ENV SAGEMAKER_PROGRAM tf_script_bert_tweet.py\n",
      " ---> Running in e01f7b1a22ae\n",
      "Removing intermediate container e01f7b1a22ae\n",
      " ---> 9e2496216d59\n",
      "[Warning] One or more build-args [REGION] were not consumed\n",
      "Successfully built 9e2496216d59\n",
      "Successfully tagged bert2tweet:latest\n",
      "The push refers to repository [343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/bert2tweet]\n",
      "6296f8b3a66d: Preparing\n",
      "8ad47dc5384c: Preparing\n",
      "2d913957779e: Preparing\n",
      "d729e097c2c9: Preparing\n",
      "b780d8d4ad2f: Preparing\n",
      "0f3a4c5f54a4: Preparing\n",
      "f8a9389186f8: Preparing\n",
      "d151b0122e5a: Preparing\n",
      "ce38e18d47e9: Preparing\n",
      "50d7c0cbb256: Preparing\n",
      "3725b53d2884: Preparing\n",
      "3235b27b45db: Preparing\n",
      "4e6af3b70d02: Preparing\n",
      "c780fd5fe812: Preparing\n",
      "11f9d76a977a: Preparing\n",
      "0938d4fa7f38: Preparing\n",
      "124424d56309: Preparing\n",
      "661efbed9d6f: Preparing\n",
      "6aee12d15f12: Preparing\n",
      "c3e4f3b073dc: Preparing\n",
      "cbe91a8e5056: Preparing\n",
      "808fd332a58a: Preparing\n",
      "b16af11cbf29: Preparing\n",
      "37b9a4b22186: Preparing\n",
      "e0b3afb09dc3: Preparing\n",
      "6c01b5a53aac: Preparing\n",
      "0f3a4c5f54a4: Waiting\n",
      "2c6ac8e5063e: Preparing\n",
      "cc967c529ced: Preparing\n",
      "f8a9389186f8: Waiting\n",
      "d151b0122e5a: Waiting\n",
      "0938d4fa7f38: Waiting\n",
      "ce38e18d47e9: Waiting\n",
      "124424d56309: Waiting\n",
      "50d7c0cbb256: Waiting\n",
      "3725b53d2884: Waiting\n",
      "3235b27b45db: Waiting\n",
      "661efbed9d6f: Waiting\n",
      "4e6af3b70d02: Waiting\n",
      "6aee12d15f12: Waiting\n",
      "c780fd5fe812: Waiting\n",
      "11f9d76a977a: Waiting\n",
      "c3e4f3b073dc: Waiting\n",
      "6c01b5a53aac: Waiting\n",
      "808fd332a58a: Waiting\n",
      "cc967c529ced: Waiting\n",
      "37b9a4b22186: Waiting\n",
      "b16af11cbf29: Waiting\n",
      "e0b3afb09dc3: Waiting\n",
      "8ad47dc5384c: Layer already exists\n",
      "d729e097c2c9: Layer already exists\n",
      "b780d8d4ad2f: Layer already exists\n",
      "2d913957779e: Layer already exists\n",
      "0f3a4c5f54a4: Layer already exists\n",
      "f8a9389186f8: Layer already exists\n",
      "ce38e18d47e9: Layer already exists\n",
      "d151b0122e5a: Layer already exists\n",
      "50d7c0cbb256: Layer already exists\n",
      "3235b27b45db: Layer already exists\n",
      "3725b53d2884: Layer already exists\n",
      "4e6af3b70d02: Layer already exists\n",
      "c780fd5fe812: Layer already exists\n",
      "11f9d76a977a: Layer already exists\n",
      "0938d4fa7f38: Layer already exists\n",
      "661efbed9d6f: Layer already exists\n",
      "124424d56309: Layer already exists\n",
      "6aee12d15f12: Layer already exists\n",
      "c3e4f3b073dc: Layer already exists\n",
      "cbe91a8e5056: Layer already exists\n",
      "808fd332a58a: Layer already exists\n",
      "b16af11cbf29: Layer already exists\n",
      "37b9a4b22186: Layer already exists\n",
      "e0b3afb09dc3: Layer already exists\n",
      "6c01b5a53aac: Layer already exists\n",
      "2c6ac8e5063e: Layer already exists\n",
      "cc967c529ced: Layer already exists\n",
      "6296f8b3a66d: Pushed\n",
      "latest: digest: sha256:8925180fdcdb9e57383642843dd57cd0491047f5ffbee11f42bce25368895e93 size: 6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd train_container\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=$train_container_name\n",
    "\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "echo $region\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Get the login command from ECR in order to pull down the Tensorflow-gpu:1.5 image\n",
    "$(aws ecr get-login --registry-ids 763104351884 --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} . --build-arg REGION=${region}\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
